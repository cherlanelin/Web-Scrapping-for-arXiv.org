"","link","link_makeup","title","author","description"
"1","arXiv:1906.11245","https://arxiv.org/abs/1906.11245","A Tractable Algorithm For Finite-Horizon Continuous Reinforcement  Learning","Phanideep Gampa, Sairam Satwik Kondamudi, Lakshmanan Kailasam","We consider the finite horizon continuous reinforcement learning problem. Ourcontribution is three-fold. First,we give a tractable algorithm based onoptimistic value iteration for the problem. Next,we give a lower bound onregret of order $\Omega(T^{2/3})$ for any algorithm discretizes the statespace, improving the previous regret bound of $\Omega(T^{1/2})$ of Ortner andRyabko \cite{contrl} for the same problem. Next,under the assumption that therewards and transitions are H\""{o}lder Continuous we show that the upper boundon the discretization error is $const.Ln^{-\alpha}T$. Finally,we give somesimple experiments to validate our propositions."
"2","arXiv:1906.11246","https://arxiv.org/abs/1906.11246","Identifying DNS-tunneled traffic with predictive models","Andreas Berg, Daniel Forsberg","DNS is a distributed, fault tolerant system that avoids a single point offailure. As such it is an integral part of the internet as we use it today andhence deemed a safe protocol which is let through firewalls and proxies with noor little checks. This can be exploited by malicious agents. Network forensicsis effective but struggles due to size of data and manual labour. This paperexplores to what extent predictive models can be used to predict networktraffic, what protocols are tunneled in the DNS protocol and more specificallywhether the predictive performance is enhanced when analyzing DNS-queries andresponses together and which feature set that can be used for DNS-tunnelednetwork prediction. The tested protocols are SSH, SFTP and Telnet and themachine learning models used are Multi Layered Perceptron and Random Forests.To train the models we extract the IP Packet length, Name length and Nameentropy of both the queries and responses in the DNS traffic. With anexperimental research strategy it is empirically shown that the performance ofthe models increases when training the models on the query and respose pairsrather than using only queries or responses. The accuracy of the models is >83%and reduction in data size when features are extracted is roughly 95%. Ourresults provides evidence that machine learning is a valuable tool in detectingnetwork protocols in a DNS tunnel and that only an small subset of networktraffic is needed to detect this anomaly."
"3","arXiv:1906.11247","https://arxiv.org/abs/1906.11247","Beyond DAGs: Modeling Causal Feedback with Fuzzy Cognitive Maps","Osonde Osoba, Bart Kosko","Fuzzy cognitive maps (FCMs) model feedback causal relations in interwovenwebs of causality and policy variables. FCMs are fuzzy signed directed graphsthat allow degrees of causal influence and event occurrence. Such causal modelscan simulate a wide range of policy scenarios and decision processes. Theirdirected loops or cycles directly model causal feedback. Their nonlineardynamics permit forward-chaining inference from input causes and policy optionsto output effects. Users can add detailed dynamics and feedback links directlyto the causal model or infer them with statistical learning laws. Users canfuse or combine FCMs from multiple experts by weighting and adding theunderlying fuzzy edge matrices and do so recursively if needed. The combinedFCM tends to better represent domain knowledge as the expert sample sizeincreases if the expert sample approximates a random sample. Many causal modelsuse more restrictive directed acyclic graphs (DAGs) and Bayesian probabilities.DAGs do not model causal feedback because they do not contain closed loops.Combining DAGs also tends to produce cycles and thus tends not to produce a newDAG. Combining DAGs tends to produce a FCM. FCM causal influence is alsotransitive whereas probabilistic causal influence is not transitive in general.Overall: FCMs trade the numerical precision of probabilistic DAGs for patternprediction, faster and scalable computation, ease of combination, and richerfeedback representation. We show how FCMs can apply to problems of publicsupport for insurgency and terrorism and to US-China conflict relations inGraham Allison's Thucydides-trap framework. The appendix gives the textualjustification of the Thucydides-trap FCM. It also extends our earlier theorem[Osoba-Kosko2017] to a more general result that shows the transitive and totalcausal influence that upstream concept nodes exert on downstream nodes."
"4","arXiv:1906.11278","https://arxiv.org/abs/1906.11278","Private Information Retrieval with Private Coded Side Information: The  Multi-Server Case","Fatemeh Kazemi, Esmaeil Karimi, Anoosheh Heidarzadeh, Alex Sprintson","In this paper, we consider the multi-server setting of Private InformationRetrieval with Private Coded Side Information (PIR-PCSI) problem. In thisproblem, there is a database of $K$ messages whose copies are replicated across$N$ servers, and there is a user who knows a random linear combination of arandom subset of $M$ messages in the database as side information. The userwishes to download one message from the servers, while protecting theidentities of both the demand message and the messages forming the sideinformation. We assume that the servers know the number of messages forming theuser's side information in advance, whereas the indices of these messages andtheir coefficients in the side information are not known to any of the serversa priori.Our goal is to characterize (or derive a lower bound on) the capacity, i.e.,the maximum achievable download rate, for the following two settings. In thefirst setting, the set of messages forming the linear combination available tothe user as side information, does not include the user's demanded message. Forthis setting, we show that the capacity is equal to$\left(1+{1}/{N}+\dots+{1}/{N^{K-M-1}}\right)^{-1}$. In the second setting, thedemand message contributes to the linear combination available to the user asside information, i.e., the demand message is one of the messages that form theuser's side information. For this setting, we show that the capacity islower-bounded by $\left(1+{1}/{N}+\dots+{1}/{N^{K-M}}\right)^{-1}$. Theproposed achievability schemes and proof techniques leverage ideas from bothour recent methods proposed for the single-server PIR-PCSI problem as well asthe techniques proposed by Sun and Jafar for multi-server private computationproblem."
"5","arXiv:1906.11282","https://arxiv.org/abs/1906.11282","Developing an App to interpret Chest X-rays to support the diagnosis of  respiratory pathology with Artificial Intelligence","Andrew Elkins, Felipe F. Freitas, Veronica Sanz","In this paper we present our work to improve access to diagnosis in remoteareas where good quality medical services may be lacking. We develop newMachine Learning methodologies for deployment onto mobile devices to help theearly diagnosis of a number of life-threatening conditions using X-ray images.By using the latest developments in fast and portable Artificial Intelligenceenvironments, we develop a smartphone app using an Artificial Neural Network toassist physicians in their diagnostic."
"6","arXiv:1906.11285","https://arxiv.org/abs/1906.11285","Re-ranking Based Diversification: A Unifying View","Shameem A Puthiya Parambath","We analyze different re-ranking algorithms for diversification and show thatmajority of them are based on maximizing submodular/modular functions from theclass of parameterized concave/linear over modular functions. We study theoptimality of such algorithms in terms of the `total curvature'. We also showthat by adjusting the hyperparameter of the concave/linear composition totrade-off relevance and diversity, if any, one is in fact tuning the `totalcurvature' of the function for relevance-diversity trade-off."
"7","arXiv:1906.12297","https://arxiv.org/abs/1906.12297","Blocking dominating sets for $H$-free graphs via edge contractions","Esther Galby, Paloma T. Lima, Bernard Ries","In this paper, we consider the following problem: given a connected graph$G$, can we reduce the domination number of $G$ by one by using only one edgecontraction? We show that the problem is $\mathsf{coNP}$-hard when restrictedto subcubic claw-free graphs and $P_7$-free graphs."
"8","arXiv:1906.11286","https://arxiv.org/abs/1906.11286","Reinforcement Learning Models of Human Behavior: Reward Processing in  Mental Disorders","Baihan Lin, Guillermo Cecchi, Djallel Bouneffouf, Jenna Reinen, Irina Rish","Drawing an inspiration from behavioral studies of human decision making, wepropose here a general parametric framework for a reinforcement learningproblem, which extends the standard Q-learning approach to incorporate atwo-stream framework of reward processing with biases biologically associatedwith several neurological and psychiatric conditions, including Parkinson's andAlzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD),addiction, and chronic pain. For AI community, the development of agents thatreact differently to different types of rewards can enable us to understand awide spectrum of multi-agent interactions in complex real-world socioeconomicsystems. Empirically, the proposed model outperforms Q-Learning and DoubleQ-Learning in artificial scenarios with certain reward distributions andreal-world human decision making gambling tasks. Moreover, from the behavioralmodeling perspective, our parametric framework can be viewed as a first steptowards a unifying computational model capturing reward processingabnormalities across multiple mental conditions and user preferences inlong-term recommendation systems."
"9","arXiv:1906.11288","https://arxiv.org/abs/1906.11288","Secure Client and Server Geolocation Over the Internet","AbdelRahman Abdou, Paul C. van Oorschot","In this article, we provide a summary of recent efforts towards achievingInternet geolocation securely, \ie without allowing the entity being geolocatedto cheat about its own geographic location. Cheating motivations arise frommany factors, including impersonation (in the case locations are used toreinforce authentication), and gaining location-dependent benefits. Inparticular, we provide a technical overview of Client Presence Verification(CPV) and Server Location Verification (SLV)---two recently proposed techniquesdesigned to verify the geographic locations of clients and servers in realtimeover the Internet. Each technique addresses a wide range of adversarial tacticsto manipulate geolocation, including the use of IP-hiding technologies likeVPNs and anonymizers, as we now explain."
"10","arXiv:1906.11289","https://arxiv.org/abs/1906.11289","Near Optimal Stratified Sampling","Tiancheng Yu, Xiyu Zhai, Suvrit Sra","The performance of a machine learning system is usually evaluated by usingi.i.d.\ observations with true labels. However, acquiring ground truth labelsis expensive, while obtaining unlabeled samples may be cheaper. Stratifiedsampling can be beneficial in such settings and can reduce the number of truelabels required without compromising the evaluation accuracy. Stratifiedsampling exploits statistical properties (e.g., variance) across strata of theunlabeled population, though usually under the unrealistic assumption thatthese properties are known. We propose two new algorithms that simultaneouslyestimate these properties and optimize the evaluation accuracy. We construct alower bound to show the proposed algorithms (to log-factors) are rate optimal.Experiments on synthetic and real data show the reduction in label complexitythat is enabled by our algorithms."
"11","arXiv:1906.11290","https://arxiv.org/abs/1906.11290","User-Oriented Summaries Using a PSO Based Scoring Optimization Method","Augusto Villa-Monte, Laura Lanzarini, Aurelio F. Bariviera, José A. Olivas","Automatic text summarization tools have a great impact on many fields, suchas medicine, law, and scientific research in general. As information overloadincreases, automatic summaries allow handling the growing volume of documents,usually by assigning weights to the extracted phrases based on theirsignificance in the expected summary. Obtaining the main contents of any givendocument in less time than it would take to do that manually is still an issueof interest. In~this~ article, a new method is presented that allowsautomatically generating extractive summaries from documents by adequatelyweighting sentence scoring features using \textit{Particle Swarm Optimization}.The key feature of the proposed method is the identification of those featuresthat are closest to the criterion used by the individual when summarizing. Theproposed method combines a binary representation and a continuous one, using anoriginal variation of the technique developed by the authors of this paper. Ourpaper shows that using user labeled information in the training set helps tofind better metrics and weights. The empirical results yield an improvedaccuracy compared to previous methods used in this field"
"12","arXiv:1906.11298","https://arxiv.org/abs/1906.11298","A Generative Model for Punctuation in Dependency Trees","Xiang Lisa Li, Dingquan Wang, Jason Eisner","Treebanks traditionally treat punctuation marks as ordinary words, butlinguists have suggested that a tree's ""true"" punctuation marks are notobserved (Nunberg, 1990). These latent ""underlying"" marks serve to delimit orseparate constituents in the syntax tree. When the tree's yield is rendered asa written sentence, a string rewriting mechanism transduces the underlyingmarks into ""surface"" marks, which are part of the observed (surface) string butshould not be regarded as part of the tree. We formalize this idea in agenerative model of punctuation that admits efficient dynamic programming. Wetrain it without observing the underlying marks, by locally maximizing theincomplete data likelihood (similarly to EM). When we use the trained model toreconstruct the tree's underlying punctuation, the results appear plausibleacross 5 languages, and in particular, are consistent with Nunberg's analysisof English. We show that our generative model can be used to beat baselines onpunctuation restoration. Also, our reconstruction of a sentence's underlyingpunctuation lets us appropriately render the surface punctuation (via ourtrained underlying-to-surface mechanism) when we syntactically transform thesentence."
"13","arXiv:1906.11301","https://arxiv.org/abs/1906.11301","Exploring the Role of Prior Beliefs for Argument Persuasion","Esin Durmus, Claire Cardie","Public debate forums provide a common platform for exchanging opinions on atopic of interest. While recent studies in natural language processing (NLP)have provided empirical evidence that the language of the debaters and theirpatterns of interaction play a key role in changing the mind of a reader,research in psychology has shown that prior beliefs can affect ourinterpretation of an argument and could therefore constitute a competingalternative explanation for resistance to changing one's stance. To study theactual effect of language use vs. prior beliefs on persuasion, we provide a newdataset and propose a controlled setting that takes into consideration tworeader level factors: political and religious ideology. We find that priorbeliefs affected by these reader level factors play a more important role thanlanguage use effects and argue that it is important to account for them in NLPstudies of persuasion."
"14","arXiv:1906.11307","https://arxiv.org/abs/1906.11307","One Size Does Not Fit All: Quantifying and Exposing the Accuracy-Latency  Trade-off in Machine Learning Cloud Service APIs via Tolerance Tiers","Matthew Halpern, Behzad Boroujerdian, Todd Mummert, Evelyn Duesterwald, Vijay Janapa Reddi","Today's cloud service architectures follow a ""one size fits all"" deploymentstrategy where the same service version instantiation is provided to the endusers. However, consumers are broad and different applications have differentaccuracy and responsiveness requirements, which as we demonstrate renders the""one size fits all"" approach inefficient in practice. We use a production-gradespeech recognition engine, which serves several thousands of users, and an opensource computer vision based system, to explain our point. To overcome thelimitations of the ""one size fits all"" approach, we recommend Tolerance Tierswhere each MLaaS tier exposes an accuracy/responsiveness characteristic, andconsumers can programmatically select a tier. We evaluate our proposal on theCPU-based automatic speech recognition (ASR) engine and cutting-edge neuralnetworks for image classification deployed on both CPUs and GPUs. The resultsshow that our proposed approach provides an MLaaS cloud service architecturethat can be tuned by the end API user or consumer to outperform theconventional ""one size fits all"" approach."
"15","arXiv:1906.11310","https://arxiv.org/abs/1906.11310","A Corpus for Modeling User and Language Effects in Argumentation on  Online Debating","Esin Durmus, Claire Cardie","Existing argumentation datasets have succeeded in allowing researchers todevelop computational methods for analyzing the content, structure andlinguistic features of argumentative text. They have been much less successfulin fostering studies of the effect of ""user"" traits -- characteristics andbeliefs of the participants -- on the debate/argument outcome as this type ofuser information is generally not available. This paper presents a dataset of78, 376 debates generated over a 10-year period along with surprisinglycomprehensive participant profiles. We also complete an example study using thedataset to analyze the effect of selected user traits on the debate outcome incomparison to the linguistic features typically employed in studies of thiskind."
"16","arXiv:1906.11313","https://arxiv.org/abs/1906.11313","Determining Relative Argument Specificity and Stance for Complex  Argumentative Structures","Esin Durmus, Faisal Ladhak, Claire Cardie","Systems for automatic argument generation and debate require the ability to(1) determine the stance of any claims employed in the argument and (2) assessthe specificity of each claim relative to the argument context. Existing workon understanding claim specificity and stance, however, has been limited to thestudy of argumentative structures that are relatively shallow, most oftenconsisting of a single claim that directly supports or opposes the argumentthesis. In this paper, we tackle these tasks in the context of complexarguments on a diverse set of topics. In particular, our dataset consists ofmanually curated argument trees for 741 controversial topics covering 95,312unique claims; lines of argument are generally of depth 2 to 6. We find that asthe distance between a pair of claims increases along the argument path,determining the relative specificity of a pair of claims becomes easier anddetermining their relative stance becomes harder."
"17","arXiv:1906.11315","https://arxiv.org/abs/1906.11315","Generalization to Novel Objects using Prior Relational Knowledge","Varun Kumar Vijay, Abhinav Ganesh, Hanlin Tang, Arjun Bansal","To solve tasks in new environments involving objects unseen during training,agents must reason over prior information about those objects and theirrelations. We introduce the Prior Knowledge Graph network, an architecture forcombining prior information, structured as a knowledge graph, with a symbolicparsing of the visual scene, and demonstrate that this approach is able toapply learned relations to novel objects whereas the baseline algorithms fail.Ablation experiments show that the agents ground the knowledge graph relationsto semantically-relevant behaviors. In both a Sokoban game and the more complexPacman environment, our network is also more sample efficient than thebaselines, reaching the same performance in 5-10x fewer episodes. Once theagents are trained with our approach, we can manipulate agent behavior bymodifying the knowledge graph in semantically meaningful ways. These resultssuggest that our network provides a framework for agents to reason overstructured knowledge graphs while still leveraging gradient based learningapproaches."
"18","arXiv:1906.11319","https://arxiv.org/abs/1906.11319","A Stricter Heap Separating Points-To Logic","René Haberland, Kirill Krinkin","Dynamic memory issues are hard to locate and may cost much of a developmentproject's efforts and was repeatedly reported similarly afterwardsindependently by different persons. Verification as one formal method may proofa given program's heap matches a specified dynamic behaviour. Dynamic (or heap)memory, is the region within main memory that is manipulated by programstatements like alloc, free and pointer manipulation during program execution.Usually, heap memory is allocated for problems where the amount of used memoryis unknown prior to execution. Regions within the heap may be related ""somehow""with each other, often, but not always, by pointers containing absoluteaddresses of related heap cells. The data structure described by all validpointer variables manifests heap graphs.A heap graph is a directed connected simple graph within the dynamic memorywhich may contain cycles, and where each vertex represents an unique memoryaddress and every edge links two heap vertices. The heap graph must be pointedby at least one variable from the local stack or a chain of other heap graphswhich is finally pointed by at least one stacked variable. Heap vertices maynot overlap. A heap formula expresses the assertion on dynamic memory and caneither be a heaplet, or a recursively defined heap-spatial or logical formula."
"19","arXiv:1906.11321","https://arxiv.org/abs/1906.11321","HEATS: Heterogeneity- and Energy-Aware Task-based Scheduling","Isabelly Rocha, Christian Göttel, Pascal Felber, Marcelo Pasin, Romain Rouvoy, Valerio Schiavoni","Cloud providers usually offer diverse types of hardware for their users.Customers exploit this option to deploy cloud instances featuring GPUs, FPGAs,architectures other than x86 (e.g., ARM, IBM Power8), or featuring certainspecific extensions (e.g, Intel SGX). We consider in this work the instancesused by customers to deploy containers, nowadays the de facto standard formicro-services, or to execute computing tasks. In doing so, the underlyingcontainer orchestrator (e.g., Kubernetes) should be designed so as to take intoaccount and exploit this hardware diversity. In addition, besides the featurerange provided by different machines, there is an often overlooked diversity inthe energy requirements introduced by hardware heterogeneity, which is simplyignored by default container orchestrator's placement strategies. We introduceHEATS, a new task-oriented and energy-aware orchestrator for containerizedapplications targeting heterogeneous clusters. HEATS allows customers to tradeperformance vs. energy requirements. Our system first learns the performanceand energy features of the physical hosts. Then, it monitors the execution oftasks on the hosts and opportunistically migrates them onto different clusternodes to match the customer-required deployment trade-offs. Our HEATS prototypeis implemented within Google's Kubernetes. The evaluation with synthetic tracesin our cluster indicate that our approach can yield considerable energy savings(up to 8.5%) and only marginally affect the overall runtime of deployed tasks(by at most 7%). HEATS is released as open-source."
"20","arXiv:1906.11326","https://arxiv.org/abs/1906.11326","Approximating the pth Root by Composite Rational Functions","Evan S. Gawlik, Yuji Nakatsukasa","A landmark result from rational approximation theory states that $x^{1/p}$ on$[0,1]$ can be approximated by a type-$(n,n)$ rational function withroot-exponential accuracy. Motivated by the recursive optimality property ofZolotarev functions (for the square root and sign functions), we investigateapproximating $x^{1/p}$ by composite rational functions of the form $r_k(x,r_{k-1}(x, r_{k-2}( \cdots (x,r_1(x,1)) )))$. While this class of rationalfunctions ceases to contain the minimax (best) approximant for $p\geq 3$, weshow that it achieves approximately $p$th-root exponential convergence withrespect to the degree. Moreover, crucially, the convergence is doublyexponential with respect to the number of degrees of freedom, suggesting thatcomposite rational functions are able to approximate $x^{1/p}$ and relatedfunctions (such as $|x|$ and the sector function) with exceptional efficiency."
"21","arXiv:1906.11327","https://arxiv.org/abs/1906.11327","The Adversarial Robustness of Sampling","Omri Ben-Eliezer, Eylon Yogev","Random sampling is a fundamental primitive in modern algorithms, statistics,and machine learning, used as a generic method to obtain a small yet""representative"" subset of the data. In this work, we investigate therobustness of sampling against adaptive adversarial attacks in a streamingsetting: An adversary sends a stream of elements from a universe $U$ to asampling algorithm (e.g., Bernoulli sampling or reservoir sampling), with thegoal of making the sample ""very unrepresentative"" of the underlying datastream. The adversary is fully adaptive in the sense that it knows the exactcontent of the sample at any given point along the stream, and can choose whichelement to send next accordingly, in an online manner.Well-known results in the static setting indicate that if the full stream ischosen in advance (non-adaptively), then a random sample of size $\Omega(d /\varepsilon^2)$ is an $\varepsilon$-approximation of the full data with goodprobability, where $d$ is the VC-dimension of the underlying set system$(U,R)$. Does this sample size suffice for robustness against an adaptiveadversary? The simplistic answer is \emph{negative}: We demonstrate a setsystem where a constant sample size (corresponding to VC-dimension $1$)suffices in the static setting, yet an adaptive adversary can make the samplevery unrepresentative, as long as the sample size is (strongly) sublinear inthe stream length, using a simple and easy-to-implement attack.However, this attack is ""theoretical only"", requiring the set system size to(essentially) be exponential in the stream length. This is not a coincidence:We show that to make Bernoulli or reservoir sampling robust against adaptiveadversaries, the modification required is solely to replace the VC-dimensionterm $d$ in the sample size with the cardinality term $\log |R|$. This nearlymatches the bound imposed by the attack."
"22","arXiv:1906.11328","https://arxiv.org/abs/1906.11328","Adversarial FDI Attack against AC State Estimation with ANN","Tian Liu, Tao Shu","Artificial neural network (ANN) provides superior accuracy for nonlinearalternating current (AC) state estimation (SE) in smart grid over traditionalmethods. However, research has discovered that ANN could be easily fooled byadversarial examples. In this paper, we initiate a new study of adversarialfalse data injection (FDI) attack against AC SE with ANN: by injecting adeliberate attack vector into measurements, the attacker can degrade theaccuracy of ANN SE while remaining undetected. We propose a population-basedalgorithm and a gradient-based algorithm to generate attack vectors. Theperformance of these algorithms is evaluated through simulations on IEEE 9-bus,14-bus and 30-bus systems under various attack scenarios. Simulation resultsshow that DE is more effective than SLSQP on all simulation cases. The attackexamples generated by DE algorithm successfully degrade the ANN SE accuracywith high probability."
"23","arXiv:1906.11331","https://arxiv.org/abs/1906.11331","$H_{\infty}$-Control of Grid-Connected Converters: Design, Objectives  and Decentralized Stability Certificates","Linbin Huang, Huanhai Xin, Florian Dörfler","The modern power system features the high penetration of power converters dueto the development of renewables, HVDC, etc. Currently, the controller designand parameter tuning of power converters heavily rely on rich engineeringexperience and extrapolation from a single converter system, which may lead toinferior performance or even instabilities under variable grid conditions. Inthis paper, we propose an $H_{\infty}$-control design framework to provide asystematic way for the robust and optimal control design of power converters.We discuss how to choose weighting functions to achieve anticipated and robustperformance with regards to multiple control objectives. Further, we show thatthe operating mode of the converter (grid-forming or grid-following) can beconveniently specified by proper choice of weighting functions. Furthermore,based on the small gain theorem, we propose a decentralized stability criterionwhich enables to guarantee the small-signal stability of multi-convertersystems through local $H_{\infty}$-control design of the converters. We providehigh-fidelity nonlinear simulations to illustrate the effectiveness of ourmethod."
"24","arXiv:1906.11333","https://arxiv.org/abs/1906.11333","Fairness criteria through the lens of directed acyclic graphical models","Benjamin R. Baer, Daniel E. Gilbert, Martin T. Wells","A substantial portion of the literature on fairness in algorithms proposes,analyzes, and operationalizes simple formulaic criteria for assessing fairness.Two of these criteria, Equalized Odds and Calibration by Group, have gainedsignificant attention for their simplicity and intuitive appeal, but also fortheir incompatibility. This chapter provides a perspective on the meaning andconsequences of these and other fairness criteria using graphical models whichreveals Equalized Odds and related criteria to be ultimately misleading. Anassessment of various graphical models suggests that fairness criteria shouldultimately be case-specific and sensitive to the nature of the information thealgorithm processes."
"25","arXiv:1906.11336","https://arxiv.org/abs/1906.11336","A Simple Deep Personalized Recommendation System","Pavlos Mitsoulis-Ntompos, Meisam Hejazinia, Serena Zhang, Travis Brady","Recommender systems are a critical tool to match listings and travelers intwo-sided vacation rental marketplaces. Such systems require high capacity toextract user preferences for items from implicit signals at scale. To learnthose preferences, we propose a Simple Deep Personalized Recommendation Systemto compute travelers' conditional embeddings. Our method combines listingembeddings in a supervised structure to build short-term historical context topersonalize recommendations for travelers. This approach is computationallyefficient and scalable, and allows us to capture non-linear dependencies. Ouroffline evaluation indicates that traveler embeddings created using a DeepAverage Network can improve the precision of a downstream conversion predictionmodel by seven percent, outperforming more complex benchmark methods forshopping experience personalization."
"26","arXiv:1906.11351","https://arxiv.org/abs/1906.11351","Software Engineering Research Community Viewpoints on Rapid Reviews","Bruno Cartaxo, Gustavo Pinto, Baldoino Fonseca, Márcio Ribeiro, Pedro Pinheiro, Sergio Soares, Maria Teresa Baldassarre","Background: One of the most important current challenges of SoftwareEngineering (SE) research is to provide relevant evidence to practice. Inhealth related fields, Rapid Reviews (RRs) have shown to be an effective methodto achieve that goal. However, little is known about how the SE researchcommunity perceives the potential applicability of RRs. Aims: The goal of thisstudy is to understand the SE research community viewpoints towards the use ofRRs as a means to provide evidence to practitioners. Method: To understandtheir viewpoints, we invited 37 researchers to analyze 50 opinion statementsabout RRs, and rate them according to what extent they agree with eachstatement. Q-Methodology was employed to identify the most salient viewpoints,represented by the so called factors. Results: Four factors were identified:Factor A groups undecided researchers that need more evidence before using RRs;Researchers grouped in Factor B are generally positive about RRs, but highlightthe need to define minimum standards; Factor C researchers are more skepticaland reinforce the importance of high quality evidence; Researchers aligned toFactor D have a pragmatic point of view, considering RRs can be applied basedon the context and constraints faced by practitioners. Conclusions: Inconclusion, although there are opposing viewpoints, there are also some commongrounds. For example, all viewpoints agree that both RRs and Systematic Reviewscan be poorly or well conducted."
"27","arXiv:1906.11356","https://arxiv.org/abs/1906.11356","Personalized Student Stress Prediction with Deep Multitask Network","Abhinav Shaw, Natcha Simsiri, Iman Deznaby, Madalina Fiterau, Tauhidur Rahaman","With the growing popularity of wearable devices, the ability to utilizephysiological data collected from these devices to predict the wearer's mentalstate such as mood and stress suggests great clinical applications, yet such atask is extremely challenging. In this paper, we present a general platform forpersonalized predictive modeling of behavioural states like students' level ofstress. Through the use of Auto-encoders and Multitask learning we extend theprediction of stress to both sequences of passive sensor data and high-levelcovariates. Our model outperforms the state-of-the-art in the prediction ofstress level from mobile sensor data, obtaining a 45.6 % improvement in F1score on the StudentLife dataset."
"28","arXiv:1906.11362","https://arxiv.org/abs/1906.11362","Interactive Physics-Inspired Traffic Congestion Management","Hossein Rastgoftar","This paper proposes a new physics-based approach to effectively controlcongestion in a network of interconnected roads (NOIR). The paper integratesmass flow conservation and diffusion-based dynamics to model trafficcoordination in a NOIR. The mass conservation law is used to model the trafficdensity dynamics across the NOIR while the diffusion law is applied to includetraffic speed and motion direction into planning. This paper offers an analogybetween traffic coordination in a transportation system and heat flux in athermal system to define a potential filed over the NOIR. The paper alsodevelops an interactive light-based and boundary control to manage trafficcongestion through optimizing the traffic signal operations and controllingtraffic flows at the NOIR boundary nodes. More specifically, a model predictiveboundary control optimizes the NOIR inflow traffic while a receding horizonoptimizer assigns the optimal movement phases at the NOIR intersections. Forsimulation, the paper models traffic congestion in a heterogeneous NOIR with alarge number of interior and boundary nodes where the proposed interactivecontrol can successfully manage the congestion."
"29","arXiv:1906.11366","https://arxiv.org/abs/1906.11366","Quantum Entropy Scoring for Fast Robust Mean Estimation and Improved  Outlier Detection","Yihe Dong, Samuel B. Hopkins, Jerry Li","We study two problems in high-dimensional robust statistics: \emph{robustmean estimation} and \emph{outlier detection}. In robust mean estimation thegoal is to estimate the mean $\mu$ of a distribution on $\mathbb{R}^d$ given$n$ independent samples, an $\varepsilon$-fraction of which have been corruptedby a malicious adversary. In outlier detection the goal is to assign an\emph{outlier score} to each element of a data set such that elements morelikely to be outliers are assigned higher scores. Our algorithms for bothproblems are based on a new outlier scoring method we call QUE-scoring based on\emph{quantum entropy regularization}. For robust mean estimation, this yieldsthe first algorithm with optimal error rates and nearly-linear running time$\widetilde{O}(nd)$ in all parameters, improving on the previous fastestrunning time $\widetilde{O}(\min(nd/\varepsilon^6, nd^2))$. For outlierdetection, we evaluate the performance of QUE-scoring via extensive experimentson synthetic and real data, and demonstrate that it often performs better thanpreviously proposed algorithms. Code for these experiments is available athttps://github.com/twistedcubic/que-outlier-detection ."
"30","arXiv:1906.11367","https://arxiv.org/abs/1906.11367","Accelerating Large-Kernel Convolution Using Summed-Area Tables","Linguang Zhang, Maciej Halber, Szymon Rusinkiewicz","Expanding the receptive field to capture large-scale context is key toobtaining good performance in dense prediction tasks, such as human poseestimation. While many state-of-the-art fully-convolutional architecturesenlarge the receptive field by reducing resolution using strided convolution orpooling layers, the most straightforward strategy is adopting large filters.This, however, is costly because of the quadratic increase in the number ofparameters and multiply-add operations. In this work, we explore usinglearnable box filters to allow for convolution with arbitrarily large kernelsize, while keeping the number of parameters per filter constant. In addition,we use precomputed summed-area tables to make the computational cost ofconvolution independent of the filter size. We adapt and incorporate the boxfilter as a differentiable module in a fully-convolutional neural network, anddemonstrate its competitive performance on popular benchmarks for the task ofhuman pose estimation."
"31","arXiv:1906.11369","https://arxiv.org/abs/1906.11369","Approximate Dynamic Programming For Linear Systems with State and Input  Constraints","Ankush Chakrabarty, Rien Quirynen, Claus Danielson, Weinan Gao","Enforcing state and input constraints during reinforcement learning (RL) incontinuous state spaces is an open but crucial problem which remains aroadblock to using RL in safety-critical applications. This paper leveragesinvariant sets to update control policies within an approximate dynamicprogramming (ADP) framework that guarantees constraint satisfaction for alltime and converges to the optimal policy (in a linear quadratic regulatorsense) asymptotically. An algorithm for implementing the proposed constrainedADP approach in a data-driven manner is provided. The potential of thisformalism is demonstrated via numerical examples."
"32","arXiv:1906.11371","https://arxiv.org/abs/1906.11371","Deception Strategies and Threats for Online Discussions","Onur Varol, Ismail Uluturk","Communication plays a major role in social systems. Effective communications,which requires transmission of the messages between individuals withoutdisruptions or noise, can be a powerful tool to deliver intended impact.Language and style of the content can be leveraged to deceive and manipulaterecipients. These deception and persuasion strategies can be applied to exertpower and amass capital in politics and business. In this work, we provide amodest review of how such deception and persuasion strategies were applied todifferent communication channels over the years. We provide examples ofcampaigns that has occurred in different periods over the last 100 years,together with their corresponding dissemination mediums. In the Internet age,we enjoy access to the vast amount of information and the ability tocommunicate without borders. However, malicious actors work toward abusingonline systems to disseminate disinformation, disrupt communication, andmanipulate people by the means of automated tools, such as social bots. It isimportant to study the old practices of persuasion to be able to investigatemodern practices and tools. Here we provide a discussion of current threatsagainst society while drawing parallels with the historical practices and therecent research efforts on systems of detection and prevention."
"33","arXiv:1906.11372","https://arxiv.org/abs/1906.11372","Incentive Mechanisms to Prevent Efficiency Loss of Non-Profit Utilities","Carlos Barreto, Eduardo Mojica-Nava, Nicanor Quijano","The modernization of the power system introduces technologies that mayimprove the system's efficiency by enhancing the capabilities of users. Despitetheir potential benefits, such technologies can have a negative impact. Thissubject has widely analyzed, mostly considering for-profit electric utilities.However, the literature has a gap regarding the impact of new technologies onnon-profit utilities.In this work, we quantify the price of anarchy of non-profit utilities, thatis, the cost caused by lack of coordination of users. We find that users, inthe worst case, can consume up to twice the optimal demand, obtaining a smallfraction of the optimal surplus. For this reason, we leverage the theory ofmechanism design to design an incentive scheme that reduces the inefficienciesof the system, which preserves the privacy of users. We illustrate withsimulations the efficiency loss of the system and show two instances ofincentive mechanism that satisfy either budget balance and budget deficit."
"34","arXiv:1906.11384","https://arxiv.org/abs/1906.11384","Eliciting Knowledge from Experts:Automatic Transcript Parsing for  Cognitive Task Analysis","Junyi Du, He Jiang, Jiaming Shen, Xiang Ren","Cognitive task analysis (CTA) is a type of analysis in applied psychologyaimed at eliciting and representing the knowledge and thought processes ofdomain experts. In CTA, often heavy human labor is involved to parse theinterview transcript into structured knowledge (e.g., flowchart for differentactions). To reduce human efforts and scale the process, automated CTAtranscript parsing is desirable. However, this task has unique challenges as(1) it requires the understanding of long-range context information inconversational text; and (2) the amount of labeled data is limited andindirect---i.e., context-aware, noisy, and low-resource. In this paper, wepropose a weakly-supervised information extraction framework for automated CTAtranscript parsing. We partition the parsing process into a sequence labelingtask and a text span-pair relation extraction task, with distant supervisionfrom human-curated protocol files. To model long-range context information forextracting sentence relations, neighbor sentences are involved as a part ofinput. Different types of models for capturing context dependency are thenapplied. We manually annotate real-world CTA transcripts to facilitate theevaluation of the parsing tasks"
"35","arXiv:1906.11385","https://arxiv.org/abs/1906.11385","A Tight Analysis of Greedy Yields Subexponential Time Approximation for  Uniform Decision Tree","Ray Li, Percy Liang, Stephen Mussmann","Decision Tree is a classic formulation of active learning: given $n$hypotheses with nonnegative weights summing to 1 and a set of tests that eachpartition the hypotheses, output a decision tree using the provided tests thatuniquely identifies each hypothesis and has minimum (weighted) average depth.Previous works showed that the greedy algorithm achieves a $O(\log n)$approximation ratio for this problem and it is NP-hard beat a $O(\log n)$approximation, settling the complexity of the problem. However, for UniformDecision Tree, i.e. Decision Tree with uniform weights, the story is moresubtle. The greedy algorithm's $O(\log n)$ approximation ratio is the bestknown, but the largest approximation ratio known to be NP-hard is$4-\varepsilon$. We prove that the greedy algorithm gives a $O(\frac{\logn}{\log C_{OPT}})$ approximation for Uniform Decision Tree, where $C_{OPT}$ isthe cost of the optimal tree and show this is best possible for the greedyalgorithm. As a corollary, this resolves a conjecture of Kosaraju, Przytycka,and Borgstrom. Our results also hold for instances of Decision Tree whoseweights are not too far from uniform. Leveraging this result, we exhibit asubexponential algorithm that yields an $O(1/\alpha)$ approximation to UniformDecision Tree in time $2^{O(n^\alpha)}$. As a corollary, achieving anysuper-constant approximation ratio on Uniform Decision Tree is not NP-hard,assuming the Exponential Time Hypothesis. This work therefore addsapproximating Uniform Decision Tree to a small list of natural problems thathave subexponential algorithms but no known polynomial time algorithms. Likethe greedy algorithm, our subexponential algorithm gives similar guaranteeseven for slightly nonuniform weights."
"36","arXiv:1906.11389","https://arxiv.org/abs/1906.11389","No Pressure! Addressing the Problem of Local Minima in Manifold Learning  Algorithms","Max Vladymyrov","Nonlinear embedding manifold learning methods provide invaluable visualinsights into a structure of high-dimensional data. However, due to acomplicated nonconvex objective function, these methods can easily get stuck inlocal minima and their embedding quality can be poor. We propose a naturalextension to several manifold learning methods aimed at identifying pressuredpoints, i.e. points stuck in the poor local minima and have poor embeddingquality. We show that the objective function can be decreased by temporarilyallowing these points to make use of an extra dimension in the embedding space.Our method is able to improve the objective function value of existing methodseven after they get stuck in a poor local minimum."
"37","arXiv:1906.11452","https://arxiv.org/abs/1906.11452","Traffic Management Strategies for Multi-Robotic Rigid Payload Transport  Systems","Yahnit Sirineni, Pulkit Verma, Kamalakar Karlapalem","In this work, we address traffic management of multiple payload transportsystems comprising of non-holonomic robots. We consider loosely coupled rigidrobot formations carrying a payload from one place to another. Each payloadtransport system (PTS) moves in various kinds of environments with obstacles.We ensure each PTS completes its given task by avoiding collisions with otherpayload systems and obstacles as well. Each PTS has one leader and multiplefollowers and the followers maintain a desired distance and angle with respectto the leader using a decentralized leader-follower control architecture whilemoving in the traffic. We showcase, through simulations the time taken by eachPTS to traverse its respective trajectory with and without other PTS andobstacles. We show that our strategies help manage the traffic for a largenumber of PTS moving from one place to another."
"38","arXiv:1906.11402","https://arxiv.org/abs/1906.11402","An Algorithm for Transmitting VR Video Based on Adaptive Modulation","Jie Feng, Yongpeng Wu, Guangtao Zhai, Ning Liu, Wenjun Zhang","Virtual reality (VR) is making waves around the world recently. However,traditional video streaming is not suitable for VR video because of the hugesize and view switch requirements of VR videos. Since the view of each user islimited, it is unnecessary to send the whole 360-degree scene at high qualitywhich can be a heavy burden for the transmission system. Assuming filed-of-view(FoV) of each user can be predicted with high probability, we can divide thevideo screen into partitions and send those partitions which will appear in FoVat high quality. Hence, we propose an novel strategy for VR video streaming.First, we define a quality-of-experience metric to measure the viewingexperience of users and define a channel model to reflect the fluctuation ofthe wireless channel. Next, we formulate the optimization problem and find itsfeasible solution by convex optimization. In order to improve bandwidthefficiency, we also add adaptive modulation to this part. Finally, we compareour algorithm with other VR streaming algorithm in the simulation. It turns outthat our algorithm outperforms other algorithms."
"39","arXiv:1906.11405","https://arxiv.org/abs/1906.11405","BioGen: Automated Biography Generation","Heer Ambavi, Ayush Garg, Ayush Garg, Nitiksha, Mridul Sharma, Rohit Sharma, Jayesh Choudhari, Mayank Singh","A biography of a person is the detailed description of several life eventsincluding his education, work, relationships, and death. Wikipedia, the freeweb-based encyclopedia, consists of millions of manually curated biographies ofeminent politicians, film and sports personalities, etc. However, manualcuration efforts, even though efficient, suffers from significant delays. Inthis work, we propose an automatic biography generation framework BioGen.BioGen generates a short collection of biographical sentences clustered intomultiple events of life. Evaluation results show that biographies generated byBioGen are significantly closer to manually written biographies in Wikipedia. Aworking model of this framework is available at nlpbiogen.herokuapp.com/home/."
"40","arXiv:1906.11407","https://arxiv.org/abs/1906.11407","Emergence of Exploratory Look-Around Behaviors through Active  Observation Completion","Santhosh K. Ramakrishnan, Dinesh Jayaraman, Kristen Grauman","Standard computer vision systems assume access to intelligently capturedinputs (e.g., photos from a human photographer), yet autonomously capturinggood observations is a major challenge in itself. We address the problem oflearning to look around: how can an agent learn to acquire informative visualobservations? We propose a reinforcement learning solution, where the agent isrewarded for reducing its uncertainty about the unobserved portions of itsenvironment. Specifically, the agent is trained to select a short sequence ofglimpses after which it must infer the appearance of its full environment. Toaddress the challenge of sparse rewards, we further introduce sidekick policylearning, which exploits the asymmetry in observability between training andtest time. The proposed methods learn observation policies that not onlyperform the completion task for which they are trained, but also generalize toexhibit useful ""look-around"" behavior for a range of active perception tasks."
"41","arXiv:1906.11409","https://arxiv.org/abs/1906.11409","Generalization of Dempster-Shafer theory: A complex belief function","Fuyuan Xiao","Dempster-Shafer evidence theory has been widely used in various fields ofapplications, because of the flexibility and effectiveness in modelinguncertainties without prior information. However, the existing evidence theoryis insufficient to consider the situations where it has no capability toexpress the fluctuations of data at a given phase of time during theirexecution, and the uncertainty and imprecision which are inevitably involved inthe data occur concurrently with changes to the phase or periodicity of thedata. In this paper, therefore, a generalized Dempster-Shafer evidence theoryis proposed. To be specific, a mass function in the generalized Dempster-Shaferevidence theory is modeled by a complex number, called as a complex basicbelief assignment, which has more powerful ability to express uncertaininformation. Based on that, a generalized Dempster's combination rule isexploited. In contrast to the classical Dempster's combination rule, thecondition in terms of the conflict coefficient between the evidences K<1 isreleased in the generalized Dempster's combination rule. Hence, it is moregeneral and applicable than the classical Dempster's combination rule. When thecomplex mass function is degenerated from complex numbers to real numbers, thegeneralized Dempster's combination rule degenerates to the classical evidencetheory under the condition that the conflict coefficient between the evidencesK is less than 1. In a word, this generalized Dempster-Shafer evidence theoryprovides a promising way to model and handle more uncertain information."
"42","arXiv:1906.11415","https://arxiv.org/abs/1906.11415","Few-Shot Video Classification via Temporal Alignment","Kaidi Cao, Jingwei Ji, Zhangjie Cao, Chien-Yi Chang, Juan Carlos Niebles","There is a growing interest in learning a model which could recognize novelclasses with only a few labeled examples. In this paper, we propose TemporalAlignment Module (TAM), a novel few-shot learning framework that can learn toclassify a previous unseen video. While most previous works neglect long-termtemporal ordering information, our proposed model explicitly leverages thetemporal ordering information in video data through temporal alignment. Thisleads to strong data-efficiency for few-shot learning. In concrete, TAMcalculates the distance value of query video with respect to novel classproxies by averaging the per frame distances along its alignment path. Weintroduce continuous relaxation to TAM so the model can be learned in anend-to-end fashion to directly optimize the few-shot learning objective. Weevaluate TAM on two challenging real-world datasets, Kinetics andSomething-Something-V2, and show that our model leads to significantimprovement of few-shot video classification over a wide range of competitivebaselines."
"43","arXiv:1906.11416","https://arxiv.org/abs/1906.11416","Clustering by the way of atomic fission","Shizhan Lu","Cluster analysis which focuses on the grouping and categorization of similarelements is widely used in various fields of research. Inspired by thephenomenon of atomic fission, a novel density-based clustering algorithm isproposed in this paper, called fission clustering (FC). It focuses on miningthe dense families of a dataset and utilizes the information of the distancematrix to fissure clustering dataset into subsets. When we face the datasetwhich has a few points surround the dense families of clusters, K-nearestneighbors local density indicator is applied to distinguish and remove thepoints of sparse areas so as to obtain a dense subset that is constituted bythe dense families of clusters. A number of frequently-used datasets were usedto test the performance of this clustering approach, and to compare the resultswith those of algorithms. The proposed algorithm is found to outperform otheralgorithms in speed and accuracy."
"44","arXiv:1906.11419","https://arxiv.org/abs/1906.11419","Automatic Coverage Selection for Surface-Based Visual Localization","James Mount, Les Dawes, Michael Milford","Localization is a critical capability for robots, drones and autonomousvehicles operating in a wide range of environments. One of the criticalconsiderations for designing, training or calibrating visual localizationsystems is the coverage of the visual sensors equipped on the platforms. In anaerial context for example, the altitude of the platform and camera field ofview plays a critical role in how much of the environment a downward facingcamera can perceive at any one time. Furthermore, in other applications, suchas on roads or in indoor environments, additional factors such as cameraresolution and sensor placement altitude can also affect this coverage. Thesensor coverage and the subsequent processing of its data also has significantcomputational implications. In this paper we present for the first time a setof methods for automatically determining the trade-off between coverage andvisual localization performance, enabling the identification of the minimumvisual sensor coverage required to obtain optimal localization performance withminimal compute. We develop a localization performance indicator based on theoverlapping coefficient, and demonstrate its predictive power for localizationperformance with a certain sensor coverage. We evaluate our method on severalchallenging real-world datasets from aerial and ground-based domains, anddemonstrate that our method is able to automatically optimize for coverageusing a small amount of calibration data. We hope these results will assist inthe design of localization systems for future autonomous robot, vehicle andflying systems."
"45","arXiv:1906.11421","https://arxiv.org/abs/1906.11421","FSM Error Messages","Marco T. Morazán (Seton Hall University), Josephine A. Des Rosiers (Seton Hall University)","Computer Science students, in general, find Automata Theory difficult andmostly unrelated to their area of study. To mitigate these perceptions, FSM, alibrary to program state machines and grammars, was developed to bringprogramming to the Automata Theory classroom. The results of the library'smaiden voyage at Seton Hall University had a positive impact on students, butthe students found the library difficult to use due to the error messagesgenerated. These messages were generated by the host language meaning thatstudents needed to be familiar with the library's implementation to make senseof them. This article presents the design of and results obtained from using anerror-messaging system tailor-made for FSM. The effectiveness of the librarywas measured by both a control group study and a survey. The results stronglysuggest that the error-messaging system has had a positive impact on students'attitude towards automata theory, towards programming in FSM, and towards FSMerror messages. The consequence has been a marked improvement on students'ability to implement algorithms developed as part of constructive proofs bymaking the debugging of FSM programs easier."
"46","arXiv:1906.11422","https://arxiv.org/abs/1906.11422","Stepping OCaml","Tsukino Furukawa (Ochanomizu University), Youyou Cong (Ochanomizu University), Kenichi Asai (Ochanomizu University)","Steppers, which display all the reduction steps of a given program, are anovice-friendly tool for understanding program behavior. Unfortunately,steppers are not as popular as they ought to be; indeed, the tool is onlyavailable in the pedagogical languages of the DrRacket programming environment.We present a stepper for a practical fragment of OCaml. Similarly to theDrRacket stepper, we keep track of evaluation contexts in order to reconstructthe whole program at each reduction step. The difference is that we supporteffectful constructs, such as exception handling and printing primitives,allowing the stepper to assist a wider range of users. In this paper, wedescribe the implementation of the stepper, share the feedback from ourstudents, and show an attempt at assessing the educational impact of ourstepper."
"47","arXiv:1906.11423","https://arxiv.org/abs/1906.11423","Vector Programming Using Generative Recursion","Marco T. Morazán (Seton Hall University)","Vector programming is an important topic in many Introduction to ComputerScience courses. Despite the importance of vectors, learning vector programmingis a source of frustration for many students. Much of the frustration is rootedin discovering the source of bugs that are manifested as out-of-boundsindexing. The problem is that such bugs are, sometimes, rooted in incorrectlycomputing an index. Other times, however, these errors are rooted in mistakenreasoning about how to correctly process a vector. Unfortunately, either way,all too often beginners are left adrift to resolve indexing errors on theirown. This article extends the work done on vector programming using vectorintervals and structural recursion to using generative recursion. As forproblems solved using structural recursion, vector intervals provide beginnerswith a useful framework for designing code that properly indexes vectors. Thisarticle presents the methodology and concrete examples that others may use tobuild their own CS1 modules involving vector programming using any programminglanguage."
"48","arXiv:1906.11425","https://arxiv.org/abs/1906.11425","Introducing Certified Compilation in Education by a Functional Language  Approach","Per Lindgren (Luleå University of Technology), Marcus Lindner (Luleå University of Technology), Nils Fitinghoff (Luleå University of Technology)","Classes on compiler technology are commonly found in Computer Sciencecurricula, covering aspects of parsing, semantic analysis, intermediatetransformations and target code generation. This paper reports on introducingcertified compilation techniques through a functional language approach in anintroductory course on Compiler Construction. Targeting students with little orno experience in formal methods, the proof process is highly automated usingthe Why3 framework. Underlying logic, semantic modelling and proofs areintroduced along with exercises and assignments leading up to a formallyverified compiler for a simplistic imperative language.This paper covers the motivation, course design, tool selection, and teachingmethods, together with evaluations and suggested improvements from theperspectives of both students and teachers."
"49","arXiv:1906.11427","https://arxiv.org/abs/1906.11427","Security of 5G-Mobile Backhaul Networks: A Survey","Gaurav Choudhary, Jiyoon Kim, Vishal Sharma","The rapid involution of the mobile generation with incipient data networkingcapabilities and utilization has exponentially increased the data trafficvolumes. Such traffic drains various key issues in 5G mobile backhaul networks.Security of mobile backhaul is of utmost importance; however, there are alimited number of articles, which have explored such a requirement. This paperdiscusses the potential design issues and key challenges of the secure 5Gmobile backhaul architecture. The comparisons of the existing state-of-the-artsolutions for secure mobile backhaul, together with their major contributionshave been explored. Furthermore, the paper discussed various key issues relatedto Quality of Service (QoS), routing and scheduling, resource management,capacity enhancement, latency, security-management, and handovers usingmechanisms like Software Defined Networking and millimeter Wave technologies.Moreover, the trails of research challenges and future directions areadditionally presented."
"50","arXiv:1906.11428","https://arxiv.org/abs/1906.11428","ELKPPNet: An Edge-aware Neural Network with Large Kernel Pyramid Pooling  for Learning Discriminative Features in Semantic Segmentation","Xianwei Zheng, Linxi Huan, Hanjiang Xiong, Jianya Gong","Semantic segmentation has been a hot topic across diverse research fields.Along with the success of deep convolutional neural networks, semanticsegmentation has made great achievements and improvements, in terms of bothurban scene parsing and indoor semantic segmentation. However, most of thestate-of-the-art models are still faced with a challenge in discriminativefeature learning, which limits the ability of a model to detect multi-scaleobjects and to guarantee semantic consistency inside one object or distinguishdifferent adjacent objects with similar appearance. In this paper, a practicaland efficient edge-aware neural network is presented for semantic segmentation.This end-to-end trainable engine consists of a new encoder-decoder network, alarge kernel spatial pyramid pooling (LKPP) block, and an edge-aware lossfunction. The encoder-decoder network was designed as a balanced structure tonarrow the semantic and resolution gaps in multi-level feature aggregation,while the LKPP block was constructed with a densely expanding receptive fieldfor multi-scale feature extraction and fusion. Furthermore, the new powerfuledge-aware loss function is proposed to refine the boundaries directly from thesemantic segmentation prediction for more robust and discriminative features.The effectiveness of the proposed model was demonstrated using Cityscapes,CamVid, and NYUDv2 benchmark datasets. The performance of the two structuresand the edge-aware loss function in ELKPPNet was validated on the Cityscapesdataset, while the complete ELKPPNet was evaluated on the CamVid and NYUDv2datasets. A comparative analysis with the state-of-the-art methods under thesame conditions confirmed the superiority of the proposed algorithm."
"51","arXiv:1906.11431","https://arxiv.org/abs/1906.11431","User Validation of Recommendation Serendipity Metrics","Li Chen, Ningxia Wang, Yonghua Yang, Keping Yang, Quan Yuan","Though it has been recognized that recommending serendipitous (i.e.,surprising and relevant) items can be helpful for increasing users'satisfaction and behavioral intention, how to measure serendipity in theoffline environment is still an open issue. In recent years, a number ofmetrics have been proposed, but most of them were based on researchers'assumptions due to the serendipity's subjective nature. In order to validatethese metrics' actual performance, we collected over 10,000 users' realfeedback data and compared with the metrics' results. It turns out the userprofile based metrics, especially content-based ones, perform better than thosebased on item popularity, in terms of estimating the unexpectedness facet ofrecommendations. Moreover, the full metrics, which involve the unexpectednesscomponent, relevance, timeliness, and user curiosity, can more accuratelyindicate the recommendation's serendipity degree, relative to those that justinvolve some of them. The application of these metrics to several recommenderalgorithms further consolidates their practical usage, because the comparisonresults are consistent with those from user evaluation. Thus, this work isconstructive for filling the gap between offline measurement and user study onrecommendation serendipity."
"52","arXiv:1906.11432","https://arxiv.org/abs/1906.11432","An Approach for Reviewing Security-Related Aspects in Agile Requirements  Specifications of Web Applications","H. Villamizar, A. A. Neto, M. Kalinowski, A. Garcia, D. Mendez Fernández","Defects in requirements specifications can have severe consequences duringthe software development lifecycle. Some of them result in overall projectfailure due to incorrect or missing quality characteristics such as security.There are several concerns that make security difficult to deal with; forinstance, (1) when stakeholders discuss general requirements in (review)meetings, they are often not aware that they should also discusssecurity-related topics, and (2) they typically do not have enough securityexpertise. These concerns become even more challenging in agile developmentcontexts, where lightweight documentation is typically involved. The goal ofthis paper is to design and evaluate an approach to support reviewingsecurity-related aspects in agile requirements specifications of webapplications. The designed approach considers user stories and securityspecifications as input and relates those user stories to security propertiesvia Natural Language Processing (NLP) techniques. Based on the related securityproperties, our approach then identifies high-level security requirements fromthe Open Web Application Security Project (OWASP) to be verified and generatesa focused reading techniques to support reviewers in detecting detects. Weevaluate our approach via two controlled experiment trials, comparing theeffectiveness and efficiency of novice inspectors verifying security aspects inagile requirements using our reading technique against using the complete listof OWASP high-level security requirements. The (statistically significant)results indicate that using the reading technique has a positive impact (withvery large effect size) on the performance of inspectors in terms ofeffectiveness and efficiency."
"53","arXiv:1906.11435","https://arxiv.org/abs/1906.11435","DeepVIO: Self-supervised Deep Learning of Monocular Visual Inertial  Odometry using 3D Geometric Constraints","Liming Han, Yimin Lin, Guoguang Du, Shiguo Lian","This paper presents an self-supervised deep learning network for monocularvisual inertial odometry (named DeepVIO). DeepVIO provides absolute trajectoryestimation by directly merging 2D optical flow feature (OFF) and InertialMeasurement Unit (IMU) data. Specifically, it firstly estimates the depth anddense 3D point cloud of each scene by using stereo sequences, and then obtains3D geometric constraints including 3D optical flow and 6-DoF pose assupervisory signals. Note that such 3D optical flow shows robustness andaccuracy to dynamic objects and textureless environments. In DeepVIO training,2D optical flow network is constrained by the projection of its corresponding3D optical flow, and LSTM-style IMU preintegration network and the fusionnetwork are learned by minimizing the loss functions from ego-motionconstraints. Furthermore, we employ an IMU status update scheme to improve IMUpose estimation through updating the additional gyroscope and accelerometerbias. The experimental results on KITTI and EuRoC datasets show that DeepVIOoutperforms state-of-the-art learning based methods in terms of accuracy anddata adaptability. Compared to the traditional methods, DeepVIO reduces theimpacts of inaccurate Camera-IMU calibrations, unsynchronized and missing data."
"54","arXiv:1906.11455","https://arxiv.org/abs/1906.11455","PKUSEG: A Toolkit for Multi-Domain Chinese Word Segmentation","Ruixuan Luo, Jingjing Xu, Yi Zhang, Xuancheng Ren, Xu Sun","Chinese word segmentation (CWS) is a fundamental step of Chinese naturallanguage processing. In this paper, we build a new toolkit, named PKUSEG, formulti-domain word segmentation. Unlike existing single-model toolkits, PKUSEGtargets at multi-domain word segmentation and provides separate models fordifferent domains, such as web, medicine, and tourism. The new toolkit alsosupports POS tagging and model training to adapt to various applicationscenarios. Experiments show that PKUSEG achieves high performance on multipledomains. The toolkit is now freely and publicly available for the usage ofresearch and industry."
"55","arXiv:1906.11436","https://arxiv.org/abs/1906.11436","Adaptive First-Order System Least-Squares Finite Element Methods for  Second Order Elliptic Equations in Non-Divergence Form","Weifeng Qiu, Shun Zhang","This paper studies adaptive first-order least-squares finite element methodsfor second-order elliptic partial differential equations in non-divergenceform. Unlike the classical finite element method which uses weak formulationsof PDEs not applicable for the non-divergence equation, the first-orderleast-squares formulations naturally have stable weak forms without usingintegration by parts, allow simple finite element approximation spaces, andhave build-in a posteriori error estimators for adaptive mesh refinements.The non-divergence equation is first written as a system of first-orderequations by introducing the gradient as a new variable. Then two versions ofleast-squares finite element methods using simple $C^0$ finite elements aredeveloped in the paper, one is the $L^2$-LSFEM which uses linear elements, theother is the weighted-LSFEM with a mesh-dependent weight to ensure the optimalconvergence. Under a very mild assumption that the PDE has a unique solution,optimal a priori and a posteriori error estimates are proved. With an extraassumption on the operator regularity which is weaker than traditionallyassumed, convergences in standard norms for the weighted-LSFEM are alsodiscussed. $L^2$-error estimates are derived for both formulations. We performextensive numerical experiments for smooth, non-smooth, and even degeneratecoefficients on smooth and singular solutions to test the accuracy andefficiency of the proposed methods."
"56","arXiv:1906.11437","https://arxiv.org/abs/1906.11437","Hard Pixels Mining: Learning Using Privileged Information for Semantic  Segmentation","Zhangxuan Gu, Li Niu, Liqing Zhang","Semantic segmentation has achieved significant progress but is stillchallenging due to the complex scene, object occlusion, and so on. Someresearch works have attempted to use extra information such as depthinformation to help RGB based semantic segmentation. However, extra informationis usually unavailable for the test images. Inspired by learning usingprivileged information, in this paper, we only leverage the depth informationof training images as privileged information in the training stage.Specifically, we rely on depth information to identify the hard pixels whichare difficult to classify, by using our proposed Depth Prediction Error (DPE)and Depth-dependent Segmentation Error (DSE). By paying more attention to theidentified hard pixels, our approach achieves the state-of-the-art results ontwo benchmark datasets and even outperforms the methods which use depthinformation of test images."
"57","arXiv:1906.11441","https://arxiv.org/abs/1906.11441","Distributed Clustering in the Anonymized Space with Local Differential  Privacy","Lin Sun, Jun Zhao, Xiaojun Ye","Clustering and analyzing on collected data can improve user experiences andquality of services in big data, IoT applications. However, directly releasingoriginal data brings potential privacy concerns, which raises challenges andopportunities for privacy-preserving clustering. In this paper, we study theproblem of non-interactive clustering in distributed setting under theframework of local differential privacy. We first extend the Bit Vector, anovel anonymization mechanism to be functionality-capable andprivacy-preserving. Based on the modified encoding mechanism, we proposekCluster algorithm that can be used for clustering in the anonymized space. Weshow the modified encoding mechanism can be easily implemented in existingclustering algorithms that only rely on distance information, such as DBSCAN.Theoretical analysis and experimental results validate the effectiveness of theproposed schemes."
"58","arXiv:1906.11443","https://arxiv.org/abs/1906.11443","Region Refinement Network for Salient Object Detection","Zhuotao Tian, Hengshuang Zhao, Michelle Shu, Jiaze Wang, Ruiyu Li, Xiaoyong Shen, Jiaya Jia","Albeit intensively studied, false prediction and unclear boundaries are stillmajor issues of salient object detection. In this paper, we propose a RegionRefinement Network (RRN), which recurrently filters redundant information andexplicitly models boundary information for saliency detection. Different fromexisting refinement methods, we propose a Region Refinement Module (RRM) thatoptimizes salient region prediction by incorporating supervised attention masksin the intermediate refinement stages. The module only brings a minor increasein model size and yet significantly reduces false predictions from thebackground. To further refine boundary areas, we propose a Boundary RefinementLoss (BRL) that adds extra supervision for better distinguishing foregroundfrom background. BRL is parameter free and easy to train. We further observethat BRL helps retain the integrity in prediction by refining the boundary.Extensive experiments on saliency detection datasets show that our refinementmodule and loss bring significant improvement to the baseline and can be easilyapplied to different frameworks. We also demonstrate that our proposed modelgeneralizes well to portrait segmentation and shadow detection tasks."
"59","arXiv:1906.11447","https://arxiv.org/abs/1906.11447","Improved Upper Bounds on the Growth Constants of Polyominoes and  Polycubes","Gill Barequet, Mira Shalah","A $d$-dimensional polycube is a facet-connected set of cells (cubes) on the$d$-dimensional cubical lattice~$\mathbb{Z}^d$. Let~$A_d(n)$ denote the numberof $d$-dimensional polycubes (distinct up to translations) with~$n$ cubes,and~$\lambda_d$ denote the limit of the ratio~$A_d(n{+}1)/A_d(n)$ as~$n \to\infty$. The exact value of~$\lambda_d$ is still unknown rigorously for anydimension~$d \geq 2$; the asymptotics of~$\lambda_d$, as~$d \to \infty$, alsoremained elusive as of today. In this paper, we revisit and extend the approachpresented by Klarner and Rivest in~1973 to bound $A_2(n)$ from above. Ourcontributions are: Using available computing power, we prove that~$\lambda_2\leq 4.5252$. This is the first improvement of the upper bound on~$\lambda_2$in almost half a century; We prove that~$\lambda_d \leq (2d-2)e+o(1)$ for anyvalue of~$d \geq 2$, using a novel construction of a rational generatingfunction which dominates that of the sequence~$\left(A_d(n)\right)$; For $d=3$,this provides a subtantial improvement of the upper bound on~$\lambda_3$from~12.2071 to~9.8073;%~10.016; However, we implement an iterative process inthree dimensions, which improves further the upper boundon~$\lambda_3$to~$9.3835$;"
"60","arXiv:1906.11450","https://arxiv.org/abs/1906.11450","Investigating Compilation Errors of Students Learning Haskell","Boldizsár Németh (Eötvös Loránd University), Eunjong Choi (Nara Institute of Science and Technology), Erina Makihara (Nara Institute of Science and Technology), Hajimu Iida (Nara Institute of Science and Technology)","While functional programming is an efficient way to express complex software,functional programming languages have a steep learning curve. Haskell can bechallenging to learn for students who were only introduced to imperativeprogramming. It is important to look for methods and tools that may reduce thedifficulty of learning functional programming. Finding methods to help studentsrequires understanding the errors that students make while learning Haskell.There are several previous studies revealing data about Haskell compilererrors, but they do not focus on the analysis of the compiler errors or theyonly study a certain kind of compiler errors.This study investigates compilation errors of novice Haskell students andmake suggestions on how their learning efficiency can be improved. Unlikeprevious studies we focus on uncovering the root problems with the studentsolutions by analysing samples of their submissions."
"61","arXiv:1906.11456","https://arxiv.org/abs/1906.11456","Enhancing Python Compiler Error Messages via Stack Overflow","Emillie Thiselton, Christoph Treude","Background: Compilers tend to produce cryptic and uninformative errormessages, leaving programmers confused and requiring them to spend precioustime to resolve the underlying error. To find help, programmers often take toonline question-and-answer forums such as Stack Overflow to start discussionthreads about the errors they encountered.Aims: We conjecture that information from Stack Overflow threads whichdiscuss compiler errors can be automatically collected and repackaged toprovide programmers with enhanced compiler error messages, thus savingprogrammers' time and energy.Method: We present Pycee, a plugin integrated with the popular Sublime TextIDE to provide enhanced compiler error messages for the Python programminglanguage. Pycee automatically queries Stack Overflow to provide customised andsummarised information within the IDE. We evaluated two Pycee variants througha think-aloud user study during which 16 programmers completed Pythonprogramming tasks while using Pycee.Results: The majority of participants agreed that Pycee was helpful whilecompleting the study tasks. When compared to a baseline relying on the officialPython documentation to enhance compiler error messages, participants generallypreferred Pycee in terms of helpfulness, citing concrete suggestions for fixesand example code as major benefits.Conclusions: Our results confirm that data from online sources such as StackOverflow can be successfully used to automatically enhance compiler errormessages. Our work opens up venues for future work to further enhance compilererror messages as well as to automatically reuse content from Stack Overflowfor other aspects of programming."
"62","arXiv:1906.11461","https://arxiv.org/abs/1906.11461","A Trust Architecture for Blockchain in IoT","Volkan Dedeoglu, Raja Jurdak, Guntur D. Putra, Ali Dorri, Salil S. Kanhere","Blockchain is a promising technology for establishing trust in IoT networks,where network nodes do not necessarily trust each other. Cryptographic hashlinks and distributed consensus mechanisms ensure that the data stored on animmutable blockchain can not be altered or deleted. However, blockchainmechanisms do not guarantee the trustworthiness of data at the origin. Wepropose a layered architecture for improving the end-to-end trust that can beapplied to a diverse range of blockchain-based IoT applications. Ourarchitecture evaluates the trustworthiness of sensor observations at the datalayer and adapts block verification at the blockchain layer through theproposed data trust and gateway reputation modules. We present the performanceevaluation of the data trust module using a simulated indoor targetlocalization and the gateway reputation module using an end-to-end blockchainimplementation, together with a qualitative security analysis for thearchitecture."
"63","arXiv:1906.11462","https://arxiv.org/abs/1906.11462","Toward Simulating Environments in Reinforcement Learning Based  Recommendations","Xiangyu Zhao, Long Xia, Zhuoye Ding, Dawei Yin, Jiliang Tang","With the recent advances in Reinforcement Learning (RL), there have beentremendous interests in employing RL for recommender systems. RL-basedrecommender systems have two key advantages: (i) they can continuously updatetheir recommendation strategies according to users' real-time feedback, and(ii) the optimal strategy maximizes the long-term reward from users, such asthe total revenue of a recommendation session. However, directly training andevaluating a new RL-based recommendation algorithm needs to collect users'real-time feedback in the real system, which is time and efforts consuming andcould negatively impact on users' experiences. Thus, it calls for a usersimulator that can mimic real users' behaviors where we can pre-train andevaluate new recommendation algorithms. Simulating users' behaviors in adynamic system faces immense challenges -- (i) the underlining itemdistribution is complex, and (ii) historical logs for each user are limited. Inthis paper, we develop a user simulator base on Generative Adversarial Network(GAN). To be specific, we design the generator to capture the underliningdistribution of users' historical logs and generate realistic logs that can beconsidered as augmentations of real logs; while the discriminator is developedto not only distinguish real and fake logs but also predict users' behaviors.The experimental results based on real-world e-commerce data demonstrate theeffectiveness of the proposed simulator. Further experiments have beenconducted to understand the importance of each component in the simulator."
"64","arXiv:1906.11463","https://arxiv.org/abs/1906.11463","Automatic Colon Polyp Detection using Region based Deep CNN and Post  Learning Approaches","Younghak Shin, Hemin Ali Qadir, Lars Aabakken, Jacob Bergsland, Ilangko Balasingham","Automatic detection of colonic polyps is still an unsolved problem due to thelarge variation of polyps in terms of shape, texture, size, and color, and theexistence of various polyp-like mimics during colonoscopy. In this study, weapply a recent region based convolutional neural network (CNN) approach for theautomatic detection of polyps in images and videos obtained from colonoscopyexaminations. We use a deep-CNN model (Inception Resnet) as a transfer learningscheme in the detection system. To overcome the polyp detection obstacles andthe small number of polyp images, we examine image augmentation strategies fortraining deep networks. We further propose two efficient post-learning methodssuch as, automatic false positive learning and off-line learning, both of whichcan be incorporated with the region based detection system for reliable polypdetection. Using the large size of colonoscopy databases, experimental resultsdemonstrate that the suggested detection systems show better performancecompared to other systems in the literature. Furthermore, we show improveddetection performance using the proposed post-learning schemes for colonoscopyvideos."
"65","arXiv:1906.11465","https://arxiv.org/abs/1906.11465","Loss Switching Fusion with Similarity Search for Video Classification","Lei Wang, Du Q. Huynh, Moussa Reda Mansour","From video streaming to security and surveillance applications, video dataplay an important role in our daily living today. However, managing a largeamount of video data and retrieving the most useful information for the userremain a challenging task. In this paper, we propose a novel videoclassification system that would benefit the scene understanding task. Wedefine our classification problem as classifying background and foregroundmotions using the same feature representation for outdoor scenes. This meansthat the feature representation needs to be robust enough and adaptable todifferent classification tasks. We propose a lightweight Loss Switching FusionNetwork (LSFNet) for the fusion of spatiotemporal descriptors and a similaritysearch scheme with soft voting to boost the classification performance. Theproposed system has a variety of potential applications such as content-basedvideo clustering, video filtering, etc. Evaluation results on two privateindustry datasets show that our system is robust in both classifying differentbackground motions and detecting human motions from these background motions."
"66","arXiv:1906.11467","https://arxiv.org/abs/1906.11467","Abnormal Colon Polyp Image Synthesis Using Conditional Adversarial  Networks for Improved Detection Performance","Younghak Shin, Hemin Ali Qadir, Ilangko Balasingham","One of the major obstacles in automatic polyp detection during colonoscopy isthe lack of labeled polyp training images. In this paper, we propose aframework of conditional adversarial networks to increase the number oftraining samples by generating synthetic polyp images. Using a normal binaryform of polyp mask which represents only the polyp position as an inputconditioned image, realistic polyp image generation is a difficult task in agenerative adversarial networks approach. We propose an edge filtering-basedcombined input conditioned image to train our proposed networks. This enablesrealistic polyp image generations while maintaining the original structures ofthe colonoscopy image frames. More importantly, our proposed frameworkgenerates synthetic polyp images from normal colonoscopy images which have theadvantage of being relatively easy to obtain. The network architecture is basedon the use of multiple dilated convolutions in each encoding part of ourgenerator network to consider large receptive fields and avoid manycontractions of a feature map size. An image resizing with convolution forupsampling in the decoding layers is considered to prevent artifacts ongenerated images. We show that the generated polyp images are not onlyqualitatively realistic but also help to improve polyp detection performance."
"67","arXiv:1906.11470","https://arxiv.org/abs/1906.11470","Automatically Extract the Semi-transparent Motion-blurred Hand from a  Single Image","Xiaomei Zhao, Yihong Wu","When we use video chat, video game, or other video applications,motion-blurred hands often appear. Accurately extracting these hands is veryuseful for video editing and behavior analysis. However, existingmotion-blurred object extraction methods either need user interactions, such asuser supplied trimaps and scribbles, or need additional information, such asbackground images. In this paper, a novel method which can automaticallyextract the semi-transparent motion-blurred hand just according to the originalRGB image is proposed. The proposed method separates the extraction task intotwo subtasks: alpha matte prediction and foreground prediction. These twosubtasks are implemented by Xception based encoder-decoder networks. Theextracted motion-blurred hand images can be calculated by multiplying thepredicted alpha mattes and foreground images. Experiments on synthetic and realdatasets show that the proposed method has promising performance."
"68","arXiv:1906.11475","https://arxiv.org/abs/1906.11475","Further Results on Stability-Preserving Mechanisms for School Choice","Karthik Gajulapalli, James A. Liu, Vijay V. Vazirani","We build on the stability-preserving school choice model introduced andstudied recently in [MV18]. We settle several of their open problems and wedefine and solve a couple of new ones."
"69","arXiv:1906.11478","https://arxiv.org/abs/1906.11478","A Convolutional Decoder for Point Clouds using Adaptive Instance  Normalization","Isaak Lim, Moritz Ibing, Leif Kobbelt","Automatic synthesis of high quality 3D shapes is an ongoing and challengingarea of research. While several data-driven methods have been proposed thatmake use of neural networks to generate 3D shapes, none of them reach the levelof quality that deep learning synthesis approaches for images provide. In thiswork we present a method for a convolutional point cloud decoder/generator thatmakes use of recent advances in the domain of image synthesis. Namely, we useAdaptive Instance Normalization and offer an intuition on why it can improvetraining. Furthermore, we propose extensions to the minimization of thecommonly used Chamfer distance for auto-encoding point clouds. In addition, weshow that careful sampling is important both for the input geometry and in ourpoint cloud generation process to improve results. The results are evaluated inan auto-encoding setup to offer both qualitative and quantitative analysis. Theproposed decoder is validated by an extensive ablation study and is able tooutperform current state of the art results in a number of experiments. We showthe applicability of our method in the fields of point cloud upsampling, singleview reconstruction, and shape synthesis."
"70","arXiv:1906.11479","https://arxiv.org/abs/1906.11479","Deep Siamese Multi-scale Convolutional Network for Change Detection in  Multi-temporal VHR Images","Hongruixuan Chen, Chen Wu, Bo Du, Liangpei Zhang","Very high resolution (VHR) images provide abundant ground details and spatialdistribution information. Change detection in multi-temporal VHR images plays asignificant role in urban expansion and area internal change analysis.Nevertheless, traditional change detection methods can neither take fulladvantage of spatial context information nor cope with the complex internalheterogeneity of VHR images. In this paper, we propose a powerful multi-scalefeature convolution unit (MFCU) for change detection in VHR images. Theproposed unit is able to extract multi-scale features in the same layer. Basedon the proposed unit, two novel deep Siamese convolutional networks, deepSiamese multi-scale convolutional network (DSMS-CN) and deep Siamesemulti-scale fully convolutional network (DSMS-FCN), are designed forunsupervised and supervised change detection in multi-temporal VHR images. Forunsupervised change detection, we implement automatic pre-classification toobtain training patch samples, and the DSMS-CN fits the statisticaldistribution of changed and unchanged area from patch samples throughmulti-scale feature extraction module and deep Siamese architecture. Forsupervised change detection, the end-to-end deep fully convolutional networkDSMS-FCN is trained in any size of multi-temporal VHR images, and directlyoutput the binary change map. In addition, for the purpose of solving theinaccurate localization problem, the fully connected conditional random field(FC-CRF) is combined with DSMS-FCN to refine the results. The experimentalresults with challenging data sets confirm that the two proposed architecturesperform better than the state-of-the-art methods."
"71","arXiv:1906.11483","https://arxiv.org/abs/1906.11483","Morphological Irregularity Correlates with Frequency","Shijie Wu, Ryan Cotterell, Timothy J. O'Donnell","We present a study of morphological irregularity. Following recent work, wedefine an information-theoretic measure of irregularity based on thepredictability of forms in a language. Using a neural transduction model, weestimate this quantity for the forms in 28 languages. We first present severalvalidatory and exploratory analyses of irregularity. We then show that ouranalyses provide evidence for a correlation between irregularity and frequency:higher frequency items are more likely to be irregular and irregular items aremore likely be highly frequent. To our knowledge, this result is the first ofits breadth and confirms longstanding proposals from the linguisticsliterature. The correlation is more robust when aggregated at the level ofwhole paradigms--providing support for models of linguistic structure in whichinflected forms are unified by abstract underlying stems or lexemes. Code isavailable at https://github.com/shijie-wu/neural-transducer."
"72","arXiv:1906.11484","https://arxiv.org/abs/1906.11484","Automated Segmentation of Hip and Thigh Muscles in Metal  Artifact-Contaminated CT using Convolutional Neural Network-Enhanced  Normalized Metal Artifact Reduction","Mitsuki Sakamoto, Yuta Hiasa, Yoshito Otake, Masaki Takao, Yuki Suzuki, Nobuhiko Sugano, Yoshinobu Sato","In total hip arthroplasty, analysis of postoperative medical images isimportant to evaluate surgical outcome. Since Computed Tomography (CT) is mostprevalent modality in orthopedic surgery, we aimed at the analysis of CT image.In this work, we focus on the metal artifact in postoperative CT caused by themetallic implant, which reduces the accuracy of segmentation especially in thevicinity of the implant. Our goal was to develop an automated segmentationmethod of the bones and muscles in the postoperative CT images. We propose amethod that combines Normalized Metal Artifact Reduction (NMAR), which is oneof the state-of-the-art metal artifact reduction methods, and a ConvolutionalNeural Network-based segmentation using two U-net architectures. The firstU-net refines the result of NMAR and the muscle segmentation is performed bythe second U-net. We conducted experiments using simulated images of 20patients and real images of three patients to evaluate the segmentationaccuracy of 19 muscles. In simulation study, the proposed method showedstatistically significant improvement (p<0.05) in the average symmetric surfacedistance (ASD) metric for 14 muscles out of 19 muscles and the average ASD ofall muscles from 1.17 +/- 0.543 mm (mean +/- std over all patients) to 1.10 +/-0.509 mm over our previous method. The real image study using the manual traceof gluteus maximus and medius muscles showed ASD of 1.32 +/- 0.25 mm. Ourfuture work includes training of a network in an end-to-end manner for both themetal artifact reduction and muscle segmentation."
"73","arXiv:1906.11485","https://arxiv.org/abs/1906.11485","Semantic Preserving Bijective Mappings for Expressions involving Special  Functions in Computer Algebra Systems and Document Preparation Systems","Andre Greiner-Petter, Moritz Schubotz, Howard S. Cohl, Bela Gipp","Purpose: Modern mathematicians and scientists of math-related disciplinesoften use Document Preparation Systems (DPS) to write and Computer AlgebraSystems (CAS) to calculate mathematical expressions. Usually, they translatethe expressions manually between DPS and CAS. This process is time-consumingand error-prone. Our goal is to automate this translation. This paper usesMaple and Mathematica as the CAS, and LaTeX as our DPS.Design/methodology/approach: Bruce Miller at the National Institute ofStandards and Technology (NIST) developed a collection of special LaTeX macrosthat create links from mathematical symbols to their definitions in the NISTDigital Library of Mathematical Functions (DLMF). We are using these macros toperform rule-based translations between the formulae in the DLMF and CAS.Moreover, we develop software to ease the creation of new rules and to discoverinconsistencies.Findings: We created 396 mappings and translated 58.8% of DLMF formulae(2,405 expressions) successfully between Maple and DLMF. For a significantpercentage, the special function definitions in Maple and the DLMF weredifferent. Therefore, an atomic symbol in one system maps to a compositeexpression in the other system. The translator was also successfully used forautomatic verification of mathematical online compendia and CAS. Our evaluationtechniques discovered two errors in the DLMF and one defect in Maple.Originality: This paper introduces the first translation tool for specialfunctions between LaTeX and CAS. The approach improves error-prone manualtranslations and can be used to verify mathematical online compendia and CAS."
"74","arXiv:1906.11488","https://arxiv.org/abs/1906.11488","Finding Security Vulnerabilities in Unmanned Aerial Vehicles Using  Software Verification","Omar M. Alhawi, Mustafa A. Mustafa, Lucas C. Cordeiro","The proliferation of Unmanned Aerial Vehicles (UAVs) embedded with vulnerablemonolithic software, involving concurrency and fragile communication links, hasrecently raised serious concerns about their security. Recent studies show thata 2kg UAV can cause a critical damage to a passenger jet windscreen. However,verifying security in UAV software based on traditional testing remains an openchallenge mainly due to scalability and deployment issue. Here we investigatethe application of software verification techniques; in particular, existingsoftware analyzers and verifiers, which implement fuzzing and bounded modelchecking techniques, to detect security vulnerabilities in typical UAVs. Wealso investigate fragility aspects related to the UAV communication link sinceall remaining UAV components (e.g., position, velocity and attitude control)heavily depend on it. Our preliminary results show real cyber-threats with thepossibility of exploiting further security vulnerabilities in real-world UAVsoftware in the foreseeable future."
"75","arXiv:1906.11507","https://arxiv.org/abs/1906.11507","An Empirical Study of Information Flows in Real-World JavaScript","Cristian-Alexandru Staicu, Daniel Schoepe, Musard Balliu, Michael Pradel, Andrei Sabelfeld","Information flow analysis prevents secret or untrusted data from flowing intopublic or trusted sinks. Existing mechanisms cover a wide array of options,ranging from lightweight taint analysis to heavyweight information flow controlthat also considers implicit flows. Dynamic analysis, which is particularlypopular for languages such as JavaScript, faces the question whether to investin analyzing flows caused by not executing a particular branch, so-calledhidden implicit flows. This paper addresses the questions how common differentkinds of flows are in real-world programs, how important these flows are toenforce security policies, and how costly it is to consider these flows. Weaddress these questions in an empirical study that analyzes 56 real-worldJavaScript programs that suffer from various security problems, such as codeinjection vulnerabilities, denial of service vulnerabilities, memory leaks, andprivacy leaks. The study is based on a state-of-the-art dynamic informationflow analysis and a formalization of its core. We find that implicit flows areexpensive to track in terms of permissiveness, label creep, and runtimeoverhead. We find a lightweight taint analysis to be sufficient for most of thestudied security problems, while for some privacy-related code, observabletracking is sometimes required. In contrast, we do not find any evidence thattracking hidden implicit flows reveals otherwise missed security problems. Ourresults help security analysts and analysis designers to understand thecost-benefit tradeoffs of information flow analysis and provide empiricalevidence that analyzing implicit flows in a cost-effective way is a relevantproblem."
"76","arXiv:1906.11613","https://arxiv.org/abs/1906.11613","Mind2Mind : transfer learning for GANs","Yaël Frégier, Jean-Baptiste Gouray","We propose an approach for transfer learning with GAN architectures. Ingeneral, transfer learning enables deep networks for classification tasks to betrained with limited computing and data resources. However a similar approachis missing in the specific context of generative tasks. This is partly due tothe fact that the extremal layers of the two networks of a GAN, which should belearned during transfer, are on two opposite sides. This requiresback-propagating information through both networks, which is computationallyexpensive. We develop a method to directly train these extremal layers againsteach other, by-passing all the intermediate layers. We also prove rigorously,for Wasserstein GANs, a theorem ensuring the convergence of the learning of thetransferred GAN. Finally, we compare our method to state-of-the-art methods andshow that our method converges much faster and requires less data."
"77","arXiv:1906.11508","https://arxiv.org/abs/1906.11508","Reducing Spreading Processes on Networks to Markov Population Models","Gerrit Großmann, Luca Bortolussi","Stochastic processes on complex networks, where each node is in one ofseveral compartments, and neighboring nodes interact with each other, can beused to describe a variety of real-world spreading phenomena. However,computational analysis of such processes is hindered by the enormous size oftheir underlying state space.In this work, we demonstrate that lumping can be used to reduce any epidemicmodel to a Markov Population Model (MPM). Therefore, we propose a novel lumpingscheme based on a partitioning of the nodes. By imposing different types ofcounting abstractions, we obtain coarse-grained Markov models with a naturalMPM representation that approximate the original systems. This makes itpossible to transfer the rich pool of approximation techniques developed forMPMs to the computational analysis of complex networks' dynamics.We present numerical examples to investigate the relationship between theaccuracy of the MPMs, the size of the lumped state space, and the type ofcounting abstraction."
"78","arXiv:1906.11511","https://arxiv.org/abs/1906.11511","Inducing Syntactic Trees from BERT Representations","Rudolf Rosa, David Mareček","We use the English model of BERT and explore how a deletion of one word in asentence changes representations of other words. Our hypothesis is thatremoving a reducible word (e.g. an adjective) does not affect therepresentation of other words so much as removing e.g. the main verb, whichmakes the sentence ungrammatical and of ""high surprise"" for the language model.We estimate reducibilities of individual words and also of longer continuousphrases (word n-grams), study their syntax-related properties, and then alsouse them to induce full dependency trees."
"79","arXiv:1906.11518","https://arxiv.org/abs/1906.11518","A Survey and Experimental Analysis of Distributed Subgraph Matching","Longbin Lai, Zhu Qing, Zhengyi Yang, Xin Jin, Zhengmin Lai, Ran Wang, Kongzhang Hao, Xuemin Lin, Lu Qin, Wenjie Zhang, Ying Zhang, Zhengping Qian, Jingren Zhou","Recently there emerge many distributed algorithms that aim at solvingsubgraph matching at scale. Existing algorithm-level comparisons failed toprovide a systematic view to the pros and cons of each algorithm mainly due tothe intertwining of strategy and optimization. In this paper, we identify fourstrategies and three general-purpose optimizations from representativestate-of-the-art works. We implement the four strategies with the optimizationsbased on the common Timely dataflow system for systematic strategy-levelcomparison. Our implementation covers all representation algorithms. We conductextensive experiments for both unlabelled matching and labelled matching toanalyze the performance of distributed subgraph matching under varioussettings, which is finally summarized as a practical guide."
"80","arXiv:1906.11520","https://arxiv.org/abs/1906.11520","Flexible Anonymous Network","Florentin Rochet, Olivier Bonaventure, Olivier Pereira","Internet technologies have been designed from guidelines like the robustnessprinciple also known as Postel's law. Jon Postel's law is described as: ""Beconservative in what you do, be liberal in what you accept from others.""Fundamentally, it advises protocol designs to be tolerant with what they acceptfrom the other peers. We propose to take a step back and wonder how therobustness principle could be revisited to support security requirements aswell as unifying flexibility from specifications, protocol design and softwareimplementations. Our goal would be to define a software architecture thatoffers the benefits of the robustness principle (i.e., efficient networkservices despite the presence of various software versions), while alsoguaranteeing that this robustness cannot be exploited by making sure that it isonly used to support authentic evolution of the protocol specification."
"81","arXiv:1906.11521","https://arxiv.org/abs/1906.11521","Lattice-Based Unsupervised Test-Time Adaptation of Neural Network  Acoustic Models","Ondrej Klejch, Joachim Fainberg, Peter Bell, Steve Renals","Acoustic model adaptation to unseen test recordings aims to reduce themismatch between training and testing conditions. Most adaptation schemes forneural network models require the use of an initial one-best transcription forthe test data, generated by an unadapted model, in order to estimate theadaptation transform. It has been found that adaptation methods usingdiscriminative objective functions - such as cross-entropy loss - often requirecareful regularisation to avoid over-fitting to errors in the one-besttranscriptions. In this paper we solve this problem by performingdiscriminative adaptation using lattices obtained from a first pass decoding,an approach that can be readily integrated into the lattice-free maximum mutualinformation (LF-MMI) framework. We investigate this approach on threetranscription tasks of varying difficulty: TED talks, multi-genre broadcast(MGB) and a low-resource language (Somali). We find that our proposed approachenables many more parameters to be adapted without over-fitting being observed,and is successful even when the initial transcription has a WER in excess of50%."
"82","arXiv:1906.11524","https://arxiv.org/abs/1906.11524","Improved Distributed Approximation to Maximum Independent Set","Ken-ichi Kawarabayashi, Seri Khoury, Aaron Schild, Gregory Schwartzman","We present improved results for approximating Maximum Independent Set($\MaxIS$) in the standard LOCAL and CONGEST models of distributed computing.Let $n$ and $\Delta$ be the number of nodes and maximum degree in the inputgraph, respectively. Bar-Yehuda et al. [PODC 2017] showed that there is analgorithm in the CONGEST model that finds a $\Delta$-approximation to $\MaxIS$in $O(\MIS(n,\Delta)\log W)$ rounds, where $\MIS(n,\Delta)$ is the running timefor finding a \emph{maximal} independent set, and $W$ is the maximum weight ofa node in the network. Whether their algorithm is randomized or deterministicdepends on the $\MIS$ algorithm that they use as a black-box. Our results: (1)A deterministic $O(\MIS(n,\Delta))$ rounds algorithm for$O(\Delta)$-approximation to $\MaxIS$ in the CONGEST model. (2) A randomized$2^{O(\sqrt{\log \log n})}$ rounds algorithm that finds, with high probability,an $O(\Delta)$-approximation to $\MaxIS$ in the CONGEST model. (3) An$\Omega(\log^*n)$ lower bound for any randomized algorithm that finds anindependent set of size $\Omega(n/\Delta)$ that succeeds with probability atleast $1-1/\log n$, even for the LOCAL model. This hardness result applies forgraphs of maximum degree $\Delta=O(n/\log^*n)$. One might wonder whether thesame hardness result applies for low degree graphs. We rule out thispossibility with our next result. (4) An $O(1)$ rounds algorithm that finds anindependent set of size $\Omega(n/\Delta)$ in graphs with maximum degree$\Delta\leq n/\log n$, with high probability. Due to a lower bound of$\Omega(\sqrt{\log n/\log \log n})$ that was given by Kuhn, Moscibroda andWattenhofer [JACM, 2016] on the number of rounds for finding a maximalindependent set ($\MIS$) in the LOCAL model, even for randomized algorithms,our second result implies that finding an $O(\Delta)$-approximation to $\MaxIS$is strictly easier than $\MIS$."
"83","arXiv:1906.11555","https://arxiv.org/abs/1906.11555","Effective Rotation-invariant Point CNN with Spherical Harmonics kernels","Adrien Poulenard, Marie-Julie Rakotosaona, Yann Ponty, Maks Ovsjanikov","We present a novel rotation invariant architecture operating directly onpoint cloud data. We demonstrate how rotation invariance can be injected into arecently proposed point-based PCNN architecture, at all layers of the network,achieving invariance to both global shape transformations, and to localrotations on the level of patches or parts, useful when dealing with non-rigidobjects. We achieve this by employing a spherical harmonics based kernel atdifferent layers of the network, which is guaranteed to be invariant to rigidmotions. We also introduce a more efficient pooling operation for PCNN usingspace-partitioning data-structures. This results in a flexible, simple andefficient architecture that achieves accurate results on challenging shapeanalysis tasks including classification and segmentation, without requiringdata-augmentation, typically employed by non-invariant approaches."
"84","arXiv:1906.11525","https://arxiv.org/abs/1906.11525","Pooled Steganalysis in JPEG: how to deal with the spreading strategy?","Ahmad Zakaria, Marc Chaumont, Gérard Subsol","In image pooled steganalysis, a steganalyst, Eve, aims to detect if a set ofimages sent by a steganographer, Alice, to a receiver, Bob, contains a hiddenmessage. We can reasonably assess that the steganalyst does not know thestrategy used to spread the payload across images. To the best of ourknowledge, in this case, the most appropriate solution for pooled steganalysisis to use a Single-Image Detector (SID) to estimate/quantify if an image iscover or stego, and to average the scores obtained on the set of images.In such a scenario, where Eve does not know the embedding strategies, weexperimentally show that if Eve can discriminate among few well-known embeddingstrategies, she can improve her steganalysis performances compared to a simpleaveraging or maximum pooled approach. Our discriminative approach allowsobtaining steganalysis efficiencies comparable to those obtained by aclairvoyant, Eve, who knows the Alice embedding strategy.Another interesting observation is that DeLS embedding strategy behavesreally better than all the other embedding strategies. Those observationsresults in the experimentation with six different embedding strategies made onJpeg images with JUNIWARD, a state-of-the-art Single-Image-Detector, and adiscriminative architecture that is invariant to the individual payload in eachimage, invariant to the size of the analyzed set of images, and build on abinary detector (for the pooling) that is able to deal with various embeddingstrategies."
"85","arXiv:1906.11527","https://arxiv.org/abs/1906.11527","Hyp-RL : Hyperparameter Optimization by Reinforcement Learning","Hadi S. Jomaa, Josif Grabocka, Lars Schmidt-Thieme","Hyperparameter tuning is an omnipresent problem in machine learning as it isan integral aspect of obtaining the state-of-the-art performance for any model.Most often, hyperparameters are optimized just by training a model on a grid ofpossible hyperparameter values and taking the one that performs best on avalidation sample (grid search). More recently, methods have been introducedthat build a so-called surrogate model that predicts the validation loss for aspecific hyperparameter setting, model and dataset and then sequentially selectthe next hyperparameter to test, based on a heuristic function of the expectedvalue and the uncertainty of the surrogate model called acquisition function(sequential model-based Bayesian optimization, SMBO).In this paper we model the hyperparameter optimization problem as asequential decision problem, which hyperparameter to test next, and address itwith reinforcement learning. This way our model does not have to rely on aheuristic acquisition function like SMBO, but can learn which hyperparametersto test next based on the subsequent reduction in validation loss they willeventually lead to, either because they yield good models themselves or becausethey allow the hyperparameter selection policy to build a better surrogatemodel that is able to choose better hyperparameters later on. Experiments on alarge battery of 50 data sets demonstrate that our method outperforms thestate-of-the-art approaches for hyperparameter learning."
"86","arXiv:1906.11538","https://arxiv.org/abs/1906.11538","Error estimates of the backward Euler-Maruyama method for multi-valued  stochastic differential equations","Monika Eisenmann, Mihály Kovács, Raphael Kruse, Stig Larsson","In this paper, we derive error estimates of the backward Euler-Maruyamamethod applied to multi-valued stochastic differential equations. An importantexample of such an equation is a stochastic gradient flow whose associatedpotential is not continuously differentiable, but assumed to be convex. We showthat the backward Euler-Maruyama method is well-defined and convergent of orderat least $1/4$ with respect to the root-mean-square norm. Our error analysisrelies on techniques for deterministic problems developed in [Nochetto,Savar\'e, and Verdi, Comm.\ Pure Appl.\ Math., 2000]. We verify that oursetting applies to an overdamped Langevin equation with a discontinuousgradient and to a spatially semi-discrete approximation of the stochastic$p$-Laplace equation."
"87","arXiv:1906.11539","https://arxiv.org/abs/1906.11539","Multi-Robot Patrolling with Sensing Idleness and Data Delay Objectives","Jürgen Scherer, Bernhard Rinner","Multi-robot patrolling represents a fundamental problem for many monitoringand surveillance applications and has gained significant interest in recentyears. In patrolling, mobile robots repeatedly travel through an environment,capture sensor data at certain sensing locations and deliver this data to thebase station in a way that maximizes the changes of detection. Robots move ontours, exchange data when they meet with robots on neighboring tours and soeventually deliver data to the base station.In this paper we jointly consider two important optimization criteria ofmulti-robot patrolling: (i) idleness, i.e. the time between consecutive visitsof sensing locations, and (ii) delay, i.e. the time between capturing data atthe sensing location and its arrival at the base station. We systematicallyinvestigate the effect of the robots' moving directions along their tours andthe selection of meeting points for data exchange. We prove that the problem ofdetermining the movement directions and meeting points such that the data delayis minimized is NP-hard. We propose heuristics and provide a simulation studywhich shows that the cooperative approach can outperform an uncooperativeapproach where every robot delivers the captured data individually to the basestation."
"88","arXiv:1906.11541","https://arxiv.org/abs/1906.11541","A Key 6G Challenge and Opportunity -- Connecting the Remaining 4  Billions: A Survey on Rural Connectivity","Elias Yaacoub, Mohamed-Slim Alouini","Providing connectivity to around half of the World population living in ruralor underprivileged areas is a tremendous challenge, but also a uniqueopportunity. In this paper, a survey of technologies for providing connectivityto rural areas, and that can help address this challenge, is provided.Fronthaul and backhaul techniques are discussed. In addition, energy and costefficiency of the studied technologies are analyzed. Typical applicationscenarios in rural areas are discussed, and several country-specific use casesare surveyed. Directions for future evolution of rural connectivity areoutlined."
"89","arXiv:1906.11548","https://arxiv.org/abs/1906.11548","Generative grasp synthesis from demonstration using parametric mixtures","Ermano Arruda, Claudio Zito, Mohan Sridharan, Marek Kopicki, Jeremy L. Wyatt","We present a parametric formulation for learning generative models for graspsynthesis from a demonstration. We cast new light on this family of approaches,proposing a parametric formulation for grasp synthesis that is computationallyfaster compared to related work and indicates better grasp success rateperformance in simulated experiments, showing a gain of at least 10% successrate (p < 0.05) in all the tested conditions. The proposed implementation isalso able to incorporate arbitrary constraints for grasp ranking that mayinclude task-specific constraints. Results are reported followed by a briefdiscussion on the merits of the proposed methods noted so far."
"90","arXiv:1906.11557","https://arxiv.org/abs/1906.11557","Flexible SVBRDF Capture with a Multi-Image Deep Network","Valentin Deschaintre, Miika Aittala, Fredo Durand, George Drettakis, Adrien Bousseau","Empowered by deep learning, recent methods for material capture can estimatea spatially-varying reflectance from a single photograph. Such lightweightcapture is in stark contrast with the tens or hundreds of pictures required bytraditional optimization-based approaches. However, a single image is oftensimply not enough to observe the rich appearance of real-world materials. Wepresent a deep-learning method capable of estimating material appearance from avariable number of uncalibrated and unordered pictures captured with a handheldcamera and flash. Thanks to an order-independent fusing layer, thisarchitecture extracts the most useful information from each picture, whilebenefiting from strong priors learned from data. The method can handle bothview and light direction variation without calibration. We show how our methodimproves its prediction with the number of input pictures, and reaches highquality reconstructions with as little as 1 to 10 images -- a sweet spotbetween existing single-image and complex multi-image approaches."
"91","arXiv:1906.11559","https://arxiv.org/abs/1906.11559","Capacity and Coverage Enhancement Using Long-Endurance Tethered Airborne  Base Stations","Mustafa A. Kishk, Ahmed Bader, Mohamed-Slim Alouini","Airborne base stations (carried by drones) have a great potential to enhancecoverage and capacity of cellular networks. Multiple scenarios and use caseswill highly benefit from such technology such as (i) offloading terrestrialbase stations (BSs) in dense and urban areas, and (ii) providing coverage forrural areas. However, one of the main challenges facing the deployment ofairborne BSs is the limited available energy at the drone, which limits theflight time. In fact, most of the currently used unmanned aerial vehicles(UAVs) can only operate for one hour maximum. This limits the performance ofthe UAV-enabled cellular network due to the need to frequently visit the groundstation to recharge, leaving the UAV's coverage area temporarily out ofservice. In this article, we propose a new UAV-enabled cellular network setupbased on tethered UAVs (TUAVs). In the proposed setup, the TUAV is connected toa ground station (GS) through a tether, which provides the TUAV with bothenergy and data. This enables a flight that can stay for days. We describe indetail the components of the proposed system. Furthermore, we enlist the mainadvantages of a TUAV-enabled cellular network compared to typical untetheredUAVs. Next, we discuss the potential applications and use cases for TUAVs.Finally, we discuss the challenges, design considerations, and future researchdirections to realize the proposed setup."
"92","arXiv:1906.11561","https://arxiv.org/abs/1906.11561","A New Benchmark Dataset for Texture Image Analysis and Surface Defect  Detection","Shervan Fekri-Ershad","Texture analysis plays an important role in many image processingapplications to describe the image content or objects. On the other hand,visual surface defect detection is a highly research field in the computervision. Surface defect refers to abnormalities in the texture of the surface.So, in this paper a dual purpose benchmark dataset is proposed for textureimage analysis and surface defect detection titled stone texture image (STIdataset). The proposed benchmark dataset consist of 4 different class of stonetexture images. The proposed benchmark dataset have some unique properties tomake it very near to real applications. Local rotation, different zoom rates,unbalanced classes, variation of textures in size are some properties of theproposed dataset. In the result part, some descriptors are applied on thisdataset to evaluate the proposed STI dataset in comparison with otherstate-of-the-art datasets."
"93","arXiv:1906.11564","https://arxiv.org/abs/1906.11564","Automatic Detection of Myocontrol Failures Based upon Situational  Context Information","Karoline Heiwolt, Claudio Zito, Markus Nowak, Claudio Castellini, Rustam Stolkin","Myoelectric control systems for assistive devices are still unreliable. Theuser's input signals can become unstable over time due to e.g. fatigue,electrode displacement, or sweat. Hence, such controllers need to be constantlyupdated and heavily rely on user feedback. In this paper, we present anautomatic failure detection method which learns when plausible predictionsbecome unreliable and model updates are necessary. Our key insight is toenhance the control system with a set of generative models that learn sensiblebehaviour for a desired task from human demonstration. We illustrate ourapproach on a grasping scenario in Virtual Reality, in which the user is askedto grasp a bottle on a table. From demonstration our model learns thereach-to-grasp motion from a resting position to two grasps (power grasp andtridigital grasp) and how to predict the most adequate grasp from localcontext, e.g. tridigital grasp on the bottle cap or around the bottleneck. Bymeasuring the error between new grasp attempts and the model prediction, thesystem can effectively detect which input commands do not reflect the user'sintention. We evaluated our model in two cases: i) with both position androtation information of the wrist pose, and ii) with only rotationalinformation. Our results show that our approach detects statistically highlysignificant differences in error distributions with p < 0.001 betweensuccessful and failed grasp attempts in both cases."
"94","arXiv:1906.11565","https://arxiv.org/abs/1906.11565","EmotionX-KU: BERT-Max based Contextual Emotion Classifier","Kisu Yang, Dongyub Lee, Taesun Whang, Seolhwa Lee, Heuiseok Lim","We propose a contextual emotion classifier based on a transferable languagemodel and dynamic max pooling, which predicts the emotion of each utterance ina dialogue. A representative emotion analysis task, EmotionX, requires toconsider contextual information from colloquial dialogues and to deal with aclass imbalance problem. To alleviate these problems, our model leverages theself-attention based transferable language model and the weighted cross entropyloss. Furthermore, we apply post-training and fine-tuning mechanisms to enhancethe domain adaptability of our model and utilize several machine learningtechniques to improve its performance. We conduct experiments on twoemotion-labeled datasets named Friends and EmotionPush. As a result, our modeloutperforms the previous state-of-the-art model and also shows competitiveperformance in the EmotionX 2019 challenge. The code will be available in theGithub page."
"95","arXiv:1906.11567","https://arxiv.org/abs/1906.11567","Adversarial Robustness via Adversarial Label-Smoothing","Morgane Goibert, Elvis Dohmatob","We study Label-Smoothing as a means for improving adversarial robustness ofsupervised deep-learning models. After establishing a thorough and unifiedframework, we propose several novel Label-Smoothing methods: adversarial,Boltzmann and second-best Label-Smoothing methods. On various datasets (MNIST,CIFAR10, SVHN) and models (linear models, MLPs, LeNet, ResNet), we show thatthese methods improve adversarial robustness against a variety of attacks(FGSM, BIM, DeepFool, Carlini-Wagner) by better taking account of the datasetgeometry. These proposed Label-Smoothing methods have two main advantages: theycan be implemented as a modified cross-entropy loss, thus do not require anymodifications of the network architecture nor do they lead to increasedtraining times, and they improve both standard and adversarial accuracy."
"96","arXiv:1906.11571","https://arxiv.org/abs/1906.11571","Sensitivity to Haptic-Audio Envelope Asynchrony","Alfonso Balandra, Shoichi Hasegawa","We want to understand the human capabilities to perceive amplitudesimilarities between a haptic and an audio signal. So, four psychophysicalexperiments were performed. Three of them measured the asynchrony JND (JustNoticeable Difference) at the signals' attack, release and decay, while theforth experiment measured the amplitude decrease on the middle of the signal.All the experiments used a combination of the constant stimulus and staircasemethods to present two stimuli, while the participants' (N=12) task was toidentify which of the two stimuli was synchronized. The audiotactile stimuluswas defined using an stereo audio signal with an ADSR (Attack Decay SustainRelease) envelope. The partial results reveal JNDs for temporal asynchrony of:54ms for attack, 265ms for decay and 57ms for release. Also the results revealan amplitude decrease JND of 25\%. Although for decay the results were todisperse, therefore we suspect that the participants were not able to thechanges on the haptic signal."
"97","arXiv:1906.11577","https://arxiv.org/abs/1906.11577","A PolSAR Scattering Power Factorization Framework and Novel  Roll-Invariant Parameters Based Unsupervised Classification Scheme Using a  Geodesic Distance","Debanshu Ratha, Eric Pottier, Avik Bhattacharya, Alejandro C. Frery","We propose a generic Scattering Power Factorization Framework (SPFF) forPolarimetric Synthetic Aperture Radar (PolSAR) data to directly obtain $N$scattering power components along with a residue power component for eachpixel. Each scattering power component is factorized into similarity (ordissimilarity) using elementary targets and a generalized random volume model.The similarity measure is derived using a geodesic distance between pairs of$4\times4$ real Kennaugh matrices. In standard model-based decompositionschemes, the $3\times3$ Hermitian positive semi-definite covariance (orcoherency) matrix is expressed as a weighted linear combination of scatteringtargets following a fixed hierarchical process. In contrast, under the proposedframework, a convex splitting of unity is performed to obtain the weights whilepreserving the dominance of the scattering components. The product of the totalpower (Span) with these weights provides the non-negative scattering powercomponents. Furthermore, the framework along the geodesic distance iseffectively used to obtain specific roll-invariant parameters which are thenutilized to design an unsupervised classification scheme. The SPFF, the rollinvariant parameters, and the classification results are assessed using C-bandRADARSAT-2 and L-band ALOS-2 images of San Francisco."
"98","arXiv:1906.11578","https://arxiv.org/abs/1906.11578","A shallow residual neural network to predict the visual cortex response","Anne-Ruth José Meijer, Arnoud Visser","Understanding how the visual cortex of the human brain really works is stillan open problem for science today. A better understanding of naturalintelligence could also benefit object-recognition algorithms based onconvolutional neural networks. In this paper we demonstrate the asset of usinga shallow residual neural network for this task. The benefit of this approachis that earlier stages of the network can be accurately trained, which allowsus to add more layers at the earlier stage. With this additional layer theprediction of the visual brain activity improves from $10.4\%$ (block 1) to$15.53\%$ (last fully connected layer). By training the network for more than10 epochs this improvement can become even larger."
"99","arXiv:1906.11583","https://arxiv.org/abs/1906.11583","Approximate Causal Abstraction","Sander Beckers, Frederick Eberhardt, Joseph Y. Halpern","Scientific models describe natural phenomena at different levels ofabstraction. Abstract descriptions can provide the basis for interventions onthe system and explanation of observed phenomena at a level of granularity thatis coarser than the most fundamental account of the system. Beckers and Halpern(2019), building on work of Rubenstein et al. (2017), developed an account ofabstraction for causal models that is exact. Here we extend this account to themore realistic case where an abstract causal model offers only an approximationof the underlying system. We show how the resulting account handles thediscrepancy that can arise between low- and high-level causal models of thesame system, and in the process provide an account of how one causal modelapproximates another, a topic of independent interest. Finally, we extend theaccount of approximate abstractions to probabilistic causal models, indicatinghow and where uncertainty can enter into an approximate abstraction."
"100","arXiv:1906.11586","https://arxiv.org/abs/1906.11586","CaDSS: Cataract Dataset for Semantic Segmentation","Evangello Flouty, Abdolrahim Kadkhodamohammadi, Imanol Luengo, Felix Fuentes-Hurtado, Hinde Taleb, Santiago Barbarisi, Gwenole Quellec, Danail Stoyanov","Video signals provide a wealth of information about surgical procedures andare the main sensory cue for surgeons. Video processing and understanding canbe used to empower computer assisted interventions (CAI) as well as thedevelopment of detailed post-operative analysis of the surgical intervention. Afundamental building block to such capabilities is the ability to understandand segment video into semantic labels that differentiate and localize tissuetypes and different instruments. Deep learning has advanced semanticsegmentation techniques dramatically in recent years but is fundamentallyreliant on the availability of labelled datasets used to train models. In thispaper, we introduce a high quality semantically segmented dataset forCataractsurgery annotated on top of an available video dataset.To the best of ourknowledge, this dataset has the highest quality annotation in surgical data todate. We introduce the dataset and then show the automatic segmentationperformance of state-of-the-art models on that dataset as a benchmark."
"101","arXiv:1906.11594","https://arxiv.org/abs/1906.11594","Curriculum Learning for Deep Generative Models with Clustering","Deli Zhao, Jiapeng Zhu, Zhenfang Guo, Bo Zhang","Training generative models like generative adversarial networks (GANs) andnormalizing flows is challenging for noisy data. A novel curriculum learningalgorithm pertaining to clustering is proposed to address this issue in thispaper. The curriculum construction is based on the centrality of underlyingclusters in data points. The data points of high centrality takes priority ofbeing fed into generative models during training. To make our algorithmscalable to large-scale data, the active set is devised, in the sense thatevery round of training proceeds only on an active subset containing a smallfraction of already trained data and the incremental data of lower centrality.Moreover, the geometric analysis is presented to interpret the necessity ofcluster curriculum for generative models. The experiments on cat and human-facedata validate that our algorithm is able to learn the optimal generative models(e.g. ProGAN and Glow) with respect to specified quality metrics for noisydata. An interesting finding is that the optimal cluster curriculum is closelyrelated to the critical point of a geometric percolation process formulated inthe paper."
"102","arXiv:1906.11596","https://arxiv.org/abs/1906.11596","Reconfiguration Algorithms for High Precision Communications in Time  Sensitive Networks: Time-Aware Shaper Configuration with IEEE 802.1Qcc  (Extended Version)","Ahmed Nasrallah, Venkatraman Balasubramanian, Akhilesh Thyagaturu, Martin Reisslein, Hesham ElBakoury","As new networking paradigms emerge for different networking applications,e.g., cyber-physical systems, and different services are handled under aconverged data link technology, e.g., Ethernet, certain applications withmission critical traffic cannot coexist on the same physical networkinginfrastructure using traditional Ethernet packet-switched networking protocols.The IEEE 802.1Q Time Sensitive Networking (TSN) task group is developingprotocol standards to provide deterministic properties on Ethernet basedpacket-switched networks. In particular, the IEEE 802.1Qcc, centralizedmanagement and control, and the IEEE 802.1Qbv, Time-Aware Shaper, can be usedto manage and control scheduled traffic streams with periodic properties alongwith best-effort traffic on the same network infrastructure. In this paper, weinvestigate the effects of using the IEEE 802.1Qcc management protocol toaccurately and precisely configure TAS enabled switches (with transmissionwindows governed by gate control lists (GCLs) with gate control entries (GCEs))ensuring ultra-low latency, zero packet loss, and minimal jitter for scheduledTSN traffic. We examine both a centralized network/distributed user model(hybrid model) and a fully-distributed (decentralized) 802.1Qcc model on atypical industrial control network with the goal of maximizing scheduledtraffic streams."
"103","arXiv:1906.11597","https://arxiv.org/abs/1906.11597","Evaluating an Automated Mediator for Joint Narratives in a Conflict  Situation","Massimo Zancanaro, Oliviero Stock, Gianluca Schiavo, Alessandro Cappelletti, Sebastian Gehrmann, Daphna Canetti, Ohad Shaked, Shani Fachter, Rachel Yifat, Ravit Mimran, Patrice L. (Tamar)Weiss","Joint narratives are often used in the context of reconciliationinterventions for people in social conflict situations, which arise, forexample, due to ethnic or religious differences. The interventions aim toencourage a change in attitudes of the participants towards each other.Typically, a human mediator is fundamental for achieving a successfulintervention. In this work, we present an automated approach to support remoteinteractions between pairs of participants as they contribute to a shared storyin their own language. A key component is an automated cognitive tutor thatguides the participants through a controlled escalation/de-escalation processduring the development of a joint narrative. We performed a controlled studycomparing a trained human mediator to the automated mediator. The resultsdemonstrate that an automated mediator, although simple at this stage,effectively supports interactions and helps to achieve positive outcomescomparable to those attained by the trained human mediator."
"104","arXiv:1906.11598","https://arxiv.org/abs/1906.11598","Smallest graphs achieving the Stinson bound","Mate Gyarmati, Peter Ligeti","Perfect secret sharing scheme is a method of distribute a secret information$s$ among participants such that only predefined coalitions, called qualifiedsubsets of the participants can recover the secret, whereas any othercoalitions, the unqualified subsets cannot determine anything about the secret.The most important property is the efficiency of the system, which is measuredby the information ratio. It can be shown that for graphs the information ratiois at most $(\delta+1)/2$ where $\delta$ is the maximal degree of the graph.Blundo et al. constructed a family of $\delta$-regular graphs with informationratio $(\delta+1)/2$ on at least $c\cdot 6^\delta$ vertices. We improve thisresult by constructing a significantly smaller graph family on $c\cdot2^\delta$ vertices achieving the same upper bound both in the worst and theaverage case."
"105","arXiv:1906.11600","https://arxiv.org/abs/1906.11600","Dealing with Topological Information within a Fully Convolutional Neural  Network","Etienne Decencière, Santiago Velasco-Forero, Fu Min, Juanjuan Chen, Hélène Burdin, Gervais Gauthier, Bruno Laÿ, Thomas Bornschloegl, Thérèse Baldeweck","A fully convolutional neural network has a receptive field of limited sizeand therefore cannot exploit global information, such as topologicalinformation. A solution is proposed in this paper to solve this problem, basedon pre-processing with a geodesic operator. It is applied to the segmentationof histological images of pigmented reconstructed epidermis acquired via WholeSlide Imaging."
"106","arXiv:1906.11604","https://arxiv.org/abs/1906.11604","Gated Embeddings in End-to-End Speech Recognition for  Conversational-Context Fusion","Suyoun Kim, Siddharth Dalmia, Florian Metze","We present a novel conversational-context aware end-to-end speech recognizerbased on a gated neural network that incorporatesconversational-context/word/speech embeddings. Unlike conventional speechrecognition models, our model learns longer conversational-context informationthat spans across sentences and is consequently better at recognizing longconversations. Specifically, we propose to use the text-based external wordand/or sentence embeddings (i.e., fastText, BERT) within an end-to-endframework, yielding a significant improvement in word error rate with betterconversational-context representation. We evaluated the models on theSwitchboard conversational speech corpus and show that our model outperformsstandard end-to-end speech recognition models."
"107","arXiv:1906.11606","https://arxiv.org/abs/1906.11606","Structural Contracts -- Contracts for Type Construction & Dependent  Types to Ensure Consistency of Extra-Functional Reasoning","Gregor Nitsche","Targeting to use contract-based design for the specification and refinementof extra-functional properties, this research abstract suggests to use typeconstraints and dependent types to ensure correct and consistent top-downdecomposition of contracts with respect to a specifiable type constructor. Forthis, we summarize the composition problem and give a short draft of ourapproach, called Structural Contracts."
"108","arXiv:1906.11607","https://arxiv.org/abs/1906.11607","Technical Health Check For Cloud Service Providers","Muhammed Fatih Bulut, Hongtan Sun, Pritpal Arora, Maja Vukovic, Klaus Koenig, Jonathan Young","Understanding the overall health of an IT Infrastructure is a key part of ITService Management. Traditional approach to perform technical health check isby visiting customer's physical site and rigorously examining the ITinfrastructure with Subject Matter Experts. Alternatively, periodic surveys aresent to Technical Architects who are responsible for the managed ITinfrastructure. In essence, both site visits and surveys suffer from reactivenature, and subjective assessment. In this paper, we present technical healthcheck for cloud providers, that monitors, assesses operational data and depictsthe current health of an IT infrastructure in real time. We also discusschallenges and opportunities of technical health check in Hybrid CloudEnvironment."
"109","arXiv:1906.11608","https://arxiv.org/abs/1906.11608","Simple Natural Language Processing Tools for Danish","Leon Derczynski","This technical note describes a set of baseline tools for automaticprocessing of Danish text. The tools are machine-learning based, using naturallanguage processing models trained over previously annotated documents. Theyare maintained at ITU Copenhagen and will always be freely available."
"110","arXiv:1906.11614","https://arxiv.org/abs/1906.11614","Methodology of Designing Multi-agent Robot Control Systems Utilising  Hierarchical Petri Nets","Maksym Figat, Cezary Zieliński","A robot system is designed as a set of embodied agents. An embodied agent isdecomposed into cooperating subsystems. In our previous work activities ofsubsystems were defined by hierarchical finite state machines. With theirstates, activities were associated. In that approach communication betweensubsystems was treated as an implementation issue. This paper represents theactivities of a robot system using hierarchical Petri nets with conditions.Such net is created by specifying consecutive layers: multi-agent robot systemlayer, agent layer, subsystem layer, behaviour layer and communication layer.This decomposition not only organizes in a systematic manner the development ofa robot system but also introduces a comprehensive description of concurrentlyacting subsystems. Based on those theoretical considerations, a tool wascreated for producing hierarchical Petri nets defining the model of a roboticsystem and enabling automatic generation of the robot controller code,resulting in a significant acceleration of the implementation phase. Thecapabilities of the tool are presented by the development of a robot controllerperforming a rudimentary task."
"111","arXiv:1906.11617","https://arxiv.org/abs/1906.11617","A non-intrusive reduced order modeling framework for quasi-geostrophic  turbulence","Sk. Mashfiqur Rahman, Suraj Pawar, Omer San, Adil Rasheed, Traian Iliescu","In this study, we present a non-intrusive reduced order modeling (ROM)framework for large-scale quasi-stationary systems. The framework proposedherein exploits the time series prediction capability of long short-term memory(LSTM) recurrent neural network such that: (i) in the training phase, the LSTMmodel is trained on the modal coefficients extracted from the high-resolutiondata using proper orthogonal decomposition (POD) transform, and (ii) in thetesting phase, the trained model predicts the modal coefficients for the totaltime recursively based on the initial time history. To illustrate thepredictive performance of the proposed framework, the mean flow fields and timeseries response of the field values are reconstructed from the predicted modalcoefficients by using an inverse POD transform. As a representative benchmarktest case, we consider a two-dimensional quasi-geostrophic (QG) oceancirculation model which, in general, displays an enormous range of fluctuatingspatial and temporal scales. We first illustrate that the conventional Galerkinprojection based ROM of such systems requires a high number of POD modes toobtain a stable flow physics. In addition, ROM-GP does not seem to capture theintermittent bursts appearing in the dynamics of the first few most energeticmodes. However, the proposed non-intrusive ROM framework based on LSTM(ROM-LSTM) yields a stable solution even for a small number of POD modes. Wealso observe that the ROM-LSTM model is able to capture quasi-periodicintermittent bursts accurately, and yields a stable and accurate mean flowdynamics using the time history of a few previous time states, denoted as thelookback time-window in this paper. Our findings suggest that the proposed ROMframework is capable of predicting noisy nonlinear fluid flows in an extremelyefficient way compared to the conventional projection based ROM."
"112","arXiv:1906.11624","https://arxiv.org/abs/1906.11624","Good for Games Automata: From Nondeterminism to Alternation","Udi Boker, Karoliina Lehtinen","A word automaton recognizing a language $L$ is good for games (GFG) if itscomposition with any game with winning condition $L$ preserves the game'swinner. While all deterministic automata are GFG, some nondeterministicautomata are not. There are various other properties that are used in theliterature for defining that a nondeterministic automaton is GFG, including""history-deterministic"", ""compliant with some letter game"", ""good for trees"",and ""good for composition with other automata"". The equivalence of theseproperties has not been formally shown.We generalize all of these definitions to alternating automata and show theirequivalence. We further show that alternating GFG automata are as expressive asdeterministic automata with the same acceptance conditions and indices. We thenshow that alternating GFG automata over finite words, and weak automata overinfinite words, are not more succinct than deterministic automata, and thatdeterminizing B\""uchi and co-B\""uchi alternating GFG automata involves a$2^{\Theta(n)}$ state blow-up. We leave open the question of whetheralternating GFG automata of stronger acceptance conditions allow fordoubly-exponential succinctness compared to deterministic automata."
"113","arXiv:1906.11626","https://arxiv.org/abs/1906.11626","On improving deep learning generalization with adaptive sparse  connectivity","Shiwei Liu, Decebal Constantin Mocanu, Mykola Pechenizkiy","Large neural networks are very successful in various tasks. However, withlimited data, the generalization capabilities of deep neural networks are alsovery limited. In this paper, we empirically start showing that intrinsicallysparse neural networks with adaptive sparse connectivity, which by design havea strict parameter budget during the training phase, have better generalizationcapabilities than their fully-connected counterparts. Besides this, we proposea new technique to train these sparse models by combining the SparseEvolutionary Training (SET) procedure with neurons pruning. Operated onMultiLayer Perceptron (MLP) and tested on 15 datasets, our proposed techniquezeros out around 50% of the hidden neurons during training, while having alinear number of parameters to optimize with respect to the number of neurons.The results show a competitive classification and generalization performance."
"114","arXiv:1906.11632","https://arxiv.org/abs/1906.11632","A Survey on GANs for Anomaly Detection","Federico Di Mattia, Paolo Galeone, Michele De Simoni, Emanuele Ghelfi","Anomaly detection is a significant problem faced in several research areas.Detecting and correctly classifying something unseen as anomalous is achallenging problem that has been tackled in many different manners over theyears.Generative Adversarial Networks (GANs) and the adversarial training processhave been recently employed to face this task yielding remarkable results. Inthis paper we survey the principal GAN-based anomaly detection methods,highlighting their pros and cons. Our contributions are the empiricalvalidation of the main GAN models for anomaly detection, the increase of theexperimental results on different datasets and the public release of a completeOpen Source toolbox for Anomaly Detection using GANs."
"115","arXiv:1906.11633","https://arxiv.org/abs/1906.11633","ORRB -- OpenAI Remote Rendering Backend","Maciek Chociej, Peter Welinder, Lilian Weng","We present the OpenAI Remote Rendering Backend (ORRB), a system that allowsfast and customizable rendering of robotics environments. It is based on theUnity3d game engine and interfaces with the MuJoCo physics simulation library.ORRB was designed with visual domain randomization in mind. It is optimized forcloud deployment and high throughput operation. We are releasing it to thepublic under a liberal MIT license: https://github.com/openai/orrb ."
"116","arXiv:1906.11695","https://arxiv.org/abs/1906.11695","Demonstration-Guided Deep Reinforcement Learning of Control Policies for  Dexterous Human-Robot Interaction","Sammy Christen, Stefan Stevsic, Otmar Hilliges","In this paper, we propose a method for training control policies forhuman-robot interactions such as handshakes or hand claps via DeepReinforcement Learning. The policy controls a humanoid Shadow Dexterous Hand,attached to a robot arm. We propose a parameterizable multi-objective rewardfunction that allows learning of a variety of interactions without changing thereward structure. The parameters of the reward function are estimated directlyfrom motion capture data of human-human interactions in order to producepolicies that are perceived as being natural and human-like by observers. Weevaluate our method on three significantly different hand interactions:handshake, hand clap and finger touch. We provide detailed analysis of theproposed reward function and the resulting policies and conduct a large-scaleuser study, indicating that our policy produces natural looking motions."
"117","arXiv:1906.11637","https://arxiv.org/abs/1906.11637","Singularity formation as a wetting mechanism in a dispersionless water  wave model","R. Camassa, G. Falqui, G. Ortenzi, M. Pedroni, G. Pitton","The behavior of a class of solutions of the shallow water Airy systemoriginating from initial data with discontinuous derivatives is considered.Initial data are obtained by splicing together self-similar parabolae with aconstant background state. These solutions are shown to develop velocity andsurface gradient catastrophes in finite time and the inherent persistence ofdry spots is shown to be terminated by the collapse of the parabolic core. Alldetails of the evolution can be obtained in closed form until the collapsetime, thanks to formation of simple waves that sandwich the evolvingself-similar core. The continuation of solutions asymptotically for short timesbeyond the collapse is then investigated analytically, in its weak form, withan approach using stretched coordinates inspired by singular perturbationtheory. This approach allows to follow the evolution after collapse byimplementing a spectrally accurate numerical code, which is developed alongsidea classical shock-capturing scheme for accuracy comparison. The codes arevalidated on special classes of initial data, in increasing order ofcomplexity, to illustrate the evolution of the dry spot initial conditions onlonger time scales past collapse."
"118","arXiv:1906.11639","https://arxiv.org/abs/1906.11639","On the Energy Efficiency of Limited-Backhaul Cell-Free Massive MIMO","Manijeh Bashar, Kanapathippillai Cumanan, Alister G. Burr, Hien Quoc Ngo, Erik G. Larsson, Pei Xiao","We investigate the energy efficiency performance of cell-free Massivemultiple-input multiple-output (MIMO), where the access points (APs) areconnected to a central processing unit (CPU) via limited-capacity links. Thanksto the distributed maximum ratio combining (MRC) weighting at the APs, wepropose that only the quantized version of the weighted signals are sent backto the CPU. Considering the effects of channel estimation errors and using theBussgang theorem to model the quantization errors, an energy efficiencymaximization problem is formulated with per-user power and backhaul capacityconstraints as well as with throughput requirement constraints. To handle thisnon-convex optimization problem, we decompose the original problem into twosub-problems and exploit a successive convex approximation (SCA) to solveoriginal energy efficiency maximization problem. Numerical results confirm thesuperiority of the proposed optimization scheme."
"119","arXiv:1906.11648","https://arxiv.org/abs/1906.11648","Consistent Internal Energy Based Schemes for the Compressible Euler  Equations","R. Herbin (LATP), T. Gallouët (I2M), J.-C Latché (IRSN), N Therme","Numerical schemes for the solution of the Euler equations have recently beendeveloped, which involve the discretisation of the internal energy equation,with corrective terms to ensure the correct capture of shocks, and, moregenerally, the consistency in the Lax-Wendroff sense. These schemes may bestaggered or colocated, using either struc-tured meshes or general simplicialor tetrahedral/hexahedral meshes. The time discretization is performed byfractional-step algorithms; these may be either based on semi-implicit pressurecorrection techniques or segregated in such a way that only explicit steps areinvolved (referred to hereafter as ""explicit"" variants). In order to ensure thepositivity of the density, the internal energy and the pressure, the discreteconvection operators for the mass and internal energy balance equations arecarefully designed; they use an upwind technique with respect to the materialvelocity only. The construction of the fluxes thus does not need any Rie-mannor approximate Riemann solver, and yields easily implementable algorithms. Thestability is obtained without restriction on the time step for the pressurecorrection scheme and under a CFL-like condition for explicit variants:preservation of the integral of the total energy over the computational domain,and positivity of the density and the internal energy. The semi-implicitfirst-order upwind scheme satisfies a local discrete entropy inequality. If aMUSCL-like scheme is used in order to limit the scheme diffusion, then a weakerproperty holds: the entropy inequality is satisfied up to a remainder termwhich is shown to tend to zero with the space and time steps, if the discretesolution is controlled in L $\infty$ and BV norms. The explicit upwind variantalso satisfies such a weaker property, at the price of an estimate for thevelocity which could be derived from the introduction of a new stabilizationterm in the momentum balance. Still for the explicit scheme, with theabove-mentioned MUSCL-like scheme, the same result only holds if the ratio ofthe time to the space step tends to zero."
"120","arXiv:1906.11649","https://arxiv.org/abs/1906.11649","Dependency Pairs Termination in Dependent Type Theory Modulo Rewriting","Frédéric Blanqui (DEDUCTEAM, LSV, ENS Paris Saclay), Guillaume Genestier (DEDUCTEAM, LSV, ENS Paris Saclay, CRI), Olivier Hermant (CRI)","Dependency pairs are a key concept at the core of modern automatedtermination provers for first-order term rewriting systems. In this paper, weintroduce an extension of this technique for a large class of dependently-typedhigher-order rewriting systems. This extends previous resultsby Wahlstedt onthe one hand and the first author on the other hand to strong normalization andnon-orthogonal rewriting systems. This new criterion is implemented in thetype-checker Dedukti."
"121","arXiv:1906.11654","https://arxiv.org/abs/1906.11654","Modal-based Kinematics and Contact Detection of Soft Robots","Yue Chen, Long Wang, Kevin Galloway, Isuru Godage, Nabil Simaan, Eric Barth","Soft robots offer an alternative approach to manipulate inside theconstrained space while maintaining the safe interaction with the externalenvironment. Due to its adaptable compliance characteristic, external contactforce can easily deform the robot shapes and lead to undesired robot kinematicand dynamic properties. Accurate contact detection and contact positionestimation are of critical importance for soft robot modeling, control,trajectory planning, and eventually affect the success of task completion. Inthis paper, we focus on the study of 1-DoF soft pneumatic bellow bendingactuator, which is one of the fundamental components to construct complex,multi-DoF soft robots. This 1-DoF soft robot is modeled through the integralrepresentation of the spacial curve. The direct and instantaneous kinematicsare calculated explicitly through a modal method. The fixed centrode deviation(FCD) method is used to to detect the external contact and estimate contactlocation. Simulation results indicate that the contact location can beaccurately estimated by solving a nonlinear least square optimization problem."
"122","arXiv:1906.11655","https://arxiv.org/abs/1906.11655","Uncertainty Estimates for Ordinal Embeddings","Michael Lohaus, Philipp Hennig, Ulrike von Luxburg","To investigate objects without a describable notion of distance, one cangather ordinal information by asking triplet comparisons of the form ""Is object$x$ closer to $y$ or is $x$ closer to $z$?"" In order to learn from such data,the objects are typically embedded in a Euclidean space while satisfying asmany triplet comparisons as possible. In this paper, we introduce empiricaluncertainty estimates for standard embedding algorithms when few noisy tripletsare available, using a bootstrap and a Bayesian approach. In particular,simulations show that these estimates are well calibrated and can serve toselect embedding parameters or to quantify uncertainty in scientificapplications."
"123","arXiv:1906.11898","https://arxiv.org/abs/1906.11898","InsectUp: Crowdsourcing Insect Observations to Assess Demographic Shifts  and Improve Classification","Léonard Boussioux, Tomás Giro-Larraz, Charles Guille-Escuret, Mehdi Cherti, Balázs Kégl","Insects play such a crucial role in ecosystems that a shift in demography ofjust a few species can have devastating consequences at environmental, socialand economic levels. Despite this, evaluation of insect demography is stronglylimited by the difficulty of collecting census data at sufficient scale. Wepropose a method to gather and leverage observations from bystanders, hikers,and entomology enthusiasts in order to provide researchers with data that couldsignificantly help anticipate and identify environmental threats. Finally, weshow that there is indeed interest on both sides for such collaboration."
"124","arXiv:1906.11657","https://arxiv.org/abs/1906.11657","Separation between Second Price Auctions with Personalized Reserves and  the Revenue Optimal Auction","Will Ma, Balasubramanian Sivan","What fraction of the single item $n$ buyers setting's expected optimalrevenue MyeRev can the second price auction with reserves achieve? In thespecial case where the buyers' valuation distributions are all drawn i.i.d. andthe distributions satisfy the regularity condition, the second price auctionwith an anonymous reserve (ASP) is the optimal auction itself. As the settinggets more complex, there are established upper bounds on the fraction of MyeRevthat ASP can achieve. On the contrary, no such upper bounds are known for thefraction of MyeRev achievable by the second price auction with eagerpersonalized reserves (ESP). In particular, no separation was earlier knownbetween ESP's revenue and MyeRev even in the most general setting ofnon-identical product distributions that don't satisfy the regularitycondition. In this paper we establish the first separation results for ESP: weshow that even in the case of distributions drawn i.i.d., but not necessarilysatisfying the regularity condition, the ESP cannot achieve more than a $0.778$fraction of MyeRev in general. Combined with Correa et al.'s result (EC 2017)that ESP can achieve at least a $0.745$ fraction of MyeRev, this nearly bridgesthe gap between upper and lower bounds on ESP's approximation factor."
"125","arXiv:1906.11661","https://arxiv.org/abs/1906.11661","Inspirational Adversarial Image Generation","Morgane Riviere, Olivier Teytaud, Jérémy Rapin, Yann LeCun, Camille Couprie","The task of image generation started to receive some attention from artistsand designers to inspire them in new creations. However, exploiting the resultsof deep generative models such as Generative Adversarial Networks can be longand tedious given the lack of existing tools. In this work, we propose a simplestrategy to inspire creators with new generations learned from a dataset oftheir choice, while providing some control on them. We design a simpleoptimization method to find the optimal latent parameters corresponding to theclosest generation to any input inspirational image. Specifically, we allow thegeneration given an inspirational image of the user choice by performingseveral optimization steps to recover optimal parameters from the model'slatent space. We tested several exploration methods starting with classicgradient descents to gradient-free optimizers. Many gradient-free optimizersjust need comparisons (better/worse than another image), so that they can evenbe used without numerical criterion, without inspirational image, but with onlywith human preference. Thus, by iterating on one's preferences we could makerobust Facial Composite or Fashion Generation algorithms. High resolution ofthe produced design generations are obtained using progressive growing of GANs.Our results on four datasets of faces, fashion images, and textures show thatsatisfactory images are effectively retrieved in most cases."
"126","arXiv:1906.11663","https://arxiv.org/abs/1906.11663","SpliceRadar: A Learned Method For Blind Image Forensics","Aurobrata Ghosh, Zheng Zhong, Terrance E Boult, Maneesh Singh","Detection and localization of image manipulations like splices are gaining inimportance with the easy accessibility of image editing softwares. Whiledetection generates a verdict for an image it provides no insight into themanipulation. Localization helps explain a positive detection by identifyingthe pixels of the image which have been tampered. We propose a deep learningbased method for splice localization without prior knowledge of a test image'scamera-model. It comprises a novel approach for learning rich filters and forsuppressing image-edges. Additionally, we train our model on a surrogate taskof camera model identification, which allows us to leverage large and widelyavailable, unmanipulated, camera-tagged image databases. During inference, weassume that the spliced and host regions come from different camera-models andwe segment these regions using a Gaussian-mixture model. Experiments on threetest databases demonstrate results on par with and above the state-of-the-artand a good generalization ability to unknown datasets."
"127","arXiv:1906.11667","https://arxiv.org/abs/1906.11667","Evolving Robust Neural Architectures to Defend from Adversarial Attacks","Danilo Vasconcellos Vargas, Shashank Kotyan","Deep neural networks were shown to misclassify slightly modified inputimages. Recently, many defenses have been proposed but none have improvedconsistently the robustness of neural networks. Here, we propose to use attacksas a function evaluation to automatically search for architectures that canresist such attacks. Experiments on neural architecture search algorithms fromthe literature show that although their accurate results, they are not able tofind robust architectures. Most of the reason for this lies in their limitedsearch space. By creating a novel neural architecture search with options fordense layers to connect with convolution layers and vice-versa as well as theaddition of multiplication, addition and concatenation layers in the searchspace, we were able to evolve an architecture that is $58\%$ accurate onadversarial samples. Interestingly, this inherent robustness of the evolvedarchitecture rivals state-of-the-art defenses such as adversarial trainingwhile being trained only on the training dataset. Moreover, the evolvedarchitecture makes use of some peculiar traits which might be useful fordeveloping even more robust ones. Thus, the results here demonstrate that morerobust architectures exist as well as opens up a new range of possibilities forthe development and exploration of deep neural networks using automaticarchitecture search.Code available at this http URL"
"128","arXiv:1906.11668","https://arxiv.org/abs/1906.11668","Artificial Intelligence: the global landscape of ethics guidelines","Anna Jobin, Marcello Ienca, Effy Vayena","In the last five years, private companies, research institutions as well aspublic sector organisations have issued principles and guidelines for ethicalAI, yet there is debate about both what constitutes ""ethical AI"" and whichethical requirements, technical standards and best practices are needed for itsrealization. To investigate whether a global agreement on these questions isemerging, we mapped and analyzed the current corpus of principles andguidelines on ethical AI. Our results reveal a global convergence emergingaround five ethical principles (transparency, justice and fairness,non-maleficence, responsibility and privacy), with substantive divergence inrelation to how these principles are interpreted; why they are deemedimportant; what issue, domain or actors they pertain to; and how they should beimplemented. Our findings highlight the importance of integratingguideline-development efforts with substantive ethical analysis and adequateimplementation strategies."
"129","arXiv:1906.11796","https://arxiv.org/abs/1906.11796","Latent Optimization for Non-adversarial Representation Disentanglement","Aviv Gabbay, Yedid Hoshen","Disentanglement between pose and content is a key task for artificialintelligence and has attracted much research interest. Current methods fordisentanglement include adversarial training and introducing cycle constraints.In this work, we present a novel disentanglement method which does not useadversarial training, achieving state-of-the-art performance. Our method useslatent optimization of an architecture borrowed from style-transfer, to enforceseparation of pose and content. We overcome the test generalization issues oflatent optimization, by a novel two-stage approach. In extensive experiments,our method is shown to achieve better disentanglement performance than bothadversarial and non-adversarial methods that use the same level of supervision."
"130","arXiv:1906.11669","https://arxiv.org/abs/1906.11669","Airways: Optimization-Based Planning of Quadrotor Trajectories according  to High-Level User Goals","Christoph Gebhardt, Benjamin Hepp, Tobias Naegeli, Stefan Stevsic, Otmar Hilliges","In this paper we propose a computational design tool that al-lows end-usersto create advanced quadrotor trajectories witha variety of applicationscenarios in mind. Our algorithm al-lows novice users to create quadrotor baseduse-cases withoutrequiring deep knowledge in either quadrotor control ortheunderlying constraints of the target domain. To achieve thisgoal we proposean optimization-based method that gener-ates feasible trajectories which can beflown in the real world.Furthermore, the method incorporates high-level humanob-jectives into the planning of flight trajectories. An easy touse 3D designtool allows for quick specification and edit-ing of trajectories as well as forintuitive exploration of theresulting solution space. We demonstrate theutility of our ap-proach in several real-world application scenarios,includingaerial-videography, robotic light-painting and drone racing."
"131","arXiv:1906.11675","https://arxiv.org/abs/1906.11675","Detection of small changes in medical and random-dot images comparing  self-organizing map performance to human detection","John Wandeto, Henry Nyongesa, Yves Remond, Birgitta Dresp-Langley","Radiologists use time series of medical images to monitor the progression ofa patient condition. They compare information gleaned from sequences of imagesto gain insight on progression or remission of the lesions, thus evaluating theprogress of a patient condition or response to therapy. Visual methods ofdetermining differences between one series of images to another can besubjective or fail to detect very small differences. We propose the use ofquantization errors obtained from Self Organizing Maps for image contentanalysis. We tested this technique with MRI images to which we progressivelyadded synthetic lesions. We have used a global approach that considers changeson the entire image as opposed to changes in segmented lesion regions only. Weclaim that this approach does not suffer from the limitations imposed bysegmentation, which may compromise the results. Results show quantizationerrors increased with the increase in lesions on the images. The results arealso consistent with previous studies using alternative approaches. We thencompared the detectability ability of our method to that of human noviceobservers having to detect very small local differences in random-dot images.The quantization errors of the SOM outputs compared with correct positiverates, after subtraction of false positive rates (guess rates), increasednoticeably and consistently with small increases in local dot size that werenot detectable by humans. We conclude that our method detects very smallchanges in complex images and suggest that it could be implemented to assisthuman operators in image based decision making."
"132","arXiv:1906.11684","https://arxiv.org/abs/1906.11684","Resonator Circuits for factoring high-dimensional vectors","Spencer J. Kent, E. Paxon Frady, Friedrich T. Sommer, Bruno A. Olshausen","We describe a type of neural network, called a Resonator Circuit, thatfactors high-dimensional vectors. Given a composite vector formed by theHadamard product of several other vectors drawn from a discrete set, aResonator Circuit can efficiently decompose the composite into these factors.This paper focuses on the case of ""bipolar"" vectors whose elements are $\pm1$and characterizes the solution quality, stability properties, and speed ofResonator Circuits in comparison to several benchmark optimization methodsincluding Alternating Least Squares, Iterative Soft Thresholding, andMultiplicative Weights. We find that Resonator Circuits substantiallyoutperform these alternative methods by leveraging a combination of powerfulnonlinear dynamics and ""searching in superposition"", by which we mean thatestimates of the correct solution are, at any given time, formed from aweighted superposition of all possible solutions. The considered alternativemethods also search in superposition, but the dynamics of Resonator Circuitsallow them to strike a more natural balance between exploring the solutionspace and exploiting local information to drive the network toward probablesolutions. Resonator Circuits can be conceptualized as a set of interconnectedHopfield Networks, and this leads to some interesting analysis. In particular,while a Hopfield Network descends an energy function and is guaranteed toconverge, a Resonator Circuit is not. However, there exists a high-fidelityregime where Resonator Circuits almost always do converge, and they can solvethe factorization problem extremely well. As factorization is central to manyaspects of perception and cognition, we believe that Resonator Circuits maybring us a step closer to understanding how this computationally difficultproblem is efficiently solved by neural circuits in brains."
"133","arXiv:1906.11686","https://arxiv.org/abs/1906.11686","Optimizing for Aesthetically Pleasing Quadrotor Camera Motion","Christoph Gebhardt, Stefan Stevsic, Otmar Hilliges","In this paper we first contribute a large scale online study (N=400) tobetter understand aesthetic perception of aerial video. The results indicatethat it is paramount to optimize smoothness of trajectories across allkeyframes. However, for experts timing control remains an essential tool.Satisfying this dual goal is technically challenging because it requires givingup desirable properties in the optimization formulation. Second, informed bythis study we propose a method that optimizes positional and temporal referencefit jointly. This allows to generate globally smooth trajectories, whileretaining user control over reference timings. The formulation is posed as avariable, infinite horizon, contour-following algorithm. Finally, a comparativelab study indicates that our optimization scheme outperforms thestate-of-the-art in terms of perceived usability and preference of resultingvideos. For novices our method produces smoother and better looking results andalso experts benefit from generated timings."
"134","arXiv:1906.11691","https://arxiv.org/abs/1906.11691","On the Sparseness of Certain MRD Codes","Heide Gluesing-Luerssen","We determine the proportion of $[3\times 3;3]$-MRD codes over ${\mathbb F}_q$within the space of all $3$-dimensional rank-metric codes over the same field.This shows that these MRD codes are sparse in the sense that this proportiontends to $0$ as $q\rightarrow\infty$. The computation is accomplished byreducing the space of all such rank-metric codes to a space of specific basesand subsequently making use of a result by Menichetti (1973) on 3-dimensionalsemifields."
"135","arXiv:1906.11693","https://arxiv.org/abs/1906.11693","Simple maximum-principle preserving time-stepping methods for  time-fractional Allen-Cahn equation","Bingquan Ji, Hong-lin Liao, Luming Zhang","Two fast L1 time-stepping methods, including the backward Euler andstabilized semi-implicit schemes, are suggested for the time-fractionalAllen-Cahn equation with Caputo's derivative. The time mesh is refined near theinitial time to resolve the intrinsically initial singularity of solution, andunequal time-steps are always incorporated into our approaches so that anadaptive time-stepping strategy can be used in long-time simulations. It isshown that the proposed schemes using the fast L1 formula preserve the discretemaximum principle. Sharp error estimates reflecting the time regularity ofsolution are established by applying the discrete fractional Gr\""{o}nwallinequality and global consistency analysis. Numerical experiments are presentedto show the effectiveness of our methods and to confirm our analysis."
"136","arXiv:1906.11700","https://arxiv.org/abs/1906.11700","Efficient algorithms for modifying and sampling from a categorical  distribution","Daniel Tang","Probabilistic programming languages and other machine learning applicationsoften require samples to be generated from a categorical distribution where theprobability of each one of $n$ categories is specified as a parameter. If theparameters are hyper-parameters then they need to be modified, however, currentimplementations of categorical distributions take $\mathcal{O}(n)$ time tomodify a parameter. If $n$ is large and the parameters are being frequentlymodified, this can become prohibitive. Here we present the insight that aHuffman tree is an efficient data structure for representing categoricaldistributions and present algorithms to generate samples as well as add, deleteand modify categories in $\mathcal{O}(\log(n))$ time. We demonstrate that thetime to sample from the distribution remains, in practice, within a few percentof the theoretical optimal value. The same algorithm may also be useful in thecontext of adaptive Huffman coding where computational efficiency is important."
"137","arXiv:1906.11706","https://arxiv.org/abs/1906.11706","The DREAMS Project: Improving the Intensive Care Patient Experience with  Virtual Reality","Triton Ong, Matthew Ruppert, Parisa Rashidi, Tezcan Ozrazgat-Baslanti, Marko Suvajdzic, Azra Bihorac","Background: Patients undergoing critical care can experience negativeoutcomes due to a variety of causes such as lack of sleep, prolonged pain, andanxiety. Our goal was to evaluate the feasibility and efficacy of usingmeditative virtual reality (VR) to improve the hospital experience of intensivecare unit (ICU) patients.Methods: A Google Daydream headset was used to expose ICU patients tocommercially available VR applications focused on calmness and relaxation(Google Spotlight Stories and RelaxVR). Sessions were conducted once daily forup to seven days. Outcome measures including pain level, anxiety, depression,medication administration, sleep quality, heart rate, respiratory rate, bloodpressure, delirium status, and patient ratings of the VR system were evaluatedusing paired t-tests and mixed models where appropriate.Results: 46 participants (M = 50 years, SD = 18) completed the study. Theclinical effects of VR were minimal for pain, sleep, and physiologicalmeasures. Delirium prevalence after VR exposure was low (13%). Mostparticipants had strong positive reactions to the VR exposure and showedconsiderable improvements in affect over time.Conclusion: The initial feasibility of exposing patients to VR in ICU wasdemonstrated. The lessons learned from deploying VR in the ICU are discussedand future avenues of research on the use of VR in the ICU are identified.Trial registration: The trial was registered on December 29, 2017 withClinicalTrials.gov with the identifier: NCT03385993."
"138","arXiv:1906.11711","https://arxiv.org/abs/1906.11711","Reducing Popularity Bias in Recommendation Over Time","Himan Abdollahpouri, Robin Burke","Many recommendation algorithms suffer from popularity bias: a small number ofpopular items being recommended too frequently, while other items getinsufficient exposure. Research in this area so far has concentrated on aone-shot representation of this bias, and on algorithms to improve thediversity of individual recommendation lists. In this work, we take atime-sensitive view of popularity bias, in which the algorithm assesses itslong-tail coverage at regular intervals, and compensates in the present momentfor omissions in the past. In particular, we present a temporal version of thewell-known xQuAD diversification algorithm adapted for long-tailrecommendation. Experimental results on two public datasets show that ourmethod is more effective in terms of the long-tail coverage and accuracytradeoff compared to some other existing approaches."
"139","arXiv:1906.11713","https://arxiv.org/abs/1906.11713","A Generalized Framework for Agglomerative Clustering of Signed Graphs  applied to Instance Segmentation","Alberto Bailoni, Constantin Pape, Steffen Wolf, Thorsten Beier, Anna Kreshuk, Fred A. Hamprecht","We propose a novel theoretical framework that generalizes algorithms forhierarchical agglomerative clustering to weighted graphs with both attractiveand repulsive interactions between the nodes. This framework defines GASP, aGeneralized Algorithm for Signed graph Partitioning, and allows us to exploremany combinations of different linkage criteria and cannot-link constraints. Weprove the equivalence of existing clustering methods to some of thosecombinations, and introduce new algorithms for combinations which have not beenstudied. An extensive comparison is performed to evaluate properties of theclustering algorithms in the context of instance segmentation in images,including robustness to noise and efficiency. We show how one of the newalgorithms proposed in our framework outperforms all previously knownagglomerative methods for signed graphs, both on the competitive CREMI 2016 EMsegmentation benchmark and on the CityScapes dataset."
"140","arXiv:1906.11715","https://arxiv.org/abs/1906.11715","Evaluating data-flow coverage in spectrum-based fault localization","Henrique Lemos Ribeiro, Higor Amario de Souza, Roberto Paulo de Andrioli Araujo, Marcos Lordello Chaim, Fabio Kon","Background: Debugging is a key task during the software development cycle.Spectrum-based Fault Localization (SFL) is a promising technique to improve andautomate debugging. SFL techniques use control-flow spectra to pinpoint themost suspicious program elements. However, data-flow spectra provide moredetailed information about the program execution, which may be useful for faultlocalization. Aims: We evaluate the effectiveness and efficiency of ten SFLranking metrics using data-flow spectra. Method: We compare the performance ofdata- and control-flow spectra for SFL using 163 faults from 5 real-world opensource programs, which contain from 468 to 4130 test cases. The data- andcontrol-flow spectra types used in our evaluation are definition-useassociations (DUAs) and lines, respectively. Results: Using data-flow spectra,up to 50% more faults are ranked in the top-15 positions compared tocontrol-flow spectra. Also, most SFL ranking metrics present bettereffectiveness using data-flow to inspect up to the top-40 positions. Theexecution cost of data-flow spectra is higher than control-flow, taking from 22seconds to less than 9 minutes. Data-flow has an average overhead of 353% forall programs, while the average overhead for control-flow is of 102%.Conclusions: The results suggest that SFL techniques can benefit from usingdata-flow spectra to classify faults in better positions, which may leaddevelopers to inspect less code to find bugs. The execution cost to gatherdata-flow is higher compared to control-flow, but it is not prohibitive.Moreover, data-flow spectra also provide information about suspicious variablesfor fault localization, which may improve the developers' performance usingSFL."
"141","arXiv:1906.11718","https://arxiv.org/abs/1906.11718","On Solving Word Equations Using SAT","Joel D. Day, Thorsten Ehlers, Mitja Kulczynski, Florin Manea, Dirk Nowotka, Danny Bøgsted Poulsen","We present Woorpje, a string solver for bounded word equations (i.e.,equations where the length of each variable is upper bounded by a giveninteger). Our algorithm works by reformulating the satisfiability of boundedword equations as a reachability problem for nondeterministic finite automata,and then carefully encoding this as a propositional satisfiability problem,which we then solve using the well-known Glucose SAT-solver. This approach hasthe advantage of allowing for the natural inclusion of additional linear lengthconstraints. Our solver obtains reliable and competitive results and,remarkably, discovered several cases where state-of-the-art solvers exhibit afaulty behaviour."
"142","arXiv:1906.11721","https://arxiv.org/abs/1906.11721","DiPETrans: A Framework for Distributed Parallel Execution of  Transactions of Blocks in Blockchain","Baheti Shrey, Anjana Parwat Singh, Peri Sathya, Simmhan Yogesh","In most of the modern day blockchain, transactions are executed serially byboth miners and validators; also, PoW is determined serially. The serialexecution limits the system throughput and increases transaction acceptancelatency, even unable to exploit the modern multi-core resources efficiently. Inthis work, we try to increase the throughput by introducing parallel executionof the transactions using a static analysis based technique. We propose aframework DiPETrans for the distributed parallel execution of blocktransactions. In DiPETrans, trusted peers in the blockchain network form acommunity to execute the transactions and to find the PoW parallelly. Thecommunity follows a master-slave approach for parallel execution. The core ideais that master analyzes the transactions using a static analysis basedtechnique, creates different groups (shards) of non-conflicting transactions,and distribute shards to workers (community members) to execute themparallelly. After transaction execution, communities compute power is utilizedto find PoW parallelly. On successful creation of a block, the masterbroadcasts the proposed block to other peers in the network for validation. Onreceiving a block, validators re-executes the block transactions, eitherparallelly (community) or serially (solo validators). If they reach the samestate as shared by the miner, then accept the block otherwise reject. Weperformed experiments with historical data from Ethereum blockchain andachieved linear speedup for transaction execution and end-to-end block creationwith up to 5 workers in the community. We experimented by varying the number oftransactions per block from 100 to 500 and obtained a maximum speedup of 2.18Xfor miner, 2.04X for info sharing validator, and 2.02X for no info sharingvalidator. DiPETrans is first of its kind, and we will be evolving it toprovide better performance."
"143","arXiv:1906.11727","https://arxiv.org/abs/1906.11727","Link weights recovery in heterogeneous information networks","Hong-Lan Botterman, Robin Lamarche-Perrin","Socio-technical systems usually consists of many intertwined networks, eachconnecting different types of objects (or actors) through a variety of means.As these networks are co-dependent, one can take advantage of this entangledstructure to study interaction patterns in a particular network from theinformation provided by other related networks. A method is hence proposed andtested to recover the weights of missing or unobserved links in heterogeneousinformation networks (HIN) - abstract representations of systems composed ofmultiple types of entities and their relations. Given a pair of nodes in a HIN,this work aims at recovering the exact weight of the incident link to these twonodes, knowing some other links present in the HIN. To do so, probabilitydistributions resulting from path-constrained random walks i.e., random walkswhere the walker is forced to follow only a specific sequence of node types andedge types, capable to capture specific semantics and commonly called ameta-path, are combined in a linearly fashion in order to approximate thedesired result. This method is general enough to compute the link weightbetween any types of nodes. Experiments on Twitter and bibliographic data showthe applicability of the method."
"144","arXiv:1906.11729","https://arxiv.org/abs/1906.11729","Using Intuition from Empirical Properties to Simplify Adversarial  Training Defense","Guanxiong Liu, Issa Khalil, Abdallah Khreishah","Due to the surprisingly good representation power of complex distributions,neural network (NN) classifiers are widely used in many tasks which includenatural language processing, computer vision and cyber security. In recentworks, people noticed the existence of adversarial examples. These adversarialexamples break the NN classifiers' underlying assumption that the environmentis attack free and can easily mislead fully trained NN classifier withoutnoticeable changes. Among defensive methods, adversarial training is a popularchoice. However, original adversarial training with single-step adversarialexamples (Single-Adv) can not defend against iterative adversarial examples.Although adversarial training with iterative adversarial examples (Iter-Adv)can defend against iterative adversarial examples, it consumes too muchcomputational power and hence is not scalable. In this paper, we analyzeIter-Adv techniques and identify two of their empirical properties. Based onthese properties, we propose modifications which enhance Single-Adv to performcompetitively as Iter-Adv. Through preliminary evaluation, we show that theproposed method enhances the test accuracy of state-of-the-art (SOTA)Single-Adv defensive method against iterative adversarial examples by up to16.93% while reducing its training cost by 28.75%."
"145","arXiv:1906.11731","https://arxiv.org/abs/1906.11731","Array Codes with Local Properties","Mario Blaum, Steven R. Hetzler","In general, array codes consist of $m\times n$ arrays and in many cases, thearrays satisfy parity constraints along lines of different slopes (generallywith a toroidal topology). Such codes are useful for RAID type ofarchitectures, since they allow to replace finite field operations by XORs. Wepresent expansions to traditional array codes of this type, like Blaum-Roth(BR) and extended EVENODD codes, by adding parity on columns. This verticalparity allows for recovery of one or more symbols in a column locally, i.e., byusing the remaining symbols in the column without invoking the rest of thearray. Properties and applications of the new codes are discussed, inparticular to Locally Recoverable (LRC) codes."
"146","arXiv:1906.11737","https://arxiv.org/abs/1906.11737","Adaptive second-order Crank-Nicolson time-stepping schemes for time  fractional molecular beam epitaxial growth models","Bingquan Ji, Hong-lin Liao, Yuezheng Gong, Luming Zhang","Adaptive second-order Crank-Nicolson time-stepping methods using the recentscalar auxiliary variable (SAV) approach are developed for the time-fractionalMolecular Beam Epitaxial models with Caputo's derivative. Based on thepiecewise linear interpolation, the Caputo's fractional derivative isapproximated by a novel second-order formula, which is naturally suitable for ageneral class of nonuniform meshes and essentially preserves the positivesemi-definite property of integral kernel. The resulting Crank-Nicolson SAVtime-stepping schemes are unconditional energy stable on nonuniform timemeshes, and are computationally efficient in multiscale time simulations whencombined with adaptive time steps, such as are appropriate for accuratelyresolving the intrinsically initial singularity of solution and for efficientlycapturing fast dynamics away from the initial time. Numerical examples arepresented to show the effectiveness of our methods."
"147","arXiv:1906.11753","https://arxiv.org/abs/1906.11753","Dynamic Drawing Guidance via Electromagnetic Haptic Feedback","Thomas Langerak, Juan Zarate, Velko Vechev, Daniele Panozzo, Otmar Hilliges","We propose a system to deliver dynamic guidance in drawing, sketching andhandwriting tasks via an electromagnet moving underneath a high refresh ratepressure sensitive tablet. The system allows the user to move the pen at theirown pace and style and does not take away control. The system continously anditeratively measures the pen motion and adjusts magnet position and poweraccording to the user input in real-time via a receding horizon optimal controlformulation. The optimization is based on a novel approximate electromagnetmodel that is fast enough for use in real-time methods, yet provides very goodfit to experimental data. Using a closed-loop time-free approach allows forerror-correcting behavior, gently pulling the user back to the desiredtrajectory rather than pushing or pulling the pen to a continuously advancingsetpoint. Our experimental results show that the system can control the penposition with a very low dispersion of 2.8mm (+/-0.8mm). An initial user studyindicates that it significantly increases accuracy of users drawing a varietyof shapes and that this improvement increases with complexity of the shape."
"148","arXiv:1906.11738","https://arxiv.org/abs/1906.11738","DVP: Data Visualization Platform","Waleed A. Yousef, Ahmed A. Abouelkahire, Omar S. Marzouk, Sameh K. Mohamed, Mohamed N. Alaggan","We identify two major steps in data analysis, data exploration forunderstanding and observing patterns/relationships in data; and construction,design and assessment of various models to formalize these relationships. Foreach step, there exists a large set of tools and software. For the first step,many visualization tools exist, such as, GGobi, Parallax, and Crystal Vision,and most recently tableau and plottly. For the second step, many ScientificComputing Environments (SCEs) exist, such as, Matlab, Mathematica, R andPython. However, there does not exist a tool which allows for seamless two-wayinteraction between visualization tools and SCEs. We have designed andimplemented a data visualization platform (DVP) with an architecture and designthat attempts to bridge this gap. DVP connects seamlessly to SCEs to bring thecomputational capabilities to the visualization methods in a single coherentplatform. DVP is designed with two interfaces, the desktop stand alone versionand the online interface. DVP with its structure and planned features is aunique software that serves a great deal of parties, including universityresearch, governmental decision support and country's economy modeling, trafficanalysis and control, financial sector and companies, and any other partyinterested in data analysis and interpretation. A free demo for the onlineinterface of DVP is available \citep{DVP}. Since DVP was launched, circa 2012,the present manuscript was not published since today for commercialization andpatent considerations."
"149","arXiv:1906.11742","https://arxiv.org/abs/1906.11742","A Game Model for Proofs with Costs","Timo Lang, Carlos Olarte, Elaine Pimentel, Christian Fermuller","We look at substructural calculi from a game semantic point of view, guidedby certain intuitions about resource conscious and, more specifically, costconscious reasoning. To this aim, we start with a game, where player I defendsa claim corresponding to a (single-conclusion) sequent, while player II triesto refute that claim. Branching rules for additive connectives are modeled bychoices of II, while branching for multiplicative connectives leads tosplitting the game into parallel subgames, all of which have to be won byplayer I to succeed. The game comes into full swing by adding cost labels toassumptions, and a corresponding budget. Different proofs of the sameend-sequent are interpreted as more or less expensive strategies for I todefend the corresponding claim. This leads to a new kind of labelled calculus,which can be seen as a fragment of SELL (subexponential linear logic). Finally,we generalize the concept of costs in proofs by using a semiring structure,illustrate our interpretation by examples and investigate someproof-theoretical properties."
"150","arXiv:1906.11746","https://arxiv.org/abs/1906.11746","Compositional Semantic Parsing Across Graphbanks","Matthias Lindemann, Jonas Groschwitz, Alexander Koller","Most semantic parsers that map sentences to graph-based meaningrepresentations are hand-designed for specific graphbanks. We present acompositional neural semantic parser which achieves, for the first time,competitive accuracies across a diverse range of graphbanks. Incorporating BERTembeddings and multi-task learning improves the accuracy further, setting newstates of the art on DM, PAS, PSD, AMR 2015 and EDS."
"151","arXiv:1906.11747","https://arxiv.org/abs/1906.11747","Raven: Open Surgical Robotic Platforms","Yangming Li, Blake Hannaford, Jacob Rosen","The Raven I and the Raven II surgical robots, as open research platforms,have been serving the robotic surgery research community for ten years. Thepaper 1) briefly presents the Raven I and the Raven II robots, 2) reviews therecent publications that are built upon the Raven robots, aim to be applied tothe Raven robots, or are directly compared with the Raven robots, and 3) usesthe Raven robots as a case study to discuss the popular research problems inthe research community and the trend of robotic surgery study. Instead of beinga thorough literature review, this work only reviews the works formallypublished in the past three years and uses these recent publications to analyzethe research interests, the popular open research problems, and opportunitiesin the topic of robotic surgery."
"152","arXiv:1906.11750","https://arxiv.org/abs/1906.11750","A Constant-Factor Approximation Algorithm for Online Coverage Path  Planning with Energy Constraint","Ayan Dutta, Gokarna Sharma","In this paper, we study the problem of coverage planning by a mobile robotwith a limited energy budget. The objective of the robot is to cover everypoint in the environment while minimizing the traveled path length. Theenvironment is initially unknown to the robot. Therefore, it needs to avoid theobstacles in the environment on-the-fly during the exploration. As the robothas a specific energy budget, it might not be able to cover the completeenvironment in one traversal. Instead, it will need to visit a static chargingstation periodically in order to recharge its energy. To solve the statedproblem, we propose a budgeted depth-first search (DFS)-based explorationstrategy that helps the robot to cover any unknown planar environment whilebounding the maximum path length to a constant-factor of the shortest-possiblepath length. Our $O(1)$-approximation guarantee advances the state-of-the-artof log-approximation for this problem. Simulation results show that ourproposed algorithm outperforms the current state-of-the-art algorithm both interms of the traveled path length and run time in all the tested environmentswith concave and convex obstacles."
"153","arXiv:1906.11751","https://arxiv.org/abs/1906.11751","The Impact of Preprocessing on Arabic-English Statistical and Neural  Machine Translation","Mai Oudah, Amjad Almahairi, Nizar Habash","Neural networks have become the state-of-the-art approach for machinetranslation (MT) in many languages. While linguistically-motivated tokenizationtechniques were shown to have significant effects on the performance ofstatistical MT, it remains unclear if those techniques are well suited forneural MT. In this paper, we systematically compare neural and statistical MTmodels for Arabic-English translation on data preprecossed by various prominenttokenization schemes. Furthermore, we consider a range of data and vocabularysizes and compare their effect on both approaches. Our empirical results showthat the best choice of tokenization scheme is largely based on the type ofmodel and the size of data. We also show that we can gain significantimprovements using a system selection that combines the output from neural andstatistical MT."
"154","arXiv:1906.11752","https://arxiv.org/abs/1906.11752","Semantic expressive capacity with bounded memory","Antoine Venant, Alexander Koller","We investigate the capacity of mechanisms for compositional semantic parsingto describe relations between sentences and semantic representations.We prove that in order to represent certain relations, mechanisms which aresyntactically projective must be able to remember an unbounded number oflocations in the semantic representations, where nonprojective mechanisms neednot.This is the first result of this kind, and has consequences both forgrammar-based and for neural systems."
"155","arXiv:1906.11755","https://arxiv.org/abs/1906.11755","Singular Value Decomposition and Neural Networks","Bernhard Bermeitinger, Tomas Hrycej, Siegfried Handschuh","Singular Value Decomposition (SVD) constitutes a bridge between the linearalgebra concepts and multi-layer neural networks---it is their linear analogy.Besides of this insight, it can be used as a good initial guess for the networkparameters, leading to substantially better optimization results."
"156","arXiv:1906.11761","https://arxiv.org/abs/1906.11761","Improving Academic Plagiarism Detection for STEM Documents by Analyzing  Mathematical Content and Citations","Norman Meuschke, Vincent Stange, Moritz Schubotz, Michael Karmer, Bela Gipp","Identifying academic plagiarism is a pressing task for educational andresearch institutions, publishers, and funding agencies. Current plagiarismdetection systems reliably find instances of copied and moderately rewordedtext. However, reliably detecting concealed plagiarism, such as strongparaphrases, translations, and the reuse of nontextual content and ideas is anopen research problem. In this paper, we extend our prior research on analyzingmathematical content and academic citations. Both are promising approaches forimproving the detection of concealed academic plagiarism primarily in Science,Technology, Engineering and Mathematics (STEM). We make the followingcontributions: i) We present a two-stage detection process that combinessimilarity assessments of mathematical content, academic citations, and text.ii) We introduce new similarity measures that consider the order ofmathematical features and outperform the measures in our prior research. iii)We compare the effectiveness of the math-based, citation-based, and text-baseddetection approaches using confirmed cases of academic plagiarism. iv) Wedemonstrate that the combined analysis of math-based and citation-based contentfeatures allows identifying potentially suspicious cases in a collection of102K STEM documents. Overall, we show that analyzing the similarity ofmathematical content and academic citations is a striking supplement forconventional text-based detection approaches for academic literature in theSTEM disciplines."
"157","arXiv:1906.11778","https://arxiv.org/abs/1906.11778","Convergence rates for the numerical approximation of the 2D stochastic  Navier-Stokes equations","Dominic Breit, Alan Dodgson","We study stochastic Navier-Stokes equations in two dimensions with respect toperiodic boundary conditions. The equations are perturbed by a nonlinearmultiplicative stochastic forcing with linear growth (in the velocity) drivenby a cylindrical Wiener process. We establish convergence rates for afinite-element based space-time approximation with respect to convergence inprobability (where the error is measure in the $L^\infty_tL^2_x\capL^2_tW^{1,2}_x$-norm). Our main result provides linear convergence in space andconvergence of order (almost) 1/2 in time. This improves earlier results from[E. Carelli, A. Prohl: Rates of convergence for discretizations of thestochastic incompressible Navier-Stokes equations. SIAM J. Numer. Anal. 50(5),2467-2496. (2012)] where the convergence rate in time is only (almost) 1/4. Ourapproach is based on a careful analysis of the pressure function using astochastic pressure decomposition."
"158","arXiv:1906.11782","https://arxiv.org/abs/1906.11782","A Sweet Recipe for Consolidated Vulnerabilities: Attacking a Live  Website by Harnessing a Killer Combination of Vulnerabilities","Mazharul Islam, MD. Nazmuddoha Ansary, Novia Nurain, Salauddin Parvez Shams, A. B. M. Alim Al Islam","The recent emergence of new vulnerabilities is an epoch-making problem in thecomplex world of website security. Most of the websites are failing to keepupdating to tackle their websites from these new vulnerabilities leavingwithout realizing the weakness of the websites. As a result, whencyber-criminals scour such vulnerable old version websites, the scanner willrepresent a set of vulnerabilities. Once found, these vulnerabilities are thenexploited to steal data, distribute malicious content, or inject defacement andspam content into the vulnerable websites. Furthermore, a combination ofdifferent vulnerabilities is able to cause more damages than anticipation.Therefore, in this paper, we endeavor to find connections among variousvulnerabilities such as cross-site scripting, local file inclusion, remote fileinclusion, buffer overflow CSRF, etc. To do so, we develop a Finite StateMachine (FSM) attacking model, which analyzes a set of vulnerabilities towardsthe road to finding connections. We demonstrate the efficacy of our model byapplying it to the set of vulnerabilities found on two live websites."
"159","arXiv:1906.11783","https://arxiv.org/abs/1906.11783","Representation Learning of Music Using Artist, Album, and Track  Information","Jongpil Lee, Jiyoung Park, Juhan Nam","Supervised music representation learning has been performed mainly usingsemantic labels such as music genres. However, annotating music with semanticlabels requires time and cost. In this work, we investigate the use of factualmetadata such as artist, album, and track information, which are naturallyannotated to songs, for supervised music representation learning. The resultsshow that each of the metadata has individual concept characteristics, andusing them jointly improves overall performance."
"160","arXiv:1906.11785","https://arxiv.org/abs/1906.11785","ExTra: Transfer-guided Exploration","Anirban Santara, Rishabh Madan, Balaraman Ravindran, Pabitra Mitra","In this work we present a novel approach for transfer-guided exploration inreinforcement learning that is inspired by the human tendency to leverageexperiences from similar encounters in the past while navigating a new task.Given an optimal policy in a related task-environment, we show that itsbisimulation distance from the current task-environment gives a lower bound onthe optimal advantage of state-action pairs in the current task-environment.Transfer-guided Exploration (ExTra) samples actions from a Softmax distributionover these lower bounds. In this way, actions with potentially higher optimumadvantage are sampled more frequently. In our experiments on gridworldenvironments, we demonstrate that given access to an optimal policy in arelated task-environment, ExTra can outperform popular domain-specificexploration strategies viz. epsilon greedy, Model-Based Interval Estimation -Exploration Based (MBIE-EB), Pursuit and Boltzmann in terms of samplecomplexity and rate of convergence. We further show that ExTra is robust tochoices of source task and shows a graceful degradation of performance as thedissimilarity of the source task increases. We also demonstrate that ExTra,when used alongside traditional exploration algorithms, improves their rate ofconvergence. Thus it is capable of complimenting the efficacy of traditionalexploration algorithms."
"161","arXiv:1906.11790","https://arxiv.org/abs/1906.11790","Encoding Database Schemas with Relation-Aware Self-Attention for  Text-to-SQL Parsers","Richard Shin","When translating natural language questions into SQL queries to answerquestions from a database, we would like our methods to generalize to domainsand database schemas outside of the training set. To handle complex questionsand database schemas with a neural encoder-decoder paradigm, it is critical toproperly encode the schema as part of the input with the question. In thispaper, we use relation-aware self-attention within the encoder so that it canreason about how the tables and columns in the provided schema relate to eachother and use this information in interpreting the question. We achievesignificant gains on the recently-released Spider dataset with 42.94% exactmatch accuracy, compared to the 18.96% reported in published work."
"162","arXiv:1906.11798","https://arxiv.org/abs/1906.11798","Stolen Memories: Leveraging Model Memorization for Calibrated White-Box  Membership Inference","Klas Leino, Matt Fredrikson","Membership inference (MI) attacks exploit a learned model's lack ofgeneralization to infer whether a given sample was in the model's training set.Known MI attacks generally work by casting the attacker's goal as a supervisedlearning problem, training an attack model from predictions generated by thetarget model, or by others like it. However, we find that these attacks do notoften provide a meaningful basis for confidently inferring training setmembership, as the attack models are not well-calibrated. Moreover, theseattacks do not significantly outperform a trivial attack that predicts that apoint is a member if and only if the model correctly predicts its label. Inthis work we present well-calibrated MI attacks that allow the attacker toaccurately control the minimum confidence with which positive membershipinferences are made. Our attacks take advantage of white-box information aboutthe target model and leverage new insights about how overfitting occurs in deepneural networks; namely, we show how a model's idiosyncratic use of featurescan provide evidence for membership. Experiments on seven real-world datasetsshow that our attacks support calibration for high-confidence inferences, whileoutperforming previous MI attacks in terms of accuracy. Finally, we show thatour attacks achieve non-trivial advantage on some models with lowgeneralization error, including those trained with small-epsilon-differentialprivacy; for large-epsilon (epsilon=16, as reported in some industrialsettings), the attack performs comparably to unprotected models."
"163","arXiv:1906.11803","https://arxiv.org/abs/1906.11803","Data Consortia","Eric Bax, John Donald, Melissa Gerber, Lisa Giaffo, Tanisha Sharma, Nikki Thompson, Kimberly Williams","Today, web-based companies use user data to provide and enhance services tousers, both individually and collectively. Some also analyze user data forother purposes, for example to select advertisements or price offers for users.Some even use or allow the data to be used to evaluate investments in financialmarkets. Users' concerns about how their data is or may be used has promptedlegislative action in the European Union and congressional questioning in theUnited States. But data can also benefit society, for example giving earlywarnings for disease outbreaks, allowing in-depth study of relationshipsbetween genetics and disease, and elucidating local and macroeconomic trends ina timely manner. So, instead of just a focus on privacy, in the future, usersmay insist that their data be used on their behalf. We explore potentialframeworks for groups of consenting, informed users to pool their data fortheir own benefit and that of society, discussing directions, challenges, andevolution for such efforts."
"164","arXiv:1906.11811","https://arxiv.org/abs/1906.11811","Faster and Better Nested Dissection Orders for Customizable Contraction  Hierarchies","Lars Gottesbüren, Michael Hamann, Tim Niklas Uhl, Dorothea Wagner","Graph partitioning has many applications. We consider the acceleration ofshortest path queries in road networks using Customizable ContractionHierarchies (CCH). It is based on computing a nested dissection order byrecursively dividing the road network into parts. Recently, with FlowCutter andInertial Flow, two flow-based graph bipartitioning algorithms have beenproposed for road networks. While FlowCutter achieves high-quality results andthus fast query times, it is rather slow. Inertial Flow is particularly fastdue to the use of geographical information while still achieving acceptablequality. We combine the techniques of both algorithms to achieve more than sixtimes faster preprocessing times than FlowCutter and even slightly betterquality. We show that using 16 cores of a shared-memory machine, thispreprocessing needs four minutes on the Europe road network."
"165","arXiv:1906.11813","https://arxiv.org/abs/1906.11813","Learning Fair Representations for Kernel Models","Zilong Tan, Samuel Yeom, Matt Fredrikson, Ameet Talwalkar","Fair representations are a powerful tool for establishing criteria likestatistical parity, proxy non-discrimination, and equality of opportunity inlearned models. Existing techniques for learning these representations aretypically model-agnostic, as they preprocess the original data such that theoutput satisfies some fairness criterion, and can be used with arbitrarylearning methods. In contrast, we demonstrate the promise of learning amodel-aware fair representation, focusing on kernel-based models. We leveragethe classical Sufficient Dimension Reduction (SDR) framework to constructrepresentations as subspaces of the reproducing kernel Hilbert space (RKHS),whose member functions are guaranteed to satisfy fairness. Our method supportsseveral fairness criteria, continuous and discrete data, and multiple protectedattributes. We further show how to calibrate the accuracy tradeoff bycharacterizing it in terms of the principal angles between subspaces of theRKHS. Finally, we apply our approach to obtain the first Fair Gaussian Process(FGP) prior for fair Bayesian learning, and show that it is competitive with,and in some cases outperforms, state-of-the-art methods on real data."
"166","arXiv:1906.11826","https://arxiv.org/abs/1906.11826","Lattice Map Spiking Neural Networks (LM-SNNs) for Clustering and  Classifying Image Data","Hananel Hazan, Daniel J. Saunders, Darpan T. Sanghavi, Hava Siegelmann, Robert Kozma","Spiking neural networks (SNNs) with a lattice architecture are introduced inthis work, combining several desirable properties of SNNs and self-organizedmaps (SOMs). Networks are trained with biologically motivated, unsupervisedlearning rules to obtain a self-organized grid of filters via cooperative andcompetitive excitatory-inhibitory interactions. Several inhibition strategiesare developed and tested, such as (i) incrementally increasing inhibition levelover the course of network training, and (ii) switching the inhibition levelfrom low to high (two-level) after an initial training segment. During thelabeling phase, the spiking activity generated by data with known labels isused to assign neurons to categories of data, which are then used to evaluatethe network's classification ability on a held-out set of test data. Severalbiologically plausible evaluation rules are proposed and compared, including apopulation-level confidence rating, and an $n$-gram inspired method. Theeffectiveness of the proposed self-organized learning mechanism is tested usingthe MNIST benchmark dataset, as well as using images produced by playing theAtari Breakout game."
"167","arXiv:1906.11888","https://arxiv.org/abs/1906.11888","Coloring With Limited Data: Few-Shot Colorization via Memory-Augmented  Networks","Seungjoo Yoo, Hyojin Bahng, Sunghyo Chung, Junsoo Lee, Jaehyuk Chang, Jaegul Choo","Despite recent advancements in deep learning-based automatic colorization,they are still limited when it comes to few-shot learning. Existing modelsrequire a significant amount of training data. To tackle this issue, we presenta novel memory-augmented colorization model MemoPainter that can producehigh-quality colorization with limited data. In particular, our model is ableto capture rare instances and successfully colorize them. We also propose anovel threshold triplet loss that enables unsupervised training of memorynetworks without the need of class labels. Experiments show that our model hassuperior quality in both few-shot and one-shot colorization tasks."
"168","arXiv:1906.11829","https://arxiv.org/abs/1906.11829","Selection Via Proxy: Efficient Data Selection For Deep Learning","Cody Coleman, Christopher Yeh, Stephen Mussmann, Baharan Mirzasoleiman, Peter Bailis, Percy Liang, Jure Leskovec, Matei Zaharia","Data selection methods such as active learning and core-set selection areuseful tools for machine learning on large datasets, but they can beprohibitively expensive to apply in deep learning. Unlike in other areas ofmachine learning, the feature representations that these techniques depend onare learned in deep learning rather than given, which takes a substantialamount of training time. In this work, we show that we can significantlyimprove the computational efficiency of data selection in deep learning byusing a much smaller proxy model to perform data selection for tasks that willeventually require a large target model (e.g., selecting data points to labelfor active learning). In deep learning, we can scale down models by removinghidden layers or reducing their dimension to create proxies that are an orderof magnitude faster. Although these small proxy models have significantlyhigher error, we find that they empirically provide useful rankings for dataselection that have a high correlation with those of larger models. We evaluatethis ""selection via proxy"" (SVP) approach on several data selection tasks. Foractive learning, applying SVP to Sener and Savarese [2018]'s recent method foractive learning in deep learning gives a 4x improvement in execution time whileyielding the same model accuracy. For core-set selection, we show that a proxymodel that trains 10x faster than a target ResNet164 model on CIFAR10 can beused to remove 50% of the training data without compromising the accuracy ofthe target model, making end-to-end training time improvements via core-setselection possible."
"169","arXiv:1906.11858","https://arxiv.org/abs/1906.11858","Robotic Supervised Autonomy: A Review","Yangming Li","This invited paper discusses a new but important problem, supervisedautonomy, in the context of robotics. The paper defines supervised autonomy andcompares the supervised autonomy with robotic teleoperation and robotic fullautonomy. Based on the discussion, the significance of supervised autonomy wasintroduced. The paper discusses the challenging and unsolved problems insupervised autonomy, and reviews the related works in our research lab. Basedon the discussions, the paper draws the conclusion that supervised autonomy iscritical for applying robotic systems to address complicated problems in thereal world."
"170","arXiv:1906.11861","https://arxiv.org/abs/1906.11861","Relating Simple Sentence Representations in Deep Neural Networks and the  Brain","Sharmistha Jat, Hao Tang, Partha Talukdar, Tom Mitchell","What is the relationship between sentence representations learned by deeprecurrent models against those encoded by the brain? Is there anycorrespondence between hidden layers of these recurrent models and brainregions when processing sentences? Can these deep models be used to synthesizebrain data which can then be utilized in other extrinsic tasks? We investigatethese questions using sentences with simple syntax and semantics (e.g., Thebone was eaten by the dog.). We consider multiple neural network architectures,including recently proposed ELMo and BERT. We use magnetoencephalography (MEG)brain recording data collected from human subjects when they were reading thesesimple sentences.Overall, we find that BERT's activations correlate the best with MEG braindata. We also find that the deep network representation can be used to generatebrain data from new sentences to augment existing brain data.To the best of our knowledge, this is the first work showing that the MEGbrain recording when reading a word in a sentence can be used to distinguishearlier words in the sentence. Our exploration is also the first to use deepneural network representations to generate synthetic brain data and to showthat it helps in improving subsequent stimuli decoding task accuracy."
"171","arXiv:1906.11873","https://arxiv.org/abs/1906.11873","VolMap: A Real-time Model for Semantic Segmentation of a LiDAR  surrounding view","Hager Radi, Waleed Ali","This paper introduces VolMap, a real-time approach for the semanticsegmentation of a 3D LiDAR surrounding view system in autonomous vehicles. Wedesigned an optimized deep convolution neural network that can accuratelysegment the point cloud produced by a 360\degree{} LiDAR setup, where the inputconsists of a volumetric bird-eye view with LiDAR height layers used as inputchannels. We further investigated the usage of multi-LiDAR setup and its effecton the performance of the semantic segmentation task. Our evaluations arecarried out on a large scale 3D object detection benchmark containing a LiDARcocoon setup, along with KITTI dataset, where the per-point segmentation labelsare derived from 3D bounding boxes. We show that VolMap achieved an excellentbalance between high accuracy and real-time running on CPU."
"172","arXiv:1906.11874","https://arxiv.org/abs/1906.11874","Team JL Solution to Google Landmark Recognition 2019","Yinzheng Gu, Chuanpeng Li","In this paper, we describe our solution to the Google Landmark Recognition2019 Challenge held on Kaggle. Due to the large number of classes, noisy data,imbalanced class sizes, and the presence of a significant amount of distractorsin the test set, our method is based mainly on retrieval techniques with bothglobal and local CNN approaches. Our full pipeline, after ensembling the modelsand applying several steps of re-ranking strategies, scores 0.37606 GAP on theprivate leaderboard which won the 1st place in the competition."
"173","arXiv:1906.11876","https://arxiv.org/abs/1906.11876","Uncertainty Based Detection and Relabeling of Noisy Image Labels","Jan M.Köhler, Maximilian Autenrieth, William H. Beluch","Deep neural networks (DNNs) are powerful tools in computer vision tasks.However, in many realistic scenarios label noise is prevalent in the trainingimages, and overfitting to these noisy labels can significantly harm thegeneralization performance of DNNs. We propose a novel technique to identifydata with noisy labels based on the different distributions of the predictiveuncertainties from a DNN over the clean and noisy data. Additionally, thebehavior of the uncertainty over the course of training helps to identify thenetwork weights which best can be used to relabel the noisy labels. Data withnoisy labels can therefore be cleaned in an iterative process. Our proposedmethod can be easily implemented, and shows promising performance on the taskof noisy label detection on CIFAR-10 and CIFAR-100."
"174","arXiv:1906.11889","https://arxiv.org/abs/1906.11889","Deep Eyedentification: Biometric Identification using Micro-Movements of  the Eye","Lena A. Jäger, Silvia Makowski, Paul Prasse, Sascha Liehr, Maximilian Seidler, Tobias Scheffer","We study involuntary micro-movements of the eye for biometric identification.While prior studies extract lower-frequency macro-movements from the output ofvideo-based eye-tracking systems and engineer explicit features of thesemacro-movements, we develop a deep convolutional architecture that processesthe raw eye-tracking signal. Compared to prior work, the network attains alower error rate by one order of magnitude and is faster by two orders ofmagnitude: it identifies users accurately within seconds."
"175","arXiv:1906.11877","https://arxiv.org/abs/1906.11877","Making CNNs for Video Parsing Accessible","Zijin Luo, Matthew Guzdial, Mark Riedl","The ability to extract sequences of game events for high-resolution e-sportgames has traditionally required access to the game's engine. This serves as abarrier to groups who don't possess this access. It is possible to apply deeplearning to derive these logs from gameplay video, but it requirescomputational power that serves as an additional barrier. These groups wouldbenefit from access to these logs, such as small e-sport tournament organizerswho could better visualize gameplay to inform both audience and commentators.In this paper we present a combined solution to reduce the requiredcomputational resources and time to apply a convolutional neural network (CNN)to extract events from e-sport gameplay videos. This solution consists oftechniques to train a CNN faster and methods to execute predictions morequickly. This expands the types of machines capable of training and runningthese models, which in turn extends access to extracting game logs with thisapproach. We evaluate the approaches in the domain of DOTA2, one of the mostpopular e-sports. Our results demonstrate our approach outperforms standardbackpropagation baselines."
"176","arXiv:1906.11878","https://arxiv.org/abs/1906.11878","Deep Learning-Based Classification Of the Defective Pistachios Via Deep  Autoencoder Neural Networks","Mehdi Abbaszadeh, Aliakbar Rahimifard, Mohammadali Eftekhari, Hossein Ghayoumi Zadeh, Ali Fayazi, Ali Dini, Mostafa Danaeian","Pistachio nut is mainly consumed as raw, salted or roasted because of itshigh nutritional properties and favorable taste. Pistachio nuts with shell andkernel defects, besides not being acceptable for a consumer, are also prone toinsects damage, mold decay, and aflatoxin contamination. In this research, adeep learning-based imaging algorithm was developed to improve the sorting ofnuts with shell and kernel defects that indicate the risk of aflatoxincontamination, such as dark stains, oily stains, adhering hull, fungal decayand Aspergillus molds. This paper presents an unsupervised learning method toclassify defective and unpleasant pistachios based on deep Auto-encoder neuralnetworks. The testing of the designed neural network on a validation datasetshowed that nuts having dark stain, oily stain or adhering hull with anaccuracy of 80.3% can be distinguished from normal nuts. Due to the limitedmemory available in the HPC of university, the results are reasonable andjustifiable."
"177","arXiv:1906.11879","https://arxiv.org/abs/1906.11879","Comparing Energy Efficiency of CPU, GPU and FPGA Implementations for  Vision Kernels","Murad Qasaimeh, Kristof Denolf, Jack Lo, Kees Vissers, Joseph Zambreno, Phillip H. Jones","Developing high performance embedded vision applications requires balancingrun-time performance with energy constraints. Given the mix of hardwareaccelerators that exist for embedded computer vision (e.g. multi-core CPUs,GPUs, and FPGAs), and their associated vendor optimized vision libraries, itbecomes a challenge for developers to navigate this fragmented solution space.To aid with determining which embedded platform is most suitable for theirapplication, we conduct a comprehensive benchmark of the run-time performanceand energy efficiency of a wide range of vision kernels. We discuss rationalesfor why a given underlying hardware architecture innately performs well orpoorly based on the characteristics of a range of vision kernel categories.Specifically, our study is performed for three commonly used HW acceleratorsfor embedded vision applications: ARM57 CPU, Jetson TX2 GPU and ZCU102 FPGA,using their vendor optimized vision libraries: OpenCV, VisionWorks andxfOpenCV. Our results show that the GPU achieves an energy/frame reductionratio of 1.1-3.2x compared to the others for simple kernels. While for morecomplicated kernels and complete vision pipelines, the FPGA outperforms theothers with energy/frame reduction ratios of 1.2-22.3x. It is also observedthat the FPGA performs increasingly better as a vision application's pipelinecomplexity grows."
"178","arXiv:1906.11880","https://arxiv.org/abs/1906.11880","Style Generator Inversion for Image Enhancement and Animation","Aviv Gabbay, Yedid Hoshen","One of the main motivations for training high quality image generative modelsis their potential use as tools for image manipulation. Recently, generativeadversarial networks (GANs) have been able to generate images of remarkablequality. Unfortunately, adversarially-trained unconditional generator networkshave not been successful as image priors. One of the main requirements for anetwork to act as a generative image prior, is being able to generate everypossible image from the target distribution. Adversarial learning oftenexperiences mode-collapse, which manifests in generators that cannot generatesome modes of the target distribution. Another requirement often not satisfiedis invertibility i.e. having an efficient way of finding a valid input latentcode given a required output image. In this work, we show that differently fromearlier GANs, the very recently proposed style-generators are quite easy toinvert. We use this important observation to propose style generators asgeneral purpose image priors. We show that style generators outperform otherGANs as well as Deep Image Prior as priors for image enhancement tasks. Thelatent space spanned by style-generators satisfies linear identity-poserelations. The latent space linearity, combined with invertibility, allows usto animate still facial images without supervision. Extensive experiments areperformed to support the main contributions of this paper."
"179","arXiv:1906.11881","https://arxiv.org/abs/1906.11881","Explicit Disentanglement of Appearance and Perspective in Generative  Models","Nicki Skafte Detlefsen, Søren Hauberg","Disentangled representation learning finds compact, independent andeasy-to-interpret factors of the data. Learning such has been shown to requirean inductive bias, which we explicitly encode in a generative model of images.Specifically, we propose a model with two latent spaces: one that representsspatial transformations of the input data, and another that represents thetransformed data. We find that the latter naturally captures the intrinsicappearance of the data. To realize the generative model, we propose aVariationally Inferred Transformational Autoencoder (VITAE) that incorporates aspatial transformer into a variational autoencoder. We show how to performinference in the model efficiently by carefully designing the encoders andrestricting the transformation class to be diffeomorphic. Empirically, ourmodel separates the visual style from digit type on MNIST, and separates shapeand pose in images of the human body."
"180","arXiv:1906.11882","https://arxiv.org/abs/1906.11882","From Data Quality to Model Quality: an Exploratory Study on Deep  Learning","Tianxing He, Shengcheng Yu, Ziyuan Wang, Jieqiong Li, Zhenyu Chen","Nowadays, people strive to improve the accuracy of deep learning models.However, very little work has focused on the quality of data sets. In fact,data quality determines model quality. Therefore, it is important for us tomake research on how data quality affects on model quality. In this paper, wemainly consider four aspects of data quality, including Dataset Equilibrium,Dataset Size, Quality of Label, Dataset Contamination. We deign experiment onMNIST and Cifar-10 and try to find out the influence the four aspects make onmodel quality. Experimental results show that four aspects all have decisiveimpact on the quality of models. It means that decrease in data quality inthese aspects will reduce the accuracy of model."
"181","arXiv:1906.11883","https://arxiv.org/abs/1906.11883","Unsupervised Learning of Object Keypoints for Perception and Control","Tejas Kulkarni, Ankush Gupta, Catalin Ionescu, Sebastian Borgeaud, Malcolm Reynolds, Andrew Zisserman, Volodymyr Mnih","The study of object representations in computer vision has primarily focusedon developing representations that are useful for image classification, objectdetection, or semantic segmentation as downstream tasks. In this work we aim tolearn object representations that are useful for control and reinforcementlearning (RL). To this end, we introduce Transporter, a neural networkarchitecture for discovering concise geometric object representations in termsof keypoints or image-space coordinates. Our method learns from raw videoframes in a fully unsupervised manner, by transporting learnt image featuresbetween video frames using a keypoint bottleneck. The discovered keypointstrack objects and object parts across long time-horizons more accurately thanrecent similar methods. Furthermore, consistent long-term tracking enables twonotable results in control domains -- (1) using the keypoint co-ordinates andcorresponding image features as inputs enables highly sample-efficientreinforcement learning; (2) learning to explore by controlling keypointlocations drastically reduces the search space, enabling deep exploration(leading to states unreachable through random action exploration) without anyextrinsic rewards."
"182","arXiv:1906.11884","https://arxiv.org/abs/1906.11884","Identifying Emotions from Walking using Affective and Deep Features","Tanmay Randhavane, Aniket Bera, Kyra Kapsaskis, Uttaran Bhattacharya, Kurt Gray, Dinesh Manocha","We present a new data-driven model and algorithm to identify the perceivedemotions of individuals based on their walking styles. Given an RGB video of anindividual walking, we extract his/her walking gait in the form of a series of3D poses. Our goal is to exploit the gait features to classify the emotionalstate of the human into one of four emotions: happy, sad, angry, or neutral.Our perceived emotion recognition approach is based on using deep featureslearned via LSTM on labeled emotion datasets. Furthermore, we combine thesefeatures with affective features computed from the gaits using posture andmovement cues. These features are classified using a Random Forest Classifier.We show that our mapping between the combined feature space and the perceivedemotional state provides 80.07% accuracy in identifying the perceived emotions.In addition to classifying discrete categories of emotions, our algorithm alsopredicts the values of perceived valence and arousal from gaits. We alsopresent an ""EWalk (Emotion Walk)"" dataset that consists of videos of walkingindividuals with gaits and labeled emotions. To the best of our knowledge, thisis the first gait-based model to identify perceived emotions from videos ofwalking individuals."
"183","arXiv:1906.11885","https://arxiv.org/abs/1906.11885","Robust Classification with Sparse Representation Fusion on Diverse Data  Subsets","Chun-Mei Feng, Yong Xu, Zuoyong Li, Jian Yang","Sparse Representation (SR) techniques encode the test samples into a sparselinear combination of all training samples and then classify the test samplesinto the class with the minimum residual. The classification of SR techniquesdepends on the representation capability on the test samples. However, most ofthese models view the representation problem of the test samples as adeterministic problem, ignoring the uncertainty of the representation. Theuncertainty is caused by two factors, random noise in the samples and theintrinsic randomness of the sample set, which means that if we capture a groupof samples, the obtained set of samples will be different in differentconditions. In this paper, we propose a novel method based upon CollaborativeRepresentation that is a special instance of SR and has closed-form solution.It performs Sparse Representation Fusion based on the Diverse Subset oftraining samples (SRFDS), which reduces the impact of randomness of the sampleset and enhances the robustness of classification results. The proposed methodis suitable for multiple types of data and has no requirement on the patterntype of the tasks. In addition, SRFDS not only preserves a closed-form solutionbut also greatly improves the classification performance. Promising results onvarious datasets serve as the evidence of better performance of SRFDS thanother SR-based methods. The Matlab code of SRFDS will be accessible atthis http URL"
"184","arXiv:1906.11886","https://arxiv.org/abs/1906.11886","Traffic Light Recognition Using Deep Learning and Prior Maps for  Autonomous Cars","Lucas C. Possatti, Rânik Guidolini, Vinicius B. Cardoso, Rodrigo F. Berriel, Thiago M. Paixão, Claudine Badue, Alberto F. De Souza, Thiago Oliveira-Santos","Autonomous terrestrial vehicles must be capable of perceiving traffic lightsand recognizing their current states to share the streets with human drivers.Most of the time, human drivers can easily identify the relevant trafficlights. To deal with this issue, a common solution for autonomous cars is tointegrate recognition with prior maps. However, additional solution is requiredfor the detection and recognition of the traffic light. Deep learningtechniques have showed great performance and power of generalization includingtraffic related problems. Motivated by the advances in deep learning, somerecent works leveraged some state-of-the-art deep detectors to locate (andfurther recognize) traffic lights from 2D camera images. However, none of themcombine the power of the deep learning-based detectors with prior maps torecognize the state of the relevant traffic lights. Based on that, this workproposes to integrate the power of deep learning-based detection with the priormaps used by our car platform IARA (acronym for Intelligent Autonomous RoboticAutomobile) to recognize the relevant traffic lights of predefined routes. Theprocess is divided in two phases: an offline phase for map construction andtraffic lights annotation; and an online phase for traffic light recognitionand identification of the relevant ones. The proposed system was evaluated onfive test cases (routes) in the city of Vit\'oria, each case being composed ofa video sequence and a prior map with the relevant traffic lights for theroute. Results showed that the proposed technique is able to correctly identifythe relevant traffic light along the trajectory."
"185","arXiv:1906.11887","https://arxiv.org/abs/1906.11887","A Preliminary Study on Data Augmentation of Deep Learning for Image  Classification","Benlin Hu, Cheng Lei, Dong Wang, Shu Zhang, Zhenyu Chen","Deep learning models have a large number of freeparameters that need to becalculated by effective trainingof the models on a great deal of training datato improvetheir generalization performance. However, data obtaining andlabelingis expensive in practice. Data augmentation is one of themethods to alleviatethis problem. In this paper, we conduct apreliminary study on how threevariables (augmentation method,augmentation rate and size of basic dataset perlabel) can affectthe accuracy of deep learning for image classification. Thestudyprovides some guidelines: (1) it is better to use transformationsthatalter the geometry of the images rather than those justlighting and color. (2)2-3 times augmentation rate is good enoughfor training. (3) the smaller amountof data, the more obviouscontributions could have."
"186","arXiv:1906.11891","https://arxiv.org/abs/1906.11891","Characterizing Bias in Classifiers using Generative Models","Daniel McDuff, Shuang Ma, Yale Song, Ashish Kapoor","Models that are learned from real-world data are often biased because thedata used to train them is biased. This can propagate systemic human biasesthat exist and ultimately lead to inequitable treatment of people, especiallyminorities. To characterize bias in learned classifiers, existing approachesrely on human oracles labeling real-world examples to identify the ""blindspots"" of the classifiers; these are ultimately limited due to the human laborrequired and the finite nature of existing image examples. We propose asimulation-based approach for interrogating classifiers using generativeadversarial models in a systematic manner. We incorporate a progressiveconditional generative model for synthesizing photo-realistic facial images andBayesian Optimization for an efficient interrogation of independent facialimage classification systems. We show how this approach can be used toefficiently characterize racial and gender biases in commercial systems."
"187","arXiv:1906.11892","https://arxiv.org/abs/1906.11892","Fine-grained zero-shot recognition with metric rescaling","Boris N. Oreshkin, Negar Rostamzadeh, Pedro O. Pinheiro, Christopher Pal","We address the problem of learning fine-grained cross-modal representations.We propose an instance-based deep metric learning approach in joint visual andtextual space. On top of that, we derive a metric rescaling approach thatsolves a very common problem in the generalized zero-shot learning setting,i.e., classifying test images from unseen classes as one of the classes seenduring training. We evaluate our approach on two fine-grained zero-shotlearning datasets: CUB and FLOWERS. We find that on the generalized zero-shotclassification task the proposed approach consistently outperforms the existingapproaches on both datasets. We demonstrate that the proposed approach,notwithstanding its simplicity of implementation and training, is superior toall the recent state-of-the-art methods of which we are aware that use the sameevaluation framework."
"188","arXiv:1906.11893","https://arxiv.org/abs/1906.11893","HalalNet: A Deep Neural Network that Classifies the Halalness  Slaughtered Chicken from their Images","A. Elfakharany, R. Yusof, N. Ismail, R. Arfa, M. Yunus","Halal requirement in food is important for millions of Muslims worldwideespecially for meat and chicken products, insuring that slaughter houses adhereto this requirement is a challenging task to do manually. In this paper amethod is proposed that uses a camera that takes images of slaughtered chickenon the conveyor in a slaughter house, the images are then analyzed by a deepneural network to classify if the image is of a halal slaughtered chicken ornot. However, traditional deep learning models require large amounts of data totrain on, which in this case these amounts of data were challenging to collectespecially the images of non-halal slaughtered chicken, hence this paper showshow the use of one shot learning [1] and transfer learning [2] can reach highaccuracy on the few amounts of data that were available. The architecture usedis based on the Siamese neural networks architecture which ranks the similaritybetween two inputs [3] while using the Xception network [4] as the twinnetworks. We call it HalalNet. This work was done as part of SYCUT (syriahcompliant slaughtering system) which is a monitoring system that monitors thehalalness of the slaughtered chicken in a slaughter house. The data used totrain and validate HalalNet was collected from the Azain slaughtering site(Semenyih, Selangor, Malaysia) containing images of both halal and non-halalslaughtered chicken."
"189","arXiv:1906.11894","https://arxiv.org/abs/1906.11894","Labeling, Cutting, Grouping: an Efficient Text Line Segmentation Method  for Medieval Manuscripts","Michele Alberti, Lars Voeögtlin, Vinaychandran Pondenkandath, Mathias Seuret, Rolf Ingold, Marcus Liwicki","This paper introduces a new way for text-line extraction by integratingdeep-learning based pre-classification and state-of-the-art segmentationmethods. Text-line extraction in complex handwritten documents poses asignificant challenge, even to the most modern computer vision algorithms.Historical manuscripts are a particularly hard class of documents as theypresent several forms of noise, such as degradation, bleed-through, interlinearglosses, and elaborated scripts. In this work, we propose a novel method whichuses semantic segmentation at pixel level as intermediate task, followed by atext-line extraction step. We measured the performance of our method on arecent dataset of challenging medieval manuscripts and surpassedstate-of-the-art results by reducing the error by 80.7%. Furthermore, wedemonstrate the effectiveness of our approach on various other datasets writtenin different scripts. Hence, our contribution is two-fold. First, wedemonstrate that semantic pixel segmentation can be used as strong denoisingpre-processing step before performing text line extraction. Second, weintroduce a novel, simple and robust algorithm that leverages the high-qualitysemantic segmentation to achieve a text-line extraction performance of 99.42%line IU on a challenging dataset."
"190","arXiv:1906.11895","https://arxiv.org/abs/1906.11895","Classifying logistic vehicles in cities using Deep learning","Salma Benslimane, Simon Tamayo (CAOR), Arnaud de La Fortelle (CAOR)","Rapid growth in delivery and freight transportation is increasing in urbanareas; as a result the use of delivery trucks and light commercial vehicles isevolving. Major cities can use traffic counting as a tool to monitor thepresence of delivery vehicles in order to implement intelligent city planningmeasures. Classical methods for counting vehicles use mechanical,electromagnetic or pneumatic sensors, but these devices are costly, difficultto implement and only detect the presence of vehicles without givinginformation about their category, model or trajectory. This paper proposes aDeep Learning tool for classifying vehicles in a given image while consideringdifferent categories of logistic vehicles, namely: light-duty, medium-duty andheavy-duty vehicles. The proposed approach yields two main contributions: firstwe developed an architecture to create an annotated and balanced database oflogistic vehicles, reducing manual annotation efforts. Second, we built aclassifier that accurately classifies the logistic vehicles passing through agiven road. The results of this work are: first, a database of 72 000 imagesfor 4 vehicles classes; and second two retrained convolutional neural networks(InceptionV3 and MobileNetV2) capable of classifying vehicles with accuraciesover 90%."
"191","arXiv:1906.11897","https://arxiv.org/abs/1906.11897","On Physical Adversarial Patches for Object Detection","Mark Lee, Zico Kolter","In this paper, we demonstrate a physical adversarial patch attack againstobject detectors, notably the YOLOv3 detector. Unlike previous work on physicalobject detection attacks, which required the patch to overlap with the objectsbeing misclassified or avoiding detection, we show that a properly designedpatch can suppress virtually all the detected objects in the image. That is, wecan place the patch anywhere in the image, causing all existing objects in theimage to be missed entirely by the detector, even those far away from the patchitself. This in turn opens up new lines of physical attacks against objectdetection systems, which require no modification of the objects in a scene. Ademo of the system can be found at https://youtu.be/WXnQjbZ1e7Y."
"192","arXiv:1906.11899","https://arxiv.org/abs/1906.11899","Lidar based Detection and Classification of Pedestrians and Vehicles  Using Machine Learning Methods","Farzad Shafiei Dizaji","The goal of this paper is to classify objects mapped by LiDAR sensor intodifferent classes such as vehicles, pedestrians and bikers. Utilizing aLiDAR-based object detector and Neural Networks-based classifier, a novelreal-time object detection is presented essentially with respect to aidself-driving vehicles in recognizing and classifying other objects encounteredin the course of driving and proceed accordingly. We discuss our work usingmachine learning methods to tackle a common high-level problem found in machinelearning applications for self-driving cars: the classification of pointclouddata obtained from a 3D LiDAR sensor."
"193","arXiv:1906.11900","https://arxiv.org/abs/1906.11900","A database for face presentation attack using wax figure faces","Shan Jia, Chuanbo Hu, Guodong Guo, Zhengquan Xu","Compared to 2D face presentation attacks (e.g. printed photos and videoreplays), 3D type attacks are more challenging to face recognition systems(FRS) by presenting 3D characteristics or materials similar to real faces.Existing 3D face spoofing databases, however, mostly based on 3D masks, arerestricted to small data size or poor authenticity due to the productiondifficulty and high cost. In this work, we introduce the first wax figure facedatabase, WFFD, as one type of super-realistic 3D presentation attacks to spoofthe FRS. This database consists of 2200 images with both real and wax figurefaces (totally 4400 faces) with a high diversity from online collections.Experiments on this database first investigate the vulnerability of threepopular FRS to this kind of new attack. Further, we evaluate the performance ofseveral face presentation attack detection methods to show the attack abilitiesof this super-realistic face spoofing database."
"194","arXiv:1906.11901","https://arxiv.org/abs/1906.11901","Comparing Machine Learning Approaches for Table Recognition in  Historical Register Books","Stéphane Clinchant, Hervé Déjean, Jean-Luc Meunier, Eva Lang, Florian Kleber","We present in this paper experiments on Table Recognition in hand-writtenregistry books. We first explain how the problem of row and column detection ismodeled, and then compare two Machine Learning approaches (Conditional RandomField and Graph Convolutional Network) for detecting these table elements.Evaluation was conducted on death records provided by the Archive of theDiocese of Passau. Both methods show similar results, a 89 F1 score, a qualitywhich allows for Information Extraction. Software and dataset are opensource/data."
"195","arXiv:1906.11902","https://arxiv.org/abs/1906.11902","Video Action Classification Using PredNet","Roshan Rane, Vageesh Saxena, Edit Szügyi","In this paper, we evaluate the PredNet \cite{lotter16} on theSomething-something action data set \cite{farzaneh18} and implement thePredNet+, which we train in a multi-task fashion to output both classificationlabels and predictions. Our idea is to condition video prediction and actionclassification on each other. We discuss a series of observations about thePredNet and conclude that it does not completely follow the principles of thepredictive coding framework."
"196","arXiv:1906.11904","https://arxiv.org/abs/1906.11904","Effective degrees of freedom for surface finish defect detection and  classification","Natalya Pya Arnqvist, Blaise Ngendangenzwa, Eric Lindahl, Leif Nilsson, Jun Yu","One of the primary concerns of product quality control in the automotiveindustry is an automated detection of defects of small sizes on specular carbody surfaces. A new statistical learning approach is presented for surfacefinish defect detection based on spline smoothing method for feature extractionand $k$-nearest neighbour probabilistic classifier. Since the surfaces arespecular, structured lightning reflection technique is applied for imageacquisition. Reduced rank cubic regression splines are used to smooth the pixelvalues while the effective degrees of freedom of the obtained smooths serve ascomponents of the feature vector. A key advantage of the approach is that itallows reaching near zero misclassification error rate when applying standardlearning classifiers. We also propose probability based performance evaluationmetrics as alternatives to the conventional metrics. The usage of thoseprovides the means for uncertainty estimation of the predictive performance ofa classifier. Experimental classification results on the images obtained fromthe pilot system located at Volvo GTO Cab plant in Ume{\aa}, Sweden, show thatthe proposed approach is much more efficient than the compared methods."
"197","arXiv:1906.11905","https://arxiv.org/abs/1906.11905","A synthetic dataset for deep learning","Xinjie Lan","In this paper, we propose a novel method for generating a synthetic datasetobeying Gaussian distribution. Compared to the commonly used benchmark datasetswith unknown distribution, the synthetic dataset has an explicit distribution,i.e., Gaussian distribution. Meanwhile, it has the same characteristics as thebenchmark dataset MNIST. As a result, we can easily apply Deep Neural Networks(DNNs) on the synthetic dataset. This synthetic dataset provides a novelexperimental tool to verify the proposed theories of deep learning."
"198","arXiv:1906.11906","https://arxiv.org/abs/1906.11906","Data Extraction from Charts via Single Deep Neural Network","Xiaoyi Liu, Diego Klabjan, Patrick NBless","Automatic data extraction from charts is challenging for two reasons: thereexist many relations among objects in a chart, which is not a commonconsideration in general computer vision problems; and different types ofcharts may not be processed by the same model. To address these problems, wepropose a framework of a single deep neural network, which consists of objectdetection, text recognition and object matching modules. The framework handlesboth bar and pie charts, and it may also be extended to other types of chartsby slight revisions and by augmenting the training data. Our model performssuccessfully on 79.4% of test simulated bar charts and 88.0% of test simulatedpie charts, while for charts outside of the training domain it degrades for57.5% and 62.3%, respectively."
"199","arXiv:1906.11907","https://arxiv.org/abs/1906.11907","Learning from Discovering: An unsupervised approach to Geographical  Knowledge Discovery using street level and street network images","Stephen Law, Mateo Neira","Recent researches have shown the increasing use of machine learning methodsin geography and urban analytics, primarily to extract features and patternsfrom spatial and temporal data. Research, integrating geographical processes inmachine learning models and, leveraging on geographical information to betterinterpret these methods had been sparse. This research contributes to theladder, where we show how latent variables learned from unsupervised learningmethods can be used for geographic knowledge discovery. In particular, wepropose a simple and novel approach called Convolutional-PCA (ConvPCA) whichare applied on both street level and street network images in finding a set ofuncorrelated visual latent responses. The approach allows for meaningfulexplanations using a combination of, geographical and generative visualizationsto explore the latent space, and to show how the learned embeddings can be usedto predict urban characteristics such as street-level enclosures and streetnetwork density."
"200","arXiv:1906.11912","https://arxiv.org/abs/1906.11912","A New Compensatory Genetic Algorithm-Based Method for Effective  Compressed Multi-function Convolutional Neural Network Model Selection with  Multi-Objective Optimization","Luna M. Zhang","In recent years, there have been many popular Convolutional Neural Networks(CNNs), such as Google's Inception-V4, that have performed very well forvarious image classification problems. These commonly used CNN models usuallyuse the same activation function, such as RELU, for all neurons in theconvolutional layers; they are ""Single-function CNNs."" However, SCNNs may notalways be optimal. Thus, a ""Multi-function CNN"" (MCNN), which uses differentactivation functions for different neurons, has been shown to outperform aSCNN. Also, CNNs typically have very large architectures that use a lot ofmemory and need a lot of data in order to be trained well. As a result, theytend to have very high training and prediction times too. An important researchproblem is how to automatically and efficiently find the best CNN with bothhigh classification performance and compact architecture with high training andprediction speeds, small power usage, and small memory size for any imageclassification problem. It is very useful to intelligently find an effective,fast, energy-efficient, and memory-efficient ""Compressed Multi-function CNN""(CMCNN) from a large number of candidate MCNNs. A new compensatory algorithmusing a new genetic algorithm (GA) is created to find the best CMCNN with anideal compensation between performance and architecture size. The optimal CMCNNhas the best performance and the smallest architecture size. Simulations usingthe CIFAR10 dataset showed that the new compensatory algorithm could findCMCNNs that could outperform non-compressed MCNNs in terms of classificationperformance (F1-score), speed, power usage, and memory usage. Other effective,fast, power-efficient, and memory-efficient CMCNNs based on popular CNNarchitectures will be developed for image classification problems in importantreal-world applications, such as brain informatics and biomedical imaging."
"201","arXiv:1906.11914","https://arxiv.org/abs/1906.11914","Tag Clouds for Object-Oriented Source Code Visualization","Ra'Fat Al-Msie'deen","Software visualization helps software engineers to understand and manage thesize and complexity of the object-oriented source code. The tag cloud is asimple and popular visualization technique. The main idea of the tag cloud isto represent tags according to their frequency in an alphabetical order wherethe most important tags are highlighted via a suitable font size. This paperproposes an original approach to visualize software code using a tag cloud. Theapproach exploits all software identifier names to visualize software code as atag cloud. Experiments were conducted on several case studies. To validate theapproach, it is applied on NanoXML and ArgoUML. The results of this evaluationvalidate the relevance and the performance of the proposed approach as all tagnames and their frequencies were correctly identified. The proposed tag cloudvisualization technique is a helpful addition to the software visualizationtoolkit. The extracted tag cloud supports software engineers as they filter andbrowse data."
"202","arXiv:1906.11915","https://arxiv.org/abs/1906.11915","Mixed-Signal Charge-Domain Acceleration of Deep Neural networks through  Interleaved Bit-Partitioned Arithmetic","Soroush Ghodrati, Hardik Sharma, Sean Kinzer, Amir Yazdanbakhsh, Kambiz Samadi, Nam Sung Kim, Doug Burger, Hadi Esmaeilzadeh","Low-power potential of mixed-signal design makes it an alluring option toaccelerate Deep Neural Networks (DNNs). However, mixed-signal circuitry suffersfrom limited range for information encoding, susceptibility to noise, andAnalog to Digital (A/D) conversion overheads. This paper aims to address thesechallenges by offering and leveraging the insight that a vector dot-product(the basic operation in DNNs) can be bit-partitioned into groups of spatiallyparallel low-bitwidth operations, and interleaved across multiple elements ofthe vectors. As such, the building blocks of our accelerator become a group ofwide, yet low-bitwidth multiply-accumulate units that operate in the analogdomain and share a single A/D converter. The low-bitwidth operation tackles theencoding range limitation and facilitates noise mitigation. Moreover, weutilize the switched-capacitor design for our bit-level reformulation of DNNoperations. The proposed switched-capacitor circuitry performs the groupmultiplications in the charge domain and accumulates the results of the groupin its capacitors over multiple cycles. The capacitive accumulation combinedwith wide bit-partitioned operations alleviate the need for A/D conversion peroperation. With such mathematical reformulation and its switched-capacitorimplementation, we define a 3D-stacked microarchitecture, dubbed BIHIWE."
"203","arXiv:1906.11922","https://arxiv.org/abs/1906.11922","An Improved CF-MAC Protocol for VANET","Ghassan Samara","Vehicular Ad hoc Network (VANET) is one of the emerging research areas in themobile computing field which is considered as a future technology and promisingtopic in the computer science and computer networks. Which provides roadsafety, updated traffic information, and infotainment. VANET consists of alarge number of vehicles moving in high speeds while broadcasting importantinformation like safety and control information which must be sent with highpriority. Crowded networks like VANET having many vehicles competing to reservethe channel to send critical information which may lead to high collisionscenarios, and therefore, there must be a protocol to send this kind ofinformation with high reliability, low data loss and with no collision. In thisresearch a collision-free protocol will be proposed to manage the channelaccess among competing vehicles to eliminate the collisions which occur rapidlyin VANET especially in dense situations, the proposed protocol hereinafter willbe called (I-MAC) protocol expected to enhance the channel performance, achieveload balancing, fairness, and decrease message loss and enhance reliability,The evaluation criteria will examine the channel throughput, message delay, andmessage loss; the results show that the overall channel performance with regardto collision and packet loss ratio is improved."
"204","arXiv:1906.11927","https://arxiv.org/abs/1906.11927","Homography from two orientation- and scale-covariant features","Daniel Barath, Zuzana Kukelova","This paper proposes a geometric interpretation of the angles and scales whichthe orientation- and scale-covariant feature detectors, e.g. SIFT, provide. Twonew general constraints are derived on the scales and rotations which can beused in any geometric model estimation tasks. Using these formulas, two newconstraints on homography estimation are introduced. Exploiting the derivedequations, a solver for estimating the homography from the minimal number oftwo correspondences is proposed. Also, it is shown how the normalization of thepoint correspondences affects the rotation and scale parameters, thus achievingnumerically stable results. Due to requiring merely two feature pairs, robustestimators, e.g. RANSAC, do significantly fewer iterations than by using thefour-point algorithm. When using covariant features, e.g. SIFT, the informationabout the scale and orientation is given at no cost. The proposed homographyestimation method is tested in a synthetic environment and on publiclyavailable real-world datasets."
"205","arXiv:1906.11929","https://arxiv.org/abs/1906.11929","Invariant Detection with Program Verification Tools","Wei He","Compilers can specialize programs having invariants for performanceimprovement. Detecting program invariants that span large and complex code,however, is difficult for compilers. Traditional compilers do not perform veryexpensive analysis and thus only identify limited invariants, which limits thepotential of subsequent optimizations. We would like to address the invariantdetection problem via more sophisticated analyses using program verificationtools. In this paper, we reveal pitfalls of choosing program verification toolsfor invariant detection, identify challenges of modeling program behavior usingone of these tools---CVC4, and propose some ideas about how to address thechallenges."
"206","arXiv:1906.11930","https://arxiv.org/abs/1906.11930","Training Models to Extract Treatment Plans from Clinical Notes Using  Contents of Sections with Headings","Ananya Poddar, Bharath Dandala, Murthy Devarakonda","Objective: Using natural language processing (NLP) to find sentences thatstate treatment plans in a clinical note, would automate plan extraction andwould further enable their use in tools that help providers and care managers.However, as in the most NLP tasks on clinical text, creating gold standard totrain and test NLP models is tedious and expensive. Fortuitously, sometimes butnot always clinical notes contain sections with a heading that identifies thesection as a plan. Leveraging contents of such labeled sections as a noisytraining data, we assessed accuracy of NLP models trained with the data.Methods: We used common variations of plan headings and rule-based heuristicsto find plan sections with headings in clinical notes, and we extractedsentences from them and formed a noisy training data of plan sentences. Wetrained Support Vector Machine (SVM) and Convolutional Neural Network (CNN)models with the data. We measured accuracy of the trained models on the noisydataset using ten-fold cross validation and separately on a set-aside manuallyannotated dataset.Results: About 13% of 117,730 clinical notes contained treatment planssections with recognizable headings in the 1001 longitudinal patient recordsthat were obtained from Cleveland Clinic under an IRB approval. We were able toextract and create a noisy training data of 13,492 plan sentences from theclinical notes. CNN achieved best F measures, 0.91 and 0.97 in thecross-validation and set-aside evaluation experiments respectively. SVMslightly underperformed with F measures of 0.89 and 0.96 in the sameexperiments.Conclusion: Our study showed that the training supervised learning modelsusing noisy plan sentences was effective in identifying them in all clinicalnotes. More broadly, sections with informal headings in clinical notes can be agood source for generating effective training data."
"207","arXiv:1906.11932","https://arxiv.org/abs/1906.11932","To Act or React: Investigating Proactive Strategies For Online Community  Moderation","Hussam Habib, Maaz Bin Musa, Fareed Zaffar, Rishab Nithyanand","Reddit administrators have generally struggled to prevent or contain suchdiscourse for several reasons including: (1) the inability for a handful ofhuman administrators to track and react to millions of posts and comments perday and (2) fear of backlash as a consequence of administrative decisions toban or quarantine hateful communities. Consequently, as shown in our backgroundresearch, administrative actions (community bans and quarantines) are oftentaken in reaction to media pressure following offensive discourse within acommunity spilling into the real world with serious consequences. In thispaper, we investigate the feasibility of proactive moderation on Reddit --i.e., proactively identifying communities at risk of committing offenses thatpreviously resulted in bans for other communities. Proactive moderationstrategies show promise for two reasons: (1) they have potential to narrow downthe communities that administrators need to monitor for hateful content and (2)they give administrators a scientific rationale to back their administrativedecisions and interventions. Our work shows that communities are constantlyevolving in their user base and topics of discourse and that evolution intohateful or dangerous (i.e., considered bannable by Reddit administrators)communities can often be predicted months ahead of time. This makes proactivemoderation feasible. Further, we leverage explainable machine learning to helpidentify the strongest predictors of evolution into dangerous communities. Thisprovides administrators with insights into the characteristics of communitiesat risk becoming dangerous or hateful. Finally, we investigate, at scale, theimpact of participation in hateful and dangerous subreddits and theeffectiveness of community bans and quarantines on the behavior of members ofthese communities."
"208","arXiv:1906.11938","https://arxiv.org/abs/1906.11938","Playing Adaptively Against Stealthy Opponents: A Reinforcement Learning  Strategy for the FlipIt Security Game","Lisa Oakley, Alina Oprea","A rise in Advanced Persistant Threats (APTs) has introduced a need forrobustness against long-running, stealthy attacks which circumvent existingcryptographic security guarantees. FlipIt is a security game that models theattacker-defender interactions in advanced scenarios such as APTs. Previouswork analyzed extensively non-adaptive strategies in FlipIt, but adaptivestrategies rise naturally in practical interactions as players receive feedbackduring the game. We model the FlipIt game as a Markov Decision Process and usereinforcement learning algorithms to design adaptive strategies. We provetheoretical results on the convergence of our new strategy against an opponentplaying with a Periodic strategy. We confirm our analysis experimentally byextensive evaluation of the strategy against specific opponents. Our strategiesconverge to the optimal adaptive strategy for Periodic and Exponentialopponents. Finally, we introduce a generalized Q-Learning strategy withcomposite states that outperforms a Greedy-based strategy for severaldistributions, including Periodic and Uniform, without prior knowledge of theopponent's strategy."
"209","arXiv:1906.11940","https://arxiv.org/abs/1906.11940","What Do Developers Ask About ML Libraries? A Large-scale Study Using  Stack Overflow","Md Johirul Islam, Hoan Anh Nguyen, Rangeet Pan, Hridesh Rajan","Modern software systems are increasingly including machine learning (ML) asan integral component. However, we do not yet understand the difficulties facedby software developers when learning about ML libraries and using them withintheir systems. To that end, this work reports on a detailed (manual)examination of 3,243 highly-rated Q&A posts related to ten ML libraries, namelyTensorflow, Keras, scikit-learn, Weka, Caffe, Theano, MLlib, Torch, Mahout, andH2O, on Stack Overflow, a popular online technical Q&A forum. We classify thesequestions into seven typical stages of an ML pipeline to understand thecorrelation between the library and the stage. Then we study the questions andperform statistical analysis to explore the answer to four research objectives(finding the most difficult stage, understanding the nature of problems, natureof libraries and studying whether the difficulties stayed consistent overtime). Our findings reveal the urgent need for software engineering (SE)research in this area. Both static and dynamic analyses are mostly absent andbadly needed to help developers find errors earlier. While there has been someearly research on debugging, much more work is needed. API misuses areprevalent and API design improvements are sorely needed. Last and somewhatsurprisingly, a tug of war between providing higher levels of abstractions andthe need to understand the behavior of the trained model is prevalent."
"210","arXiv:1906.11941","https://arxiv.org/abs/1906.11941","Quantile Regression Deep Reinforcement Learning","Oliver Richter, Roger Wattenhofer","Policy gradient based reinforcement learning algorithms coupled with neuralnetworks have shown success in learning complex policies in the model freecontinuous action space control setting. However, explicitly parameterizedpolicies are limited by the scope of the chosen parametric probabilitydistribution. We show that alternatively to the likelihood based policygradient, a related objective can be optimized through advantage weightedquantile regression. Our approach models the policy implicitly in the network,which gives the agent the freedom to approximate any distribution in eachaction dimension, not limiting its capabilities to the commonly used unimodalGaussian parameterization. This broader spectrum of policies makes ouralgorithm suitable for problems where Gaussian policies cannot fit the optimalpolicy. Moreover, our results on the MuJoCo physics simulator benchmarks arecomparable or superior to state-of-the-art on-policy methods."
"211","arXiv:1906.11942","https://arxiv.org/abs/1906.11942","Datasets for Face and Object Detection in Fisheye Images","Jianglin Fu, Ivan V. Bajic, Rodney G. Vaughan","We present two new fisheye image datasets for training face and objectdetection models: VOC-360 and Wider-360. The fisheye images are created bypost-processing regular images collected from two well-known datasets, VOC2012and Wider Face, using a model for mapping regular to fisheye images implementedin Matlab. VOC-360 contains 39,575 fisheye images for object detection,segmentation, and classification. Wider-360 contains 63,897 fisheye images forface detection. These datasets will be useful for developing face and objectdetectors as well as segmentation modules for fisheye images while the effortsto collect and manually annotate true fisheye images are underway."
"212","arXiv:1906.11943","https://arxiv.org/abs/1906.11943","Findings of the First Shared Task on Machine Translation Robustness","Xian Li, Paul Michel, Antonios Anastasopoulos, Yonatan Belinkov, Nadir Durrani, Orhan Firat, Philipp Koehn, Graham Neubig, Juan Pino, Hassan Sajjad","We share the findings of the first shared task on improving robustness ofMachine Translation (MT). The task provides a testbed representing challengesfacing MT models deployed in the real world, and facilitates new approaches toimprove models; robustness to noisy input and domain mismatch. We focus on twolanguage pairs (English-French and English-Japanese), and the submitted systemsare evaluated on a blind test set consisting of noisy comments on Reddit andprofessionally sourced translations. As a new task, we received 23 submissionsby 11 participating teams from universities, companies, national labs, etc. Allsubmitted systems achieved large improvements over baselines, with the bestimprovement having +22.33 BLEU. We evaluated submissions by both human judgmentand automatic evaluation (BLEU), which shows high correlations (Pearson's r =0.94 and 0.95). Furthermore, we conducted a qualitative analysis of thesubmitted systems using compare-mt, which revealed their salient differences inhandling challenges in this task. Such analysis provides additional insightswhen there is occasional disagreement between human judgment and BLEU, e.g.systems better at producing colloquial expressions received higher score fromhuman judgment."
"213","arXiv:1906.11945","https://arxiv.org/abs/1906.11945","Error bounds for deep ReLU networks using the Kolmogorov--Arnold  superposition theorem","Hadrien Montanelli, Haizhao Yang","We prove a theorem concerning the approximation of multivariate continuousfunctions by deep ReLU networks, for which the curse of the dimensionality islessened. Our theorem is based on the Kolmogorov--Arnold superposition theorem,and on the approximation of the inner and outer functions that appear in thesuperposition by very deep ReLU networks."
"214","arXiv:1906.11946","https://arxiv.org/abs/1906.11946","LApps: Technological, Legal and Market Potentials of Blockchain  Lightning Network Applications","Mahdi H. Miraz, David C. Donald","Following in the footsteps of pioneer Bitcoin, many altcoins as well ascoloured coins have been being developed and merchandised adopting blockchainas the core enabling technology. However, since interoperability andscalability, due to high and capped (in particular cases) transaction latencyare deep-rooted in the architecture of blockchain technology, they are bydefault inherited in any blockchain based applications. Lightning Network (LN)is one of the supporting technologies developed to eliminate this impediment ofblockchain technology by facilitating instantaneous transfers of cryptos. Sincethe potentials of LN is still relatively unknown, this paper investigates thecurrent states of development along with possible non-monetary usage of LN,especially in settlement coloured coins such as securities, as well as creationof new business models based on Lightning Applications (LApps) and microchannelpayments as well as micro-trades. The legal challenges that may act asimpediment to the adoption of LN is also discussed."
"215","arXiv:1906.11948","https://arxiv.org/abs/1906.11948","Packing Boundary-Anchored Rectangles and Squares","Therese Biedl, Ahmad Biniaz, Anil Maheshwari, Saeed Mehrabi","Consider a set $P$ of $n$ points on the boundary of an axis-aligned square$Q$. We study the boundary-anchored packing problem on $P$ in which the goal isto find a set of interior-disjoint axis-aligned rectangles in $Q$ such thateach rectangle is anchored (has a corner at some point in $P$), each point in$P$ is used to anchor at most one rectangle, and the total area of therectangles is maximized. Here, a rectangle is anchored at a point $p$ in $P$ ifone of its corners coincides with $p$. In this paper, we show how to solve thisproblem in time linear in $n$, provided that the points of $P$ are given insorted order along the boundary of $Q$. We also consider the problem foranchoring squares and give an $O(n^4)$-time algorithm when the points in $P$lie on two opposite sides of $Q$."
"216","arXiv:1906.11951","https://arxiv.org/abs/1906.11951","Supervise Thyself: Examining Self-Supervised Representations in  Interactive Environments","Evan Racah, Christopher Pal","Self-supervised methods, wherein an agent learns representations solely byobserving the results of its actions, become crucial in environments which donot provide a dense reward signal or have labels. In most cases, such methodsare used for pretraining or auxiliary tasks for ""downstream"" tasks, such ascontrol, exploration, or imitation learning. However, it is not clear whichmethod's representations best capture meaningful features of the environment,and which are best suited for which types of environments. We present asmall-scale study of self-supervised methods on two visual environments: FlappyBird and Sonic The Hedgehog. In particular, we quantitatively evaluate therepresentations learned from these tasks in two contexts: a) the extent towhich the representations capture true state information of the agent and b)how generalizable these representations are to novel situations, like newlevels and textures. Lastly, we evaluate these self-supervised features byvisualizing which parts of the environment they focus on. Our results show thatthe utility of the representations is highly dependent on the visuals anddynamics of the environment."
"217","arXiv:1906.11957","https://arxiv.org/abs/1906.11957","Variational Mandible Shape Completion for Virtual Surgical Planning","Amir H. Abdi, Mehran Pesteie, Eitan Prisman, Purang Abolmaesumi, Sidney Fels","The premorbid geometry of the mandible is of significant relevance in jawreconstructive surgeries and occasionally unknown to the surgical team. In thispaper, an optimization framework is introduced to train deep models forcompletion (reconstruction) of the missing segments of the bone based on theremaining healthy structure. To leverage the contextual information of thesurroundings of the dissected region, the voxel-weighted Dice loss isintroduced. To address the non-deterministic nature of the shape completionproblem, we leverage a weighted multi-target probabilistic solution which is anextension to the conditional variational autoencoder (CVAE). This approachconsiders multiple targets as acceptable reconstructions, each weightedaccording to their conformity with the original shape. We quantify theperformance gain of the proposed method against similar algorithms, includingCVAE, where we report statistically significant improvements in bothdeterministic and probabilistic paradigms. The probabilistic model is alsoevaluated on its ability to generate anatomically relevant variations for themissing bone. As a unique aspect of this work, the model is tested on realsurgical cases where the clinical relevancy of its reconstructions and theircompliance with surgeon's virtual plan are demonstrated as necessary stepstowards clinical adoption."
"218","arXiv:1906.12167","https://arxiv.org/abs/1906.12167","Gray Level Image Threshold Using Neutrosophic Shannon Entropy","Vasile Patrascu","This article presents a new method of segmenting grayscale images byminimizing Shannon's neutrosophic entropy. For the proposed segmentationmethod, the neutrosophic information components, i.e., the degree of truth, thedegree of neutrality and the degree of falsity are defined taking into accountthe belonging to the segmented regions and at the same time to the separationthreshold area. The principle of the method is simple and easy to understandand can lead to multiple thresholds. The efficacy of the method is illustratedusing some test gray level images. The experimental results show that theproposed method has good performance for segmentation with optimal gray levelthresholds."
"219","arXiv:1906.11960","https://arxiv.org/abs/1906.11960","Studying the Impact of Mood on Identifying Smartphone Users","Khadija Zanna, Sayde King, Tempestt Neal, Shaun Canavan","This paper explores the identification of smartphone users when certainsamples collected while the subject felt happy, upset or stressed were absentor present. We employ data from 19 subjects using the StudentLife dataset, adataset collected by researchers at Dartmouth College that was originallycollected to correlate behaviors characterized by smartphone usage patternswith changes in stress and academic performance. Although many previous workson behavioral biometrics have implied that mood is a source of intra-personvariation which may impact biometric performance, our results contradict thisassumption. Our findings show that performance worsens when removing samplesthat were generated when subjects may be happy, upset, or stressed. Thus, thereis no indication that mood negatively impacts performance. However, we do findthat changes existing in smartphone usage patterns may correlate with mood,including changes in locking, audio, location, calling, homescreen, and e-mailhabits. Thus, we show that while mood is a source of intra-person variation, itmay be an inaccurate assumption that biometric systems (particularly, mobilebiometrics) are likely influenced by mood."
"220","arXiv:1906.11964","https://arxiv.org/abs/1906.11964","OpenCitations","Silvio Peroni, David Shotton","OpenCitations is a scholarly infrastructure organization dedicated to openscholarship and the publication of open bibliographic and citation data asLinked Open Data using Semantic Web technologies, to the development ofsoftware tools and services that enable convenient access to these open data,and to community advocacy for open citations.This paper describes OpenCitations and its datasets, tools, services andactivities. It introduces the OpenCitations Data Model and the SPAR (SemanticPublishing and Referencing) Ontologies for encoding scholarly bibliographic andcitation data in RDF, and OpenCitations' open software of generic applicabilityfor searching, browsing and providing REST APIs over RDF triplestores. Itdescribes Open Citation Identifiers (OCIs), globally unique and persistentidentifiers for bibliographic citations, and the OpenCitations OCI ResolutionService that returns bibliographic and citation metadata when queried with anOCI. And it describes the OpenCitations Corpus (OCC), a database of opendownloadable bibliographic and citation data harvested from bibliographicreferences in the scholarly literature and made available in RDF under aCreative Commons public domain dedication. Finally, it outlines the OpenCitation Indexes of citation data openly available in third-party bibliographicdatabases that OpenCitations is currently making available as Linked OpenDatasets accessible via its REST API, of which the first and largest is COCI,the OpenCitations Index of Crossref DOI-to-DOI Citations which currentlycontains over 445 million bibliographic citations."
"221","arXiv:1906.11966","https://arxiv.org/abs/1906.11966","[1,2]-Domination in Generalized Petersen Graphs","Fairouz Beggas, Volker Turau, Mohammed Haddad, Hamamache Kheddouci","A vertex subset $S$ of a graph $G=(V,E)$ is a $[1,2]$-dominating set if eachvertex of $V\backslash S$ is adjacent to either one or two vertices in $S$. Theminimum cardinality of a $[1,2]$-dominating set of $G$, denoted by$\gamma_{[1,2]}(G)$, is called the $[1,2]$-domination number of $G$. In thispaper the $[1,2]$-domination and the $[1,2]$-total domination numbers of thegeneralized Petersen graphs $P(n,2)$ are determined."
"222","arXiv:1906.11970","https://arxiv.org/abs/1906.11970","On nested and 2-nested graphs: two subclasses of graphs between  threshold and split graphs","Nina Pardal, Guillermo A. Durán, Luciano N. Grippo, Martín D. Safe","A $(0,1)$-matrix has the Consecutive Ones Property (C1P) for the rows ifthere is a permutation of its columns such that the ones in each row appearconsecutively. We say a $(0, 1)$-matrix is nested if it has the consecutiveones property for the rows (C1P) and every two rows are either disjoint ornested. We say a $(0, 1)$-matrix is 2-nested if it has the C1P and admits apartition of its rows into two sets such that the submatrix induced by each ofthese sets is nested. We say a split graph $G$ with split partition $(K, S)$ isnested (resp.\ 2-nested) if the matrix $A(S, K)$ which indicates the adjacencybetween vertices in $S$ and $K$ is nested (resp.\ 2-nested). In this work, wecharacterize nested and 2-nested matrices by minimal forbidden submatrices.This characterization leads to a minimal forbidden induced subgraphcharacterization for these classes of graphs, which are a superclass ofthreshold graphs and a subclass of split and circle graphs."
"223","arXiv:1906.11976","https://arxiv.org/abs/1906.11976","Multivariate Big Data Analysis for Intrusion Detection: 5 steps from the  haystack to the needle","José Camacho, José Manuel García-Giménez, Noemí Marta Fuentes-García, Gabriel Maciá-Fernández","The research literature on cybersecurity incident detection & response isvery rich in automatic detection methodologies, in particular those based onthe anomaly detection paradigm. However, very little attention has been devotedto the diagnosis ability of the methods, aimed to provide useful information onthe causes of a given detected anomaly. This information is of utmostimportance for the security team to reduce the time from detection to response.In this paper, we present Multivariate Big Data Analysis (MBDA), a completeintrusion detection approach based on 5 steps to effectively handle massiveamounts of disparate data sources. The approach has been designed to deal withthe main characteristics of Big Data, that is, the high volume, velocity andvariety. The core of the approach is the Multivariate Statistical NetworkMonitoring (MSNM) technique proposed in a recent paper. Unlike in state of theart machine learning methodologies applied to the intrusion detection problem,when an anomaly is identified in MBDA the output of the system includes thedetail of the logs of raw information associated to this anomaly, so that thesecurity team can use this information to elucidate its root causes. MBDA isbased in two open software packages available in Github: the MEDA Toolbox andthe FCParser. We illustrate our approach with two case studies. The first onedemonstrates the application of MBDA to semistructured sources of information,using the data from the VAST 2012 mini challenge 2. This complete case study issupplied in a virtual machine available for download. In the second case studywe show the Big Data capabilities of the approach in data collected from a realnetwork with labeled attacks."
"224","arXiv:1906.11979","https://arxiv.org/abs/1906.11979","A Utility-Preserving GAN for Face Obscuration","Hanxiang Hao, David Güera, Amy R. Reibman, Edward J. Delp","From TV news to Google StreetView, face obscuration has been used for privacyprotection. Due to recent advances in the field of deep learning, obscurationmethods such as Gaussian blurring and pixelation are not guaranteed to concealidentity. In this paper, we propose a utility-preserving generative model,UP-GAN, that is able to provide an effective face obscuration, while preservingfacial utility. By utility-preserving we mean preserving facial features thatdo not reveal identity, such as age, gender, skin tone, pose, and expression.We show that the proposed method achieves the best performance in terms ofobscuration and utility preservation."
"225","arXiv:1906.11981","https://arxiv.org/abs/1906.11981","Convolution Based Spectral Partitioning Architecture for Hyperspectral  Image Classification","Ringo S.W. Chu, Ho-Cheung Ng, Xiwei Wang, Wayne Luk","Hyperspectral images (HSIs) can distinguish materials with high number ofspectral bands, which is widely adopted in remote sensing applications andbenefits in high accuracy land cover classifications. However, HSIs processingare tangled with the problem of high dimensionality and limited amount oflabelled data. To address these challenges, this paper proposes a deep learningarchitecture using three dimensional convolutional neural networks withspectral partitioning to perform effective feature extraction. We conductexperiments using Indian Pines and Salinas scenes acquired by NASA AirborneVisible/Infra-Red Imaging Spectrometer. In comparison to prior results, ourarchitecture shows competitive performance for classification results overcurrent methods."
"226","arXiv:1906.11992","https://arxiv.org/abs/1906.11992","BTEL: A Binary Tree Encoding Approach for Visual Localization","Huu Le, Tuan Hoang, Michael Milford","Visual localization algorithms have achieved significant improvements inperformance thanks to recent advances in camera technology and vision-basedtechniques. However, there remains one critical caveat: all current approachesthat are based on image retrieval currently scale at best linearly with thesize of the environment with respect to both storage, and consequentially inmost approaches, query time. This limitation severely curtails the capabilityof autonomous systems in a wide range of compute, power, storage, size, weightor cost constrained applications such as drones. In this work, we present anovel binary tree encoding approach for visual localization which can serve asan alternative for existing quantization and indexing techniques. The proposedtree structure allows us to derive a compressed training scheme that achievessub-linearity in both required storage and inference time. The encoding memorycan be easily configured to satisfy different storage constraints. Moreover,our approach is amenable to an optional sequence filtering mechanism to furtherimprove the localization results, while maintaining the same amount of storage.Our system is entirely agnostic to the front-end descriptors, allowing it to beused on top of recent state-of-the-art image representations. Experimentalresults show that the proposed method significantly outperformsstate-of-the-art approaches under limited storage constraints."
"227","arXiv:1906.11993","https://arxiv.org/abs/1906.11993","Privacy-Preserving Distributed Learning with Secret Gradient Descent","Valentin Hartmann, Robert West","In many important application domains of machine learning, data is aprivacy-sensitive resource. In addition, due to the growing complexity of themodels, single actors typically do not have sufficient data to train a model ontheir own. Motivated by these challenges, we propose Secret Gradient Descent(SecGD), a method for training machine learning models on data that is spreadover different clients while preserving the privacy of the training data. Weachieve this by letting each client add temporary noise to the information theysend to the server during the training process. They also share this noise inseparate messages with the server, which can then subtract it from thepreviously received values. By routing all data through an anonymizationnetwork such as Tor, we prevent the server from knowing which messagesoriginate from the same client, which in turn allows us to show that breaking aclient's privacy is computationally intractable as it would require solving ahard instance of the subset sum problem. This setup allows SecGD to work in thepresence of only two honest clients and a malicious server, and without theneed for peer-to-peer connections."
"228","arXiv:1906.11994","https://arxiv.org/abs/1906.11994","Adversarial Representation Learning on Large-Scale Bipartite Graphs","Chaoyang He, Tian Xie, Yu Rong, Wenbing Huang, Junzhou Huang, Xiang Ren, Cyrus Shahabi","Graph representation on large-scale bipartite graphs is central for a varietyof applications, ranging from social network analysis to recommendation systemdevelopment. Existing methods exhibit two key drawbacks: 1. unable tocharacterize the inconsistency of the node features within thebipartite-specific structure; 2. unfriendly to support large-scale bipartitegraphs. To this end, we propose ABCGraph, a scalable model for unsupervisedlearning on large-scale bipartite graphs. At its heart, ABCGraph utilizes theproposed Bipartite Graph Convolutional Network (BGCN) as the encoder andadversarial learning as the training loss to learn representations from nodesin two different domains and bipartite structures, in an unsupervised manner.Moreover, we devise a cascaded architecture to capture the multi-hoprelationship in bipartite structure and improves the scalability as well.Extensive experiments on multiple datasets of varying scales verify theeffectiveness of ABCGraph compared to state-of-the-arts. For the experiment ona real-world large-scale bipartite graph system, fast training speed and lowmemory cost demonstrate the scalability of ABCGraph model."
"229","arXiv:1906.11999","https://arxiv.org/abs/1906.11999","Efficient Spatial Anti-Aliasing Rendering for Line Joins on Vector Maps","Chaoyang He, Ming Li","The spatial anti-aliasing technique for line joins (intersections of the roadsegments) on vector maps is exclusively crucial to visual experience and systemperformance. Due to limitations of OpenGL API, one common practice to achievethe anti-aliased effect is splicing multiple triangles at varying scale levelsto approximate the fan-shaped line joins. However, this approximationinevitably produces some unreality, and the system rendering performance is notoptimal. To circumvent these drawbacks, in this paper, we propose a simple butefficient algorithm which uses only two triangles to substitute the multipletriangles approximation and then renders a realistic fan-shaped curve withalpha operation based on geometrical relation computing. Our experiment showsit has advantages of a realistic anti-aliasing effect, less memory cost, higherframe rate, and drawing line joins without overlapping rendering. Our proposedspatial anti-aliasing technique has been widely used in Internet Maps such asTencent Mobile Maps and Tencent Automotive Maps."
"230","arXiv:1906.12001","https://arxiv.org/abs/1906.12001","Towards Large-Scale Autonomous Wireless Sensor Networks","Francesco Fraternali","Wireless Sensor Networks (WSNs) have the goal of gathering data from theenvironment. The advent of the Internet of Things (IoT) drastically changedWSN's vision that, as never before, needs to expand and include hundreds orthousands of sensors. But to follow the current IoT trends new techniques needto be implemented since orders of thousands of sensor nodes are not manageableby today's WSNs systems that often rely on manual configuration and hence arenot practical. As an example, the replacement of batteries of thousand of nodescould be extremely arduous or even impossible for structural health monitoringof civil infrastructures (i.e. bridges, towers). Hence, the solution to thegrowing burden of the system manager is automation, allowing the system tocheck its own status, to re-configure itself and fix the major problems in thenetwork whenever it is possible. In this paper, we present and discuss the mainfeatures needed to achieve an autonomous large scale WSN. Furthermore, wecompare these features with the state of the art of real-world large scale WSNdeployments showing that further solutions are needed to drastically reducehuman intervention while guaranteeing the main functionalities of the system."
"231","arXiv:1906.12005","https://arxiv.org/abs/1906.12005","Rényi Fair Inference","Sina Baharlouei, Maher Nouiehed, Meisam Razaviyayn","Machine learning algorithms have been increasingly deployed in criticalautomated decision-making systems that directly affect human lives. When thesealgorithms are only trained to minimize the training/test error, they couldsuffer from systematic discrimination against individuals based on theirsensitive attributes such as gender or race. Recently, there has been a surgein machine learning society to develop algorithms for fair machine learning. Inparticular, many adversarial learning procedures have been proposed to imposefairness. Unfortunately, these algorithms either can only impose fairness up tofirst-order dependence between the variables, or they lack computationalconvergence guarantees. In this paper, we use R\'enyi correlation as a measureof fairness of machine learning models and develop a general training frameworkto impose fairness. In particular, we propose a min-max formulation whichbalances the accuracy and fairness when solved to optimality. For the case ofdiscrete sensitive attributes, we suggest an iterative algorithm withtheoretical convergence guarantee for solving the proposed min-max problem. Ouralgorithm and analysis are then specialized to fair classification and the fairclustering problem under disparate impact doctrine. Finally, the performance ofthe proposed R\'enyi fair inference framework is evaluated on Adult and Bankdatasets."
"232","arXiv:1906.12015","https://arxiv.org/abs/1906.12015","Accelerated Symmetric ADMM and Its Applications in Signal Processing","Jianchao Bai, Junli Liang, Ke Guo, Yang Jing","The alternating direction method of multipliers (ADMM) were extensivelyinvestigated in the past decades for solving separable convex optimizationproblems. Fewer researchers focused on exploring its convergence properties forthe nonconvex case although it performed surprisingly efficient. In this paper,we propose a symmetric ADMM based on different acceleration techniques for afamily of potentially nonsmooth nonconvex programing problems with equalityconstraints, where the dual variables are updated twice with differentstepsizes. Under proper assumptions instead of using the so-calledKurdyka-Lojasiewicz inequality, convergence of the proposed algorithm as wellas its pointwise iteration-complexity are analyzed in terms of thecorresponding augmented Lagrangian function and the primal-dual residuals,respectively. Performance of our algorithm is verified by some preliminarynumerical examples on applications in sparse nonconvex/convex regularizedminimization signal processing problems."
"233","arXiv:1906.12017","https://arxiv.org/abs/1906.12017","Binary optimal linear codes from posets of the disjoint union of two  chains","Yansheng Wu, Jong Yoon Hyun, Qin Yue","Recently, Chang and Hyun obtained some classes of binary optimal codes viasimplicial complexes. In this letter, we utilize posets of the disjoint unionof two chains to construct binary optimal linear codes."
"234","arXiv:1906.12018","https://arxiv.org/abs/1906.12018","Pruned Landmark Labeling Meets Vertex Centric Computation: A  Surprisingly Happy Marriage!","Ruoming Jin, Zhen Peng, Wendell Wu, Feodor Dragan, Gagan Agrawal, Bin Ren","In this paper, we study how the Pruned Landmark Labeling (PPL) algorithm canbe parallelized in a scalable fashion, producing the same results as thesequential algorithm. More specifically, we parallelize using a Vertex-Centric(VC) computational model on a modern SIMD powered multicore architecture. Wedesign a new VC-PLL algorithm that resolves the apparent mismatch between theinherent sequential dependence of the PLL algorithm and the Vertex- Centric(VC) computing model. Furthermore, we introduce a novel batch execution modelfor VC computation and the BVC-PLL algorithm to reduce the computationalinefficiency in VC-PLL. Quite surprisingly, the theoretical analysis revealsthat under a reasonable assumption, BVC-PLL has lower computational and memoryaccess costs than PLL and indicates it may run faster than PLL as a sequentialalgorithm. We also demonstrate how BVC-PLL algorithm can be extended to handledirected graphs and weighted graphs and how it can utilize the hierarchicalparallelism on a modern parallel computing architecture. Extensive experimentson real-world graphs not only show the sequential BVC-PLL can run more than twotimes faster than the original PLL, but also demonstrates its parallelefficiency and scalability."
"235","arXiv:1906.12023","https://arxiv.org/abs/1906.12023","Evaluation of Abramowitz functions in the right half of the complex  plane","Zydrunas Gimbutas, Shidong Jiang, Li-Shi Luo","A numerical scheme is developed for the evaluation of Abramowitz functions$J_n$ in the right half of the complex plane. For $n=-1,\, \ldots,\, 2$, thescheme utilizes series expansions for $|z|<1$ and asymptotic expansions for$|z|>R$ with $R$ determined by the required precision, and modified Laurentseries expansions which are precomputed via a least squares procedure toapproximate $J_n$ accurately and efficiently on each sub-region in theintermediate region $1\le |z| \le R$. For $n>2$, $J_n$ is evaluated via arecurrence relation. The scheme achieves nearly machine precision for $n=-1,\ldots, 2$, with the cost about four times of evaluating a complex exponentialper function evaluation."
"236","arXiv:1906.12028","https://arxiv.org/abs/1906.12028","ProtoNet: Learning from Web Data with Memory","Yi Tu, Li Niu, Dawei Cheng, Liqing Zhang","Learning from web data has attracted lots of research interest in recentyears. However, crawled web images usually have two types of noises, labelnoise and background noise, which induce extra difficulties in utilizing themeffectively. Most existing methods either rely on human supervision or ignorethe background noise. In this paper, we propose the novel ProtoNet, which iscapable of handling these two types of noises together, without the supervisionof clean images in the training stage. Particularly, we use a memory module toidentify the representative and discriminative prototypes for each category.Then, we remove noisy images and noisy region proposals from the web datasetwith the aid of the memory module. Our approach is efficient and can be easilyintegrated into arbitrary CNN model. Extensive experiments on four benchmarkdatasets demonstrate the effectiveness of our method."
"237","arXiv:1906.12056","https://arxiv.org/abs/1906.12056","DP-LSSGD: A Stochastic Optimization Method to Lift the Utility in  Privacy-Preserving ERM","Bao Wang, Quanquan Gu, March Boedihardjo, Farzin Barekat, Stanley J. Osher","Machine learning (ML) models trained by differentially private stochasticgradient descent (DP-SGD) has much lower utility than the non-private ones. Tomitigate this degradation, we propose a DP Laplacian smoothing SGD (DP-LSSGD)for privacy-preserving ML. At the core of DP-LSSGD is the Laplace smoothingoperator, which smooths out the Gaussian noise vector used in the Gaussianmechanism. Under the same amount of noise used in the Gaussian mechanism,DP-LSSGD attains the same differential privacy guarantee, but a strictly betterutility guarantee, excluding an intrinsic term which is usually dominated bythe other terms, for convex optimization than DP-SGD by a factor which is muchless than one. In practice, DP-LSSGD makes training both convex and nonconvexML models more efficient and enables the trained models to generalize better.For ResNet20, under the same strong differential privacy guarantee, DP-LSSGDcan lift the testing accuracy of the trained private model by more than $8$\%compared with DP-SGD. The proposed algorithm is simple to implement and theextra computational complexity and memory overhead compared with DP-SGD arenegligible. DP-LSSGD is applicable to train a large variety of ML models,including deep neural nets. The code is available at\url{https://github.com/BaoWangMath/DP-LSSGD}."
"238","arXiv:1906.12029","https://arxiv.org/abs/1906.12029","A Neural-based Program Decompiler","Cheng Fu, Huili Chen, Haolan Liu, Xinyun Chen, Yuandong Tian, Farinaz Koushanfar, Jishen Zhao","Reverse engineering of binary executables is a critical problem in thecomputer security domain. On the one hand, malicious parties may recoverinterpretable source codes from the software products to gain commercialadvantages. On the other hand, binary decompilation can be leveraged for codevulnerability analysis and malware detection. However, efficient binarydecompilation is challenging. Conventional decompilers have the following majorlimitations: (i) they are only applicable to specific source-target languagepair, hence incurs undesired development cost for new language tasks; (ii)their output high-level code cannot effectively preserve the correctfunctionality of the input binary; (iii) their output program does not capturethe semantics of the input and the reversed program is hard to interpret. Toaddress the above problems, we propose Coda, the first end-to-end neural-basedframework for code decompilation. Coda decomposes the decompilation task intotwo key phases: First, Coda employs an instruction type-aware encoder and atree decoder for generating an abstract syntax tree (AST) with attentionfeeding during the code sketch generation stage. Second, Coda then updates thecode sketch using an iterative error correction machine guided by an ensembledneural error predictor. By finding a good approximate candidate and then fixingit towards perfect, Coda achieves superior performance compared to baselineapproaches. We assess Coda's performance with extensive experiments on variousbenchmarks. Evaluation results show that Coda achieves an average of 82\%program recovery accuracy on unseen binary samples, where the state-of-the-artdecompilers yield 0\% accuracy. Furthermore, Coda outperforms thesequence-to-sequence model with attention by a margin of 70\% program accuracy."
"239","arXiv:1906.12035","https://arxiv.org/abs/1906.12035","Multi-Criteria Chinese Word Segmentation with Transformer","Xipeng Qiu, Hengzhi Pei, Hang Yan, Xuanjing Huang","Different linguistic perspectives cause many diverse segmentation criteriafor Chinese word segmentation (CWS). Most existing methods focus on improvingthe performance of single-criterion CWS. However, it is interesting to exploitthese heterogeneous segmentation criteria and mine their common underlyingknowledge. In this paper, we propose a concise and effective model formulti-criteria CWS, which utilizes a shared fully-connected self-attentionmodel to segment the sentence according to a criterion indicator. Experimentson eight datasets with heterogeneous segmentation criteria show that theperformance of each corpus obtains a significant improvement, compared tosingle-criterion learning."
"240","arXiv:1906.12038","https://arxiv.org/abs/1906.12038","Analyzing GDPR Compliance Through the Lens of Privacy Policy","Jayashree Mohan, Melissa Wasserman, Vijay Chidambaram","With the arrival of the European Union's General Data Protection Regulation(GDPR), several companies are making significant changes to their systems toachieve compliance. The changes range from modifying privacy policies toredesigning systems which process personal data. This work analyzes the privacypolicies of large-scaled cloud services which seek to be GDPR compliant. Theprivacy policy is the main medium of information dissemination between the datacontroller and the users. We show that many services that claim compliancetoday do not have clear and concise privacy policies. We identify severalpoints in the privacy policies which potentially indicate non-compliance; weterm these GDPR vulnerabilities. We identify GDPR vulnerabilities in ten cloudservices. Based on our analysis, we propose seven best practices for craftingGDPR privacy policies."
"241","arXiv:1906.12039","https://arxiv.org/abs/1906.12039","Supervised Contextual Embeddings for Transfer Learning in Natural  Language Processing Tasks","Mihir Kale, Aditya Siddhant, Sreyashi Nag, Radhika Parik, Matthias Grabmair, Anthony Tomasic","Pre-trained word embeddings are the primary method for transfer learning inseveral Natural Language Processing (NLP) tasks. Recent works have focused onusing unsupervised techniques such as language modeling to obtain theseembeddings. In contrast, this work focuses on extracting representations frommultiple pre-trained supervised models, which enriches word embeddings withtask and domain specific knowledge. Experiments performed in cross-task,cross-domain and cross-lingual settings indicate that such supervisedembeddings are helpful, especially in the low-resource setting, but the extentof gains is dependent on the nature of the task and domain. We make our codepublicly available."
"242","arXiv:1906.12043","https://arxiv.org/abs/1906.12043","Faster Distributed Deep Net Training: Computation and Communication  Decoupled Stochastic Gradient Descent","Shuheng Shen, Linli Xu, Jingchang Liu, Xianfeng Liang, Yifei Cheng","With the increase in the amount of data and the expansion of model scale,distributed parallel training becomes an important and successful technique toaddress the optimization challenges. Nevertheless, although distributedstochastic gradient descent (SGD) algorithms can achieve a linear iterationspeedup, they are limited significantly in practice by the communication cost,making it difficult to achieve a linear time speedup. In this paper, we proposea computation and communication decoupled stochastic gradient descent(CoCoD-SGD) algorithm to run computation and communication in parallel toreduce the communication cost. We prove that CoCoD-SGD has a linear iterationspeedup with respect to the total computation capability of the hardwareresources. In addition, it has a lower communication complexity and better timespeedup comparing with traditional distributed SGD algorithms. Experiments ondeep neural network training demonstrate the significant improvements ofCoCoD-SGD: when training ResNet18 and VGG16 with 16 Geforce GTX 1080Ti GPUs,CoCoD-SGD is up to 2-3$\times$ faster than traditional synchronous SGD."
"243","arXiv:1906.12051","https://arxiv.org/abs/1906.12051","A Taxonomy for Virtual and Augmented Reality in Education","Jiri Motejlek, Esat Alpay","In this paper, a taxonomy for VR/AR in education is presented that can helpdifferentiate and categorise education experiences and provide indication as towhy some applications of fail whereas others succeed. Examples will bepresented to illustrate the taxonomy, including its use in developing andplanning two current VR projects in our laboratory. The first project is a VRapplication for the training of Chemical Engineering students (and potentiallyindustrial operators) on the use of a physical pilot plant facility. The secondproject involves the use of VR cinematography for enacting ethics scenarios(and thus ethical awareness and development) pertinent to engineering worksituations."
"244","arXiv:1906.12143","https://arxiv.org/abs/1906.12143","A DTLS Abstraction Layer for the Recursive Networking Architecture in  RIOT","M. Aiman Ismail, Thomas C. Schmidt","On the Internet of Things (IoT), devices continuously communicate with eachother, with a gateway, or other Internet nodes. Often devices are constrainedand use insecure channels for their communication, which exposes them to aselection of attacks that may extract sensitive pieces of information ormanipulate dialogues for the purpose of sabotaging.This paper presents a new layer in the RIOT networking architecture toseamlessly integrate secure communication between applications using DTLS. Thelayer acts as a modular abstraction layer of the different DTLSimplementations, enabling swapping of the underlying implementation with just afew lines of code. This paper also introduces credman, a new module to managecredentials used for (D)TLS connections."
"245","arXiv:1906.12061","https://arxiv.org/abs/1906.12061","Learning to Cope with Adversarial Attacks","Xian Yeow Lee, Aaron Havens, Girish Chowdhary, Soumik Sarkar","The security of Deep Reinforcement Learning (Deep RL) algorithms deployed inreal life applications are of a primary concern. In particular, the robustnessof RL agents in cyber-physical systems against adversarial attacks areespecially vital since the cost of a malevolent intrusions can be extremelyhigh. Studies have shown Deep Neural Networks (DNN), which forms the coredecision-making unit in most modern RL algorithms, are easily subjected toadversarial attacks. Hence, it is imperative that RL agents deployed inreal-life applications have the capability to detect and mitigate adversarialattacks in an online fashion. An example of such a framework is theMeta-Learned Advantage Hierarchy (MLAH) agent that utilizes a meta-learningframework to learn policies robustly online. Since the mechanism of thisframework are still not fully explored, we conducted multiple experiments tobetter understand the framework's capabilities and limitations. Our resultsshows that the MLAH agent exhibits interesting coping behaviors when subjectedto different adversarial attacks to maintain a nominal reward. Additionally,the framework exhibits a hierarchical coping capability, based on theadaptability of the Master policy and sub-policies themselves. From empiricalresults, we also observed that as the interval of adversarial attacks increase,the MLAH agent can maintain a higher distribution of rewards, though at thecost of higher instabilities."
"246","arXiv:1906.12064","https://arxiv.org/abs/1906.12064","Background Subtraction using Adaptive Singular Value Decomposition","Günther Reitberger, Tomas Sauer","An important task when processing sensor data is to distinguish relevant fromirrelevant data. This paper describes a method for an iterative singular valuedecomposition that maintains a model of the background via singular vectorsspanning a subspace of the image space, thus providing a way to determine theamount of new information contained in an incoming frame. We update thesingular vectors spanning the background space in a computationally efficientmanner and provide the ability to perform block-wise updates, leading to a fastand robust adaptive SVD computation. The effects of those two properties andthe success of the overall method to perform a state of the art backgroundsubtraction are shown in both qualitative and quantitative evaluations."
"247","arXiv:1906.12066","https://arxiv.org/abs/1906.12066","Pinpointing Performance Inefficiencies in Java","Pengfei Su, Qingsen Wang, Milind Chabbi, Xu Liu","Many performance inefficiencies such as inappropriate choice of algorithms ordata structures, developers' inattention to performance, and missed compileroptimizations show up as wasteful memory operations. Wasteful memory operationsare those that produce/consume data to/from memory that may have been avoided.We present, JXPerf, a lightweight performance analysis tool for pinpointingwasteful memory operations in Java programs. Traditional byte-codeinstrumentation for such analysis (1) introduces prohibitive overheads and (2)misses inefficiencies in machine code generation. JXPerf overcomes both ofthese problems. JXPerf uses hardware performance monitoring units to samplememory locations accessed by a program and uses hardware debug registers tomonitor subsequent accesses to the same memory. The result is a lightweightmeasurement at machine-code level with attribution of inefficiencies to theirprovenance: machine and source code within full calling contexts. JXPerfintroduces only 7% runtime overhead and 7% memory overhead making it useful inproduction. Guided by JXPerf, we optimize several Java applications byimproving code generation and choosing superior data structures and algorithms,which yield significant speedups."
"248","arXiv:1906.12068","https://arxiv.org/abs/1906.12068","Lost in Translation: Loss and Decay of Linguistic Richness in Machine  Translation","Eva Vanmassenhove, Dimitar Shterionov, Andy Way","This work presents an empirical approach to quantifying the loss of lexicalrichness in Machine Translation (MT) systems compared to Human Translation(HT). Our experiments show how current MT systems indeed fail to render thelexical diversity of human generated or translated text. The inability of MTsystems to generate diverse outputs and its tendency to exacerbate alreadyfrequent patterns while ignoring less frequent ones, might be the underlyingcause for, among others, the currently heavily debated issues related to genderbiased output. Can we indeed, aside from biased data, talk about an algorithmthat exacerbates seen biases?"
"249","arXiv:1906.12073","https://arxiv.org/abs/1906.12073","Access Balancing in Storage Systems by Labeling Partial Steiner Systems","Yeow Meng Chee, Charles J. Colbourn, Hoang Dau, Ryan Gabrys, Alan C.H. Ling, Dylan Lusi, Olgica Milenkovic","Storage architectures ranging from minimum bandwidth regenerating encodeddistributed storage systems to declustered-parity RAIDs can be designed usingdense partial Steiner systems in order to support fast reads, writes, andrecovery of failed storage units. In order to ensure good performance,popularities of the data items should be taken into account and the frequenciesof accesses to the storage units made as uniform as possible. A proposedcombinatorial model ranks items by popularity and assigns data items toelements in a dense partial Steiner system so that the sums of ranks of theelements in each block are as equal as possible. By developing necessaryconditions in terms of independent sets, we demonstrate that certain Steinersystems must have a much larger difference between the largest and smallestblock sums than is dictated by an elementary lower bound. In contrast, we alsoshow that certain dense partial $S(t, t+1, v)$ designs can be labeled torealize the elementary lower bound. Furthermore, we prove that for everyadmissible order $v$, there is a Steiner triple system $(S(2, 3, v))$ whoselargest difference in block sums is within an additive constant of the lowerbound."
"250","arXiv:1906.12075","https://arxiv.org/abs/1906.12075","A linear method for camera pair self-calibration and multi-view  reconstruction with geometrically verified correspondences","Nikos Melanitis, Petros Maragos","We examine 3D reconstruction of architectural scenes in unordered sets ofuncalibrated images. We introduce a linear method to self-calibrate and findthe metric reconstruction of a camera pair. We assume unknown and differentfocal lengths but otherwise known internal camera parameters and a knownprojective reconstruction of the camera pair. We recover two possible cameraconfigurations in space and use the Cheirality condition, that all 3D scenepoints are in front of both cameras, to disambiguate the solution. We show intwo Theorems, first that the two solutions are in mirror positions and then therelations between their viewing directions. Our new method performs on par(median rotation error $\Delta R = 3.49^{\circ}$) with the standard approach ofKruppa equations ($\Delta R = 3.77^{\circ}$) for self-calibration and 5-Pointalgorithm for calibrated metric reconstruction of a camera pair. We rejecterroneous image correspondences by introducing a method to examine whetherpoint correspondences appear in the same order along $x, y$ image axes in imagepairs. We evaluate this method by its precision and recall and show that itimproves the robustness of point matches in architectural and general scenes.Finally, we integrate all the introduced methods to a 3D reconstructionpipeline. We utilize the numerous camera pair metric recontructions usingrotation-averaging algorithms and a novel method to average focal lengthestimates."
"251","arXiv:1906.12082","https://arxiv.org/abs/1906.12082","Sample Efficient Learning of Path Following and Obstacle Avoidance  Behavior for Quadrotors","Stefan Stevsic, Tobias Naegeli, Javier Alonso-Mora, Otmar Hilliges","In this paper we propose an algorithm for the training of neural networkcontrol policies for quadrotors. The learned control policy computes controlcommands directly from sensor inputs and is hence computationally efficient. Animitation learning algorithm produces a policy that reproduces the behavior ofa path following control algorithm with collision avoidance. Due to thegeneralization ability of neural networks, the resulting policy performs localcollision avoidance of unseen obstacles while following a global referencepath. The algorithm uses a time-free model predictive path-following controlleras a supervisor. The controller generates demonstrations by following fewexample paths. This enables an easy to implement learning algorithm that isrobust to errors of the model used in the model predictive controller. Thepolicy is trained on the real quadrotor, which requires collision-freeexploration around the example path. An adapted version of the supervisor isused to enable exploration. Thus, the policy can be trained from a relativelysmall number of examples on the real quadrotor, making the training sampleefficient."
"252","arXiv:1906.12085","https://arxiv.org/abs/1906.12085","FameSVD: Fast and Memory-efficient Singular Value Decomposition","Xiaocan Li, Shuo Wang, Yinghao Cai","We propose a novel algorithm to perform the Singular Value Decomposition(SVD) by leveraging the internal property of SVD. Due to the derivation beingexplored deterministically rather than stochastically, the convergence isguaranteed. Complexity analysis is also conducted. Our proposed SVD methodoutperforms classic algorithms with significant margin both in runtime andmemory usage. Furthermore, we discuss the relationship between SVD andPrincipal Component Analysis (PCA). For those SVD or PCA algorithms that do notacquire all eigenvalues or cannot get them precisely, we utilize the matrixanalysis knowledge to get the sum of all eigenvalues in order that cumulativeexplained variance criterion could be used in not-all-eigenvalues-are-knowncases."
"253","arXiv:1906.12086","https://arxiv.org/abs/1906.12086","Safe Contextual Bayesian Optimization for Sustainable Room Temperature  PID Control Tuning","Marcello Fiducioso, Sebastian Curi, Benedikt Schumacher, Markus Gwerder, Andreas Krause","We tune one of the most common heating, ventilation, and air conditioning(HVAC) control loops, namely the temperature control of a room. For economicaland environmental reasons, it is of prime importance to optimize theperformance of this system. Buildings account from 20 to 40% of a countryenergy consumption, and almost 50% of it comes from HVAC systems. Scenarioprojections predict a 30% decrease in heating consumption by 2050 due toefficiency increase. Advanced control techniques can improve performance;however, the proportional-integral-derivative (PID) control is typically useddue to its simplicity and overall performance. We use Safe Contextual BayesianOptimization to optimize the PID parameters without human intervention. Wereduce costs by 32% compared to the current PID controller setting whileassuring safety and comfort to people in the room. The results of this workhave an immediate impact on the room control loop performances and its relatedcommissioning costs. Furthermore, this successful attempt paves the way forfurther use at different levels of HVAC systems, with promising energy,operational, and commissioning costs savings, and it is a practicaldemonstration of the positive effects that Artificial Intelligence can have onenvironmental sustainability."
"254","arXiv:1906.12087","https://arxiv.org/abs/1906.12087","ARMIN: Towards a More Efficient and Light-weight Recurrent Memory  Network","Zhangheng Li, Jia-Xing Zhong, Jingjia Huang, Tao Zhang, Thomas Li, Ge Li","In recent years, memory-augmented neural networks(MANNs) have shown promisingpower to enhance the memory ability of neural networks for sequentialprocessing tasks. However, previous MANNs suffer from complex memory addressingmechanism, making them relatively hard to train and causing computationaloverheads. Moreover, many of them reuse the classical RNN structure such asLSTM for memory processing, causing inefficient exploitations of memoryinformation. In this paper, we introduce a novel MANN, the Auto-addressing andRecurrent Memory Integrating Network (ARMIN) to address these issues. The ARMINonly utilizes hidden state ht for automatic memory addressing, and uses a novelRNN cell for refined integration of memory information. Empirical results on avariety of experiments demonstrate that the ARMIN is more light-weight andefficient compared to existing memory networks. Moreover, we demonstrate thatthe ARMIN can achieve much lower computational overhead than vanilla LSTM whilekeeping similar performances. Codes are available on github.com/zoharli/armin."
"255","arXiv:1906.12088","https://arxiv.org/abs/1906.12088","Non-user Inclusive Design for Maintaining Harmony of Real-Virtual Human  Interaction in Augmented Reality","Chao Shi","Augmented reality enables the illusion of contents such as objects and humansin the virtual world co-existing with users in the real world. However,non-users who are not aware of the presence of the virtual world anddynamically move nearby might either cause a conflict by directly breaking intospace where a user is talking to a Virtual Human (VH), or be troubled when tryto avoid disturbing the user. To maintain harmony and keep both the user's andnon-users' comfort, we propose a method that controls the VH to adjust its ownposition to avoid such potential conflict. The difficulty to address thisproblem is that the agent must avoid potential conflict in a natural way tokeep the user away from feeling unnatural. Our idea is to endow the VH withthree capabilities: anticipating non-users walking around, understanding how toestablish and maintain proper formation to adapt to the environment, andplanning to avoid conflicts by shifting formation in advance. We develop anon-user inclusive spatial formation model that realizes natural arrangementshift corresponding to the environment based on theoretical sources fromliterature. We implemented our proposed model into a VH behavior planningsystem to achieve natural conflict avoidance. Evaluation experiments showedthat it successfully reduces potential conflicts caused by non-users."
"256","arXiv:1906.12089","https://arxiv.org/abs/1906.12089","Uncovering the Semantics of Wikipedia Categories","Nicolas Heist, Heiko Paulheim","The Wikipedia category graph serves as the taxonomic backbone for large-scaleknowledge graphs like YAGO or Probase, and has been used extensively for taskslike entity disambiguation or semantic similarity estimation. Wikipedia'scategories are a rich source of taxonomic as well as non-taxonomic information.The category 'German science fiction writers', for example, encodes the type ofits resources (Writer), as well as their nationality (German) and genre(Science Fiction). Several approaches in the literature make use of fractionsof this encoded information without exploiting its full potential. In thispaper, we introduce an approach for the discovery of category axioms that usesinformation from the category network, category instances, and theirlexicalisations. With DBpedia as background knowledge, we discover 703k axiomscovering 502k of Wikipedia's categories and populate the DBpedia knowledgegraph with additional 4.4M relation assertions and 3.3M type assertions at morethan 87% and 90% precision, respectively."
"257","arXiv:1906.12091","https://arxiv.org/abs/1906.12091","Searching for Interaction Functions in Collaborative Filtering","Quanming Yao, Xiangning Chen, James Kwok, Yong Li","Interaction function (IFC), which captures interactions among items andusers, is of great importance in collaborative filtering (CF). The innerproduct is the most popular IFC due to its success in low-rank matrixfactorization. However, interactions in real-world applications can be highlycomplex. Many other operations (such as plus and concatenation) have also beenproposed, and can possibly offer better performance than the inner product. Inthis paper, motivated by the success of automated machine learning, we proposeto search for proper interaction functions (SIF) for CF tasks. We first designan expressive search space for SIF by reviewing and generalizing existing CFapproaches. We then propose to represent the search space as a structuredmulti-layer perceptron, and design a stochastic gradient descent algorithmwhich can simultaneously update both architectures and learning parameters.Experimental results demonstrate that the proposed method can be much moreefficient than popular AutoML approaches, and also obtain much betterprediction performance than state-of-the-art CF approaches."
"258","arXiv:1906.12092","https://arxiv.org/abs/1906.12092","Throughput Scaling of Covert Communication over Wireless Adhoc Networks","Kang-Hee Cho, Si-Hyeon Lee, Vincent Y. F. Tan","We consider the problem of covert communication over wireless adhoc networksin which (roughly) $n$ legitimate nodes (LNs) and $n^{\kappa}$ for $0<\kappa<1$non-communicating warden nodes (WNs) are randomly distributed in a square ofunit area. Each legitimate source wants to communicate with its intendeddestination node while ensuring that every WN is unable to detect the presenceof the communication. In this scenario, we study the throughput scaling law.Due the covert communication constraint, the transmit powers are necessarilylimited. Under this condition, we introduce a preservation region around eachWN. This region serves to prevent transmission from the LNs and to increase thetransmit power of the LNs outside the preservation regions. For theachievability results, multi-hop (MH), hierarchical cooperation (HC), andhybrid HC-MH schemes are utilized with some appropriate modifications. In theproposed MH and hybrid schemes, because the preservation regions may impedecommunication along direct data paths, the data paths are suitably modified bytaking a detour around each preservation region. To avoid the concentration ofdetours resulting extra relaying burdens, we distribute the detours evenly overa wide region. In the proposed HC scheme, we control the symbol power and thescheduling of distributed multiple-input multiple-output transmission. We alsopresent matching upper bounds on the throughput scaling under the assumptionthat every active LN consumes the same average transmit power over the timeperiod in which the WNs observe the channel outputs."
"259","arXiv:1906.12095","https://arxiv.org/abs/1906.12095","Robustness Against Transactional Causal Consistency","Sidi Mohamed Beillahi, Ahmed Bouajjani, Constantin Enea","Distributed storage systems and databases are widely used by various types ofapplications. Transactional access to these storage systems is an importantabstraction allowing application programmers to consider blocks of actions(i.e., transactions) as executing atomically. For performance reasons, theconsistency models implemented by modern databases are weaker than the standardserializability model, which corresponds to the atomicity abstraction oftransactions executing over a sequentially consistent memory. Causalconsistency for instance is one such model that is widely used in practice.In this paper, we investigate application-specific relationships betweenseveral variations of causal consistency and we address the issue of verifyingautomatically if a given transactional program is robust against causalconsistency, i.e., all its behaviors when executed over an arbitrary causallyconsistent database are serializable. We show that programs without write-writeraces have the same set of behaviors under all these variations, and we showthat checking robustness is polynomial time reducible to a state reachabilityproblem in transactional programs over a sequentially consistent shared memory.A surprising corollary of the latter result is that causal consistencyvariations which admit incomparable sets of behaviors admit comparable sets ofrobust programs. This reduction also opens the door to leveraging existingmethods and tools for the verification of concurrent programs (assumingsequential consistency) for reasoning about programs running over causallyconsistent databases. Furthermore, it allows to establish that the problem ofchecking robustness is decidable when the programs executed at different sitesare finite-state."
"260","arXiv:1906.12098","https://arxiv.org/abs/1906.12098","Category-Theoretic Foundations of ""STCLang: State Thread Composition as  a Foundation for Monadic Dataflow Parallelism""","Sebastian Ertel, Justus Adam, Norman A. Rink, Andrés Goens, Jeronimo Castrillon","This manuscript gives a category-theoretic foundation to the composition ofState Threads as a Foundation for Monadic Dataflow Parallelism. It serves as asupplementary formalization of the concepts introduced in the Article ""STCLang:State Thread Composition as a Foundation for Monadic Dataflow Parallelism"", aspublished in Proceedings of the 12th ACM SIGPLAN International Symposium onHaskell (Haskell'19)."
"261","arXiv:1906.12108","https://arxiv.org/abs/1906.12108","Inversion of trace formulas for a Sturm-Liouville operator","Xiang Xu, Jian Zhai","This paper revisits the classical problem ""Can we hear the density of astring?"", which can be formulated as an inverse spectral problem for aSturm-Liouville operator. Based on inverting a sequence of trace formulas, wepropose a new numerical scheme to reconstruct the density. Numericalexperiments are presented to verify the validity and effectiveness of thenumerical scheme."
"262","arXiv:1906.12118","https://arxiv.org/abs/1906.12118","Fully automatic computer-aided mass detection and segmentation via  pseudo-color mammograms and Mask R-CNN","Hang Min, Devin Wilson, Yinhuang Huang, Samuel Kelly, Stuart Crozier, Andrew P Bradley, Shekhar S. Chandra","Purpose: To propose pseudo-color mammograms that enhance mammographic massesas part of a fast computer-aided detection (CAD) system that simultaneouslydetects and segments masses without any user intervention. Methods: Theproposed pseudo-color mammograms, whose three channels contain the originalgrayscale mammogram and two morphologically enhanced images, are used toprovide pseudo-color contrast to the lesions. The morphological enhancement'sifts' out the mass-like mammographic patterns to improve detection andsegmentation. We construct a fast, fully automated simultaneous mass detectionand segmentation CAD system using the colored mammograms as inputs of transferlearning with the Mask R-CNN which is a state-of-the-art deep learningframework. The source code for this work has been made available online.Results: Evaluated on the publicly available mammographic dataset INbreast, themethod outperforms the state-of-the-art methods by achieving an average truepositive rate of 0.90 at 0.9 false positive per image and an average Dicesimilarity index for mass segmentation of 0.88, while taking 20.4 seconds toprocess each image on average. Conclusions: The proposed method provides anaccurate, fully-automatic breast mass detection and segmentation result in lessthan half a minute without any user intervention while outperformingstate-of-the-art methods."
"263","arXiv:1906.12120","https://arxiv.org/abs/1906.12120","One Embedding To Do Them All","Loveperteek Singh, Shreya Singh, Sagar Arora, Sumit Borar","Online shopping caters to the needs of millions of users daily. Search,recommendations, personalization have become essential building blocks forserving customer needs. Efficacy of such systems is dependent on a thoroughunderstanding of products and their representation. Multiple informationsources and data types provide a complete picture of the product on theplatform. While each of these tasks shares some common characteristics,typically product embeddings are trained and used in isolation.In this paper, we propose a framework to combine multiple data sources andlearn unified embeddings for products on our e-commerce platform. Our productembeddings are built from three types of data sources - catalog text data, auser's clickstream session data and product images. We use various techniqueslike denoising auto-encoders for text, Bayesian personalized ranking (BPR) forclickstream data, Siamese neural network architecture for image data andcombined ensemble over the above methods for unified embeddings. Further, wecompare and analyze the performance of these embeddings across three unrelatedreal-world e-commerce tasks specifically checking product attribute coverage,finding similar products and predicting returns. We show that unified productembeddings perform uniformly well across all these tasks."
"264","arXiv:1906.12128","https://arxiv.org/abs/1906.12128","Early Bird Catches the Worm: Predicting Returns Even Before Purchase in  Fashion E-commerce","Sajan Kedia, Manchit Madan, Sumit Borar","With the rapid growth in fashion e-commerce and customer-friendly productreturn policies, the cost to handle returned products has become a significantchallenge. E-tailers incur huge losses in terms of reverse logistics costs,liquidation cost due to damaged returns or fraudulent behavior. Accurateprediction of product returns prior to order placement can be critical forcompanies. It can facilitate e-tailers to take preemptive measures even beforethe order is placed, hence reducing overall returns. Furthermore, findingreturn probability for millions of customers at the cart page in real-time canbe difficult. To address this problem we propose a novel approach based on DeepNeural Network. Users' taste & products' latent hidden features were capturedusing product embeddings based on Bayesian Personalized Ranking (BPR). Anotherset of embeddings was used which captured users' body shape and size by usingskip-gram based model. The deep neural network incorporates these embeddingsalong with the engineered features to predict return probability. Using thisreturn probability, several live experiments were conducted on one of the majorfashion e-commerce platform in order to reduce overall returns."
"265","arXiv:1906.12133","https://arxiv.org/abs/1906.12133","Online Quantitative Timed Pattern Matching with Semiring-Valued Weighted  Automata","Masaki Waga","Monitoring of a signal plays an essential role in the runtime verification ofcyber-physical systems. Qualitative timed pattern matching is one of themathematical formulations of monitoring, which gives a Boolean verdict for eachsub-signal according to the satisfaction of the given specification. There aretwo orthogonal directions of extension of the qualitative timed patternmatching. One direction on the result is quantitative: what engineers want isoften not a qualitative verdict but the quantitative measurement of thesatisfaction of the specification. The other direction on the algorithm isonline checking: the monitor returns some verdicts before obtaining the entiresignal, which enables to monitor a running system. It is desired fromapplication viewpoints. In this paper, we conduct these two extensions, takingan automata-based approach. This is the first quantitative and online timedpattern matching algorithm to the best of our knowledge. More specifically, weemploy what we call timed symbolic weighted automata to specify quantitativespecifications to be monitored, and we obtain an online algorithm using theshortest distance of a weighted variant of the zone graph and dynamicprogramming. Moreover, our problem setting is semiring-based and therefore,general. Our experimental results confirm the scalability of our algorithm forspecifications with a time-bound."
"266","arXiv:1906.12140","https://arxiv.org/abs/1906.12140","SeF: A Secure Fountain Architecture for Slashing Storage Costs in  Blockchains","Swanand Kadhe, Jichan Chung, Kannan Ramchandran","Full nodes, which synchronize the entire blockchain history and independentlyvalidate all the blocks, form the backbone of any blockchain network by playinga vital role in ensuring security properties. On the other hand, a user runninga full node needs to pay a heavy price in terms of storage costs. E.g., theBitcoin blockchain size has grown over 215GB, in spite of its low throughput.The ledger size for a high throughput blockchain Ripple has already reached9TB, and it is growing at an astonishing rate of 12GB per day!In this paper, we propose an architecture based on 'fountain codes', a classof erasure codes, that enables any full node to 'encode' validated blocks intoa small number of 'coded blocks', thereby reducing its storage costs by ordersof magnitude. In particular, our proposed ""Secure Fountain (SeF)"" architecturecan achieve a near-optimal trade-off between the storage savings per node andthe 'bootstrap cost' in terms of the number of (honest) storage-constrainednodes a new node needs to contact to recover the blockchain. A key technicalinnovation in SeF codes is to make fountain codes secure against adversarialnodes that can provide maliciously formed coded blocks. Our idea is to use theheader-chain as a 'side-information' to check whether a coded block ismaliciously formed while it is getting decoded. Further, the 'ratelessproperty' of fountain codes helps in achieving high decentralization andscalability. Our experiments demonstrate that SeF codes tuned to achieve 1000xstorage savings enable full nodes to encode the 191GB Bitcoin blockchain into195MB on average. A new node can recover the blockchain from an arbitrary setof storage-constrained nodes as long as the set contains ~1100 honest nodes onaverage. Note that for a 1000x storage savings, the fundamental bound on thenumber of honest nodes to contact is 1000: we need about 10% more in practice."
"267","arXiv:1906.12141","https://arxiv.org/abs/1906.12141","MGOS: A Library for Molecular Geometry and its Operating System","Deok-Soo Kima, Joonghyun Ryua, Youngsong Choa, Mokwon Leeb, Jehyun Cha, Chanyoung Song, Sangwha Kim, Roman A Laskowskid, Kokichi Sugihara, Jong Bhak, Seong Eon Ryu","The geometry of atomic arrangement underpins the structural understanding ofmolecules in many fields. However, no general framework ofmathematical/computational theory for the geometry of atomic arrangementexists. Here we present ""Molecular Geometry (MG)"" as a theoretical frameworkaccompanied by ""MG Operating System (MGOS)"" which consists of callablefunctions implementing the MG theory. MG allows researchers to modelcomplicated molecular structure problems in terms of elementary yet standardnotions of volume, area, etc. and MGOS frees them from the hard and tedioustask of developing/implementing geometric algorithms so that they can focusmore on their primary research issues. MG facilitates simpler modeling ofmolecular structure problems; MGOS functions can be conveniently embedded inapplication programs for the efficient and accurate solution of geometricqueries involving atomic arrangements. The use of MGOS in problems involvingspherical entities is akin to the use of math libraries in general purposeprogramming languages in science and engineering."
"268","arXiv:1906.12166","https://arxiv.org/abs/1906.12166","A study on Stokes-Brinkman dimensionless model for flow in porous media","Anna Caroline Felix Santos de Jesus","In this work we propose a non-dimensionalization approach for theStokes-Brinkman model for flow in porous media. We study the effect of thedimensionless number found, which will be denoted by A and named as Anna'snumber, has on the outflow and transition between the Darcy and Stokes regime."
"269","arXiv:1906.12147","https://arxiv.org/abs/1906.12147","Utility-Preserving Privacy Mechanisms for Counting Queries","Natasha Fernandes, Kacem Lefki, Catuscia Palamidessi","Differential privacy (DP) and local differential privacy (LPD) are frameworksto protect sensitive information in data collections. They are both based onobfuscation. In DP the noise is added to the result of queries on the dataset,whereas in LPD the noise is added directly on the individual records, beforebeing collected. The main advantage of LPD with respect to DP is that it doesnot need to assume a trusted third party. The main disadvantage is that thetrade-off between privacy and utility is usually worse than in DP, andtypically to retrieve reasonably good statistics from the locally sanitizeddata it is necessary to have a huge collection of them. In this paper, we focuson the problem of estimating counting queries from collections of noisyanswers, and we propose a variant of LDP based on the addition of geometricnoise. Our main result is that the geometric noise has a better statisticalutility than other LPD mechanisms from the literature."
"270","arXiv:1906.12151","https://arxiv.org/abs/1906.12151","Place recognition in gardens by learning visual representations: data  set and benchmark analysis","Maria Leyva-Vallina, Nicola Strisciuglio, Nicolai Petkov","Visual place recognition is an important component of systems for cameralocalization and loop closure detection. It concerns the recognition of apreviously visited place based on visual cues only. Although it is a widelystudied problem for indoor and urban environments, the recent use of robots forautomation of agricultural and gardening tasks has created new problems, due tothe challenging appearance of garden-like environments. Garden scenespredominantly contain green colors, as well as repetitive patterns andtextures. The lack of available data recorded in gardens and naturalenvironments makes the improvement of visual localization algorithms difficult.In this paper we propose an extended version of the TB-Places data set, whichis designed for testing algorithms for visual place recognition. It containsimages with ground truth camera pose recorded in real gardens in differentseasons, with varying light conditions. We constructed and released a groundtruth for all possible pairs of images, indicating whether they depict the sameplace or not. We present the results of a benchmark analysis of methods basedon convolutional neural networks for holistic image description and placerecognition. We train existing networks (i.e. ResNet, DenseNet and VGG NetVLAD)as backbone of a two-way architecture with a contrastive loss function. Theresults that we obtained demonstrate that learning garden-tailoredrepresentations contribute to an improvement of performance, although thegeneralization capabilities are limited."
"271","arXiv:1906.12156","https://arxiv.org/abs/1906.12156","Detection of time-varying heat sources using an analytic forward model","Janne P. Tamminen","We present a simple, analytic point source model for both static andtime-varying point-like heat sources and the resulting temperature profile thatsolves the heat equation in dimension three. Simple algorithms to detect thelocation and spectral content of these sources are developed and numericallytested using Finite Element Mesh simulations. The resulting framework for heatsource reconstruction problems, which are ill-posed inverse problems, seemspromising and warrants for future research. Possible fields of application forour work are material testing, to detect manufacturing defects, and medicalimaging to detect abnormal health conditions."
"272","arXiv:1906.12158","https://arxiv.org/abs/1906.12158","Open-Ended Long-Form Video Question Answering via Hierarchical  Convolutional Self-Attention Networks","Zhu Zhang, Zhou Zhao, Zhijie Lin, Jingkuan Song, Xiaofei He","Open-ended video question answering aims to automatically generate thenatural-language answer from referenced video contents according to the givenquestion. Currently, most existing approaches focus on short-form videoquestion answering with multi-modal recurrent encoder-decoder networks.Although these works have achieved promising performance, they may still beineffectively applied to long-form video question answering due to the lack oflong-range dependency modeling and the suffering from the heavy computationalcost. To tackle these problems, we propose a fast Hierarchical ConvolutionalSelf-Attention encoder-decoder network(HCSA). Concretely, we first develop ahierarchical convolutional self-attention encoder to efficiently modellong-form video contents, which builds the hierarchical structure for videosequences and captures question-aware long-range dependencies from videocontext. We then devise a multi-scale attentive decoder to incorporatemulti-layer video representations for answer generation, which avoids theinformation missing of the top encoder layer. The extensive experiments showthe effectiveness and efficiency of our method."
"273","arXiv:1906.12159","https://arxiv.org/abs/1906.12159","Teaching DNNs to design fast fashion","Abhianv Ravi, Arun Patro, Vikram Garg, Anoop Kolar Rajagopal, Aruna Rajan, Rajdeep Hazra Banerjee","$ $""Fast Fashion"" spearheads the biggest disruption in fashion that enabledto engineer resilient supply chains to quickly respond to changing fashiontrends. The conventional design process in commercial manufacturing is oftenfed through ""trends"" or prevailing modes of dressing around the world thatindicate sudden interest in a new form of expression, cyclic patterns, andpopular modes of expression for a given time frame. In this work, we propose afully automated system to explore, detect, and finally synthesize trends infashion into design elements by designing representative prototypes of apparelgiven time series signals generated from social media feeds. Our system isenvisioned to be the first step in design of Fast Fashion where the productioncycle for clothes from design inception to manufacturing is meant to be rapidand responsive to current ""trends"". It also works to reduce wastage in fashionproduction by taking in customer feedback on sellability at the time of designgeneration. We also provide an interface wherein the designers can play withmultiple trending styles in fashion and visualize designs as interpolations ofelements of these styles. We aim to aid the creative process through generatinginteresting and inspiring combinations for a designer to mull by running themthrough her key customers."
"274","arXiv:1906.12165","https://arxiv.org/abs/1906.12165","Localizing Unseen Activities in Video via Image Query","Zhu Zhang, Zhou Zhao, Zhijie Lin, Jingkuan Song, Deng Cai","Action localization in untrimmed videos is an important topic in the field ofvideo understanding. However, existing action localization methods arerestricted to a pre-defined set of actions and cannot localize unseenactivities. Thus, we consider a new task to localize unseen activities invideos via image queries, named Image-Based Activity Localization. This taskfaces three inherent challenges: (1) how to eliminate the influence ofsemantically inessential contents in image queries; (2) how to deal with thefuzzy localization of inaccurate image queries; (3) how to determine theprecise boundaries of target segments. We then propose a novel self-attentioninteraction localizer to retrieve unseen activities in an end-to-end fashion.Specifically, we first devise a region self-attention method with relativeposition encoding to learn fine-grained image region representations. Then, weemploy a local transformer encoder to build multi-step fusion and reasoning ofimage and video contents. We next adopt an order-sensitive localizer todirectly retrieve the target segment. Furthermore, we construct a new datasetActivityIBAL by reorganizing the ActivityNet dataset. The extensive experimentsshow the effectiveness of our method."
"275","arXiv:1906.12170","https://arxiv.org/abs/1906.12170","LipReading with 3D-2D-CNN BLSTM-HMM and word-CTC models","Dilip Kumar Margam, Rohith Aralikatti, Tanay Sharma, Abhinav Thanda, Pujitha A K, Sharad Roy, Shankar M Venkatesan","In recent years, deep learning based machine lipreading has gainedprominence. To this end, several architectures such as LipNet, LCANet andothers have been proposed which perform extremely well compared to traditionallipreading DNN-HMM hybrid systems trained on DCT features. In this work, wepropose a simpler architecture of 3D-2D-CNN-BLSTM network with a bottlenecklayer. We also present analysis of two different approaches for lipreading onthis architecture. In the first approach, 3D-2D-CNN-BLSTM network is trainedwith CTC loss on characters (ch-CTC). Then BLSTM-HMM model is trained onbottleneck lip features (extracted from 3D-2D-CNN-BLSTM ch-CTC network) in atraditional ASR training pipeline. In the second approach, same 3D-2D-CNN-BLSTMnetwork is trained with CTC loss on word labels (w-CTC). The first approachshows that bottleneck features perform better compared to DCT features. Usingthe second approach on Grid corpus' seen speaker test set, we report $1.3\%$WER - a $55\%$ improvement relative to LCANet. On unseen speaker test set wereport $8.6\%$ WER which is $24.5\%$ improvement relative to LipNet. We alsoverify the method on a second dataset of $81$ speakers which we collected.Finally, we also discuss the effect of feature duplication on BLSTM-HMM modelperformance."
"276","arXiv:1906.12171","https://arxiv.org/abs/1906.12171","Gesture Recognition in RGB Videos UsingHuman Body Keypoints and Dynamic  Time Warping","Pascal Schneider, Raphael Memmesheimer, Ivanna Kramer, Dietrich Paulus","Gesture recognition opens up new ways for humans to intuitively interact withmachines. Especially for service robots, gestures can be a valuable addition tothe means of communication to, for example, draw the robot's attention tosomeone or something. Extracting a gesture from video data and classifying itis a challenging task and a variety of approaches have been proposed throughoutthe years. This paper presents a method for gesture recognition in RGB videosusing OpenPose to extract the pose of a person and Dynamic Time Warping (DTW)in conjunction with One-Nearest-Neighbor (1NN) for time-series classification.The main features of this approach are the independence of any specifichardware and high flexibility, because new gestures can be added to theclassifier by adding only a few examples of it. We utilize the robustness ofthe Deep Learning-based OpenPose framework while avoiding the data-intensivetask of training a neural network ourselves. We demonstrate the classificationperformance of our method using a public dataset."
"277","arXiv:1906.12172","https://arxiv.org/abs/1906.12172","New pointwise convolution in Deep Neural Networks through Extremely Fast  and Non Parametric Transforms","Joonhyun Jeong, Sung-Ho Bae","Some conventional transforms such as Discrete Walsh-Hadamard Transform (DWHT)and Discrete Cosine Transform (DCT) have been widely used as feature extractorsin image processing but rarely applied in neural networks. However, we foundthat these conventional transforms have the ability to capture thecross-channel correlations without any learnable parameters in DNNs. This paperfirstly proposes to apply conventional transforms to pointwise convolution,showing that such transforms significantly reduce the computational complexityof neural networks without accuracy performance degradation. Especially forDWHT, it requires no floating point multiplications but only additions andsubtractions, which can considerably reduce computation overheads. In addition,its fast algorithm further reduces complexity of floating point addition from$\mathcal{O}(n^2)$ to $\mathcal{O}(n\log n)$. These nice properties constructextremely efficient networks in the number parameters and operations, enjoyingaccuracy gain. Our proposed DWHT-based model gained 1.49\% accuracy increasewith 79.1\% reduced parameters and 48.4\% reduced FLOPs compared with itsbaseline model (MoblieNet-V1) on the CIFAR 100 dataset."
"278","arXiv:1906.12174","https://arxiv.org/abs/1906.12174","Road-network-based Rapid Geolocalization","Yongfei Li, Dongfang Yang, Shicheng Wang, Hao He","It has always been a research hotspot to use geographic information to assistthe navigation of unmanned aerial vehicles. In this paper, a road-network-basedlocalization method is proposed. We match roads in the measurement images tothe reference road vector map, and realize successful localization on areas aslarge as a whole city. The road network matching problem is treated as a pointcloud registration problem under two-dimensional projective transformation, andsolved under a hypothesise-and-test framework. To deal with the projectivepoint cloud registration problem, a global projective invariant feature isproposed, which consists of two road intersections augmented with theinformation of their tangents. We call it two road intersections tuple. Wededuce the closed-form solution for determining the alignment transformationfrom a pair of matching two road intersections tuples. In addition, we proposethe necessary conditions for the tuples to match. This can reduce the candidatematching tuples, thus accelerating the search to a great extent. We test allthe candidate matching tuples under a hypothesise-and-test framework to searchfor the best match. The experiments show that our method can localize thetarget area over an area of 400 within 1 second on a single cpu."
"279","arXiv:1906.12175","https://arxiv.org/abs/1906.12175","Are you really looking at me? A Framework for Extracting Interpersonal  Eye Gaze from Conventional Video","Minh Tran, Taylan Sen, Kurtis Haut, Mohammad Rafayet Ali, Mohammed Ehsan Hoque","Despite a revolution in the pervasiveness of video cameras in our dailylives, one of the most meaningful forms of nonverbal affective communication,interpersonal eye gaze, i.e. eye gaze relative to a conversation partner, isnot available from common video. We introduce the Interpersonal-CalibratingEye-gaze Encoder (ICE), which automatically extracts interpersonal gaze fromvideo recordings without specialized hardware and without prior knowledge ofparticipant locations. Leveraging the intuition that individuals spend a largeportion of a conversation looking at each other enables the ICE dynamicclustering algorithm to extract interpersonal gaze. We validate ICE in bothvideo chat using an objective metric with an infrared gaze tracker (F1=0.846,N=8), as well as in face-to-face communication with expert-rated evaluations ofeye contact (r= 0.37, N=170). We then use ICE to analyze behavior in twodifferent, yet important affective communication domains: interrogation-baseddeception detection, and communication skill assessment in speed dating. Wefind that honest witnesses break interpersonal gaze contact and look down moreoften than deceptive witnesses when answering questions (p=0.004, d=0.79). Inpredicting expert communication skill ratings in speed dating videos, wedemonstrate that interpersonal gaze alone has more predictive power than facialexpressions."
"280","arXiv:1906.12176","https://arxiv.org/abs/1906.12176","Filter Early, Match Late: Improving Network-Based Visual Place  Recognition","Stephen Hausler, Adam Jacobson, Michael Milford","CNNs have excelled at performing place recognition over time, particularlywhen the neural network is optimized for localization in the currentenvironmental conditions. In this paper we investigate the concept of featuremap filtering, where, rather than using all the activations within aconvolutional tensor, only the most useful activations are used. Since specificfeature maps encode different visual features, the objective is to removefeature maps that are detract from the ability to recognize a location acrossappearance changes. Our key innovation is to filter the feature maps in anearly convolutional layer, but then continue to run the network and extract afeature vector using a later layer in the same network. By filtering earlyvisual features and extracting a feature vector from a higher, more viewpointinvariant later layer, we demonstrate improved condition and viewpointinvariance. Our approach requires image pairs for training from the deploymentenvironment, but we show that state-of-the-art performance can regularly beachieved with as little as a single training image pair. An exhaustiveexperimental analysis is performed to determine the full scope of causalitybetween early layer filtering and late layer extraction. For validity, we usethree datasets: Oxford RobotCar, Nordland, and Gardens Point, achieving overallsuperior performance to NetVLAD. The work provides a number of new avenues forexploring CNN optimizations, without full re-training."
"281","arXiv:1906.12177","https://arxiv.org/abs/1906.12177","A multi-task U-net for segmentation with lazy labels","Rihuan Ke, Aurélie Bugeau, Nicolas Papadakis, Peter Schuetz, Carola-Bibiane Schönlieb","The need for labour intensive pixel-wise annotation is a major limitation ofmany fully supervised learning methods for image segmentation. In this paper,we propose a deep convolutional neural network for multi-class segmentationthat circumvents this problem by being trainable on coarse data labels combinedwith only a very small number of images with pixel-wise annotations. We callthis new labelling strategy 'lazy' labels. Image segmentation is thenstratified into three connected tasks: rough detection of class instances,separation of wrongly connected objects without a clear boundary, andpixel-wise segmentation to find the accurate boundaries of each object. Theseproblems are integrated into a multitask learning framework and the model istrained end-to-end in a semi-supervised fashion. The method is applied on adataset of food microscopy images. We show that the model gives accuratesegmentation results even if exact boundary labels are missing for a majorityof the annotated data. This allows more flexibility and efficiency for trainingdeep neural networks that are data hungry in a practical setting where manualannotation is expensive, by collecting more lazy (rough) annotations thanprecisely segmented images."
"282","arXiv:1906.12181","https://arxiv.org/abs/1906.12181","Reconstructing Perceived Images from Brain Activity by Visually-guided  Cognitive Representation and Adversarial Learning","Ziqi Ren, Jie Li, Xuetong Xue, Xin Li, Fan Yang, Zhicheng Jiao, Xinbo Gao","Reconstructing perceived images based on brain signals measured withfunctional magnetic resonance imaging (fMRI) is a significant and meaningfultask in brain-driven computer vision. However, the inconsistent distributionand representation between fMRI signals and visual images cause theheterogeneity gap, which makes it challenging to learn a reliable mappingbetween them. Moreover, considering that fMRI signals are extremelyhigh-dimensional and contain a lot of visually-irrelevant information,effectively reducing the noise and encoding powerful visual representations forimage reconstruction is also an open problem. We show that it is possible toovercome these challenges by learning a visually-relevant latent representationfrom fMRI signals guided by the corresponding visual features, and recoveringthe perceived images via adversarial learning. The resulting framework iscalled Dual-Variational Autoencoder/ Generative Adversarial Network(D-VAE/GAN). By using a novel 3-stage training strategy, it encodes bothcognitive and visual features via a dual structure variational autoencoder(D-VAE) to adapt cognitive features to visual feature space, and then learns toreconstruct perceived images with generative adversarial network (GAN).Extensive experiments on three fMRI recording datasets show that D-VAE/GANachieves more accurate visual reconstruction compared with the state-of-the-artmethods."
"283","arXiv:1906.12182","https://arxiv.org/abs/1906.12182","Adaptive Honeypot Engagement through Reinforcement Learning of  Semi-Markov Decision Processes","Linan Huang, Quanyan Zhu","The honeynet is a promising active cyber defense mechanism. It reveals thefundamental Indicators of Compromise (IoC) by luring attackers to conductadversarial behaviors in a controlled and monitored environment. The activeinteraction at the honeynet brings a high reward but also introduces highimplementation costs and risks of adversarial honeynet exploitation. In thiswork, we apply the infinite-horizon Semi-Markov Decision Process (SMDP) tocharacterize the stochastic transition and sojourn time of attackers in thehoneynet and quantify the reward-risk trade-off. In particular, we produceadaptive long-term engagement policies shown to be risk-averse, cost-effective,and time-efficient. Numerical results have demonstrated that our adaptiveinteraction policies can quickly attract attackers to the target honeypot andengage them for a sufficiently long period to obtain worthy threat information.Meanwhile, the penetration probability is kept at a low level.The results show that the expected utility is robust against attackers of alarge range of persistence and intelligence. Finally, we apply reinforcementlearning to SMDP to solve the curse of modeling. Under a prudent choice of thelearning rate and exploration policy, we achieve a quick and robust convergenceof the optimal policy and value."
"284","arXiv:1906.12187","https://arxiv.org/abs/1906.12187","Deep Radar Detector","Daniel Brodeski, Igal Bilik, Raja Giryes","While camera and LiDAR processing have been revolutionized since theintroduction of deep learning, radar processing still relies on classicaltools. In this paper, we introduce a deep learning approach for radarprocessing, working directly with the radar complex data. To overcome the lackof radar labeled data, we rely in training only on the radar calibration dataand introduce new radar augmentation techniques. We evaluate our method on theradar 4D detection task and demonstrate superior performance compared to theclassical approaches while keeping real-time performance. Applying deeplearning on radar data has several advantages such as eliminating the need foran expensive radar calibration process each time and enabling classification ofthe detected objects with almost zero-overhead."
"285","arXiv:1906.12334","https://arxiv.org/abs/1906.12334","K-Core Maximization through Edge Additions","Zhongxin Zhou, Fan Zhang, Xuemin Lin, Wenjie Zhang, Chen Chen","A popular model to measure the stability of a network is k-core - the maximalinduced subgraph in which every vertex has at least k neighbors. Many studiesmaximize the number of vertices in k-core to improve the stability of anetwork. In this paper, we study the edge k-core problem: Given a graph G, aninteger k and a budget b, add b edges to non-adjacent vertex pairs in G suchthat the k-core is maximized. We prove the problem is NP-hard and APX-hard. Aheuristic algorithm is proposed on general graphs with effective optimizationtechniques. Comprehensive experiments on 9 real-life datasets demonstrate theeffectiveness and the efficiency of our proposed methods."
"286","arXiv:1906.12188","https://arxiv.org/abs/1906.12188","A Deep Decoder Structure Based on WordEmbedding Regression for An  Encoder-Decoder Based Model for Image Captioning","Ahmad Asadi, Reza Safabakhsh","Generating textual descriptions for images has been an attractive problem forthe computer vision and natural language processing researchers in recentyears. Dozens of models based on deep learning have been proposed to solve thisproblem. The existing approaches are based on neural encoder-decoder structuresequipped with the attention mechanism. These methods strive to train decodersto minimize the log likelihood of the next word in a sentence given theprevious ones, which results in the sparsity of the output space. In this work,we propose a new approach to train decoders to regress the word embedding ofthe next word with respect to the previous ones instead of minimizing the loglikelihood. The proposed method is able to learn and extract long-terminformation and can generate longer fine-grained captions without introducingany external memory cell. Furthermore, decoders trained by the proposedtechnique can take the importance of the generated words into considerationwhile generating captions. In addition, a novel semantic attention mechanism isproposed that guides attention points through the image, taking the meaning ofthe previously generated word into account. We evaluate the proposed approachwith the MS-COCO dataset. The proposed model outperformed the state of the artmodels especially in generating longer captions. It achieved a CIDEr scoreequal to 125.0 and a BLEU-4 score equal to 50.5, while the best scores of thestate of the art models are 117.1 and 48.0, respectively."
"287","arXiv:1906.12189","https://arxiv.org/abs/1906.12189","Learning-based Model Predictive Control for Safe Exploration and  Reinforcement Learning","Torsten Koller, Felix Berkenkamp, Matteo Turchetta, Joschka Boedecker, Andreas Krause","Reinforcement learning has been successfully used to solve difficult tasks incomplex unknown environments. However, these methods typically do not provideany safety guarantees during the learning process. This is particularlyproblematic, since reinforcement learning agent actively explore theirenvironment. This prevents their use in safety-critical, real-worldapplications. In this paper, we present a learning-based model predictivecontrol scheme that provides high-probability safety guarantees throughout thelearning process. Based on a reliable statistical model, we construct provablyaccurate confidence intervals on predicted trajectories. Unlike previousapproaches, we allow for input-dependent uncertainties. Based on these reliablepredictions, we guarantee that trajectories satisfy safety constraints.Moreover, we use a terminal set constraint to recursively guarantee theexistence of safe control actions at every iteration. We evaluate the resultingalgorithm to safely explore the dynamics of an inverted pendulum and to solve areinforcement learning task on a cart-pole system with safety constraints."
"288","arXiv:1906.12192","https://arxiv.org/abs/1906.12192","GNN-FiLM: Graph Neural Networks with Feature-wise Linear Modulation","Marc Brockschmidt","This paper presents a new Graph Neural Network (GNN) type using feature-wiselinear modulations (FiLM). Many GNN variants propagate information along theedges of a graph by computing ""messages"" based only on the representationsource of each edge. In GNN-FiLM, the representation of the target node of anedge is additionally used to compute a transformation that can be applied toall incoming messages, allowing feature-wise modulation of the passedinformation.Experiments with GNN-FiLM as well as a number of baselines and relatedextensions show that it outperforms baseline methods while not beingsignificantly slower."
"289","arXiv:1906.12195","https://arxiv.org/abs/1906.12195","Adversarial Pixel-Level Generation of Semantic Images","Emanuele Ghelfi, Paolo Galeone, Michele De Simoni, Federico Di Mattia","Generative Adversarial Networks (GANs) have obtained extraordinary success inthe generation of realistic images, a domain where a lower pixel-level accuracyis acceptable. We study the problem, not yet tackled in the literature, ofgenerating semantic images starting from a prior distribution. Intuitively thisproblem can be approached using standard methods and architectures. However, abetter-suited approach is needed to avoid generating blurry, hallucinated andthus unusable images since tasks like semantic segmentation require pixel-levelexactness. In this work, we present a novel architecture for learning togenerate pixel-level accurate semantic images, namely Semantic GenerativeAdversarial Networks (SemGANs). The experimental evaluation shows that ourarchitecture outperforms standard ones from both a quantitative and aqualitative point of view in many semantic image generation tasks."
"290","arXiv:1906.12198","https://arxiv.org/abs/1906.12198","A New Malware Detection System Using a High Performance-ELM method","Shahab Shamshirband, Anthony T. Chronopoulos","A vital element of a cyberspace infrastructure is cybersecurity. Manyprotocols proposed for security issues, which leads to anomalies that affectthe related infrastructure of cyberspace. Machine learning (ML) methods used tomitigate anomalies behavior in mobile devices. This paper aims to apply a HighPerformance Extreme Learning Machine (HP-ELM) to detect possible anomalies intwo malware datasets. Two widely used datasets (the CTU-13 and Malware) areused to test the effectiveness of HP-ELM. Extensive comparisons are carried outin order to validate the effectiveness of the HP-ELM learning method. Theexperiment results demonstrate that the HP-ELM was the highest accuracy ofperformance of 0.9592 for the top 3 features with one activation function."
"291","arXiv:1906.12199","https://arxiv.org/abs/1906.12199","Remark on Algorithm 680: evaluation of the complex error function: Cause  and Remedy for the Loss of Accuracy Near the Real Axis","Mofreh Zaghloul","In this remark we identify the cause of the loss of accuracy in thecomputation of the Faddeyeva function, w(z), near the real axis when usingAlgorithm 680. We provide a simple correction to this problem which allows usto restore this code as one of the important reference routines for accuracycomparisons."
"292","arXiv:1906.12221","https://arxiv.org/abs/1906.12221","Safeguarding the Evidential Value of Forensic Cryptocurrency  Investigations","Michael Fröwis, Thilo Gottschalk, Bernhard Haslhofer, Christian Rückert, Paulina Pesch","Analyzing cryptocurrency payment flows has become a key forensic method inlaw enforcement and is nowadays used to investigate a wide spectrum of criminalactivities. However, despite its widespread adoption, the evidential value ofobtained findings in court is still largely unclear. In this paper, we focus onthe key ingredients of modern cryptocurrency analytic techniques, which areclustering heuristics and attribution tags. By empirically quantifying theeffect of CoinJoin transactions, we illustrate that clustering heuristics canlead to false interpretations. We then discuss clustering heuristics andattribution tags in the light of internationally accepted legal standards andrules for substantiating suspicions and providing evidence in court. From thatwe derive a set of legal key requirements and translate them into a datasharing framework that builds on existing legal and technical standards.Integrating that framework in modern cryptocurrency analytics tools could allowmore efficient and effective investigations, while safeguarding theirevidential value."
"293","arXiv:1906.12204","https://arxiv.org/abs/1906.12204","Modularity in Multilayer Networks using Redundancy-based Resolution and  Projection-based Inter-Layer Coupling","Alessia Amelio, Giuseppe Mangioni, Andrea Tagarelli","The generalized version of modularity for multilayer networks, a.k.a.multislice modularity, is characterized by two model parameters, namelyresolution factor and inter-layer coupling factor. The former corresponds to anotion of layer-specific relevance, whereas the inter-layer coupling factorrepresents the strength of node connections across the network layers. Despitethe potential of this approach, the setting of both parameters can bearbitrarily selected, without considering specific characteristics from thetopology of the multilayer network as well as from an available communitystructure. Also, the multislice modularity is not designed to explicitly modelorder relations over the layers, which is of prior importance for dynamicnetworks.This paper aims to overcome the main limitations of the multislice modularityby introducing a new formulation of modularity for multilayer networks. Werevise the role and semantics of both the resolution and inter-layer couplingfactors based on information available from the within-layer and inter-layerstructures of the multilayer communities. Also, our proposed multilayermodularity is general enough to consider orderings of network layers and theirconstraints on layer coupling. Experiments were carried out on synthetic andreal-world multilayer networks using state-of-the-art approaches for multilayercommunity detection. The obtained results have shown the meaningfulness of theproposed modularity, revealing the effects of different combinations of theresolution and inter-layer coupling functions. This work also represents astarting point for the development of new optimization methods for communitydetection in multilayer networks."
"294","arXiv:1906.12211","https://arxiv.org/abs/1906.12211","PUFFINN: Parameterless and Universally Fast FInding of Nearest Neighbors","Martin Aumüller, Tobias Christiani, Rasmus Pagh, Michael Vesterli","We present PUFFINN, a parameterless LSH-based index for solving the$k$-nearest neighbor problem with probabilistic guarantees. By parameterless wemean that the user is only required to specify the amount of memory the indexis supposed to use and the result quality that should be achieved. The indexcombines several heuristic ideas known in the literature. By small adaptions tothe query algorithm, we make heuristics rigorous. We perform experiments onreal-world and synthetic inputs to evaluate implementation choices and showthat the implementation satisfies the quality guarantees while beingcompetitive with other state-of-the-art approaches to nearest neighbor search.We describe a novel synthetic data set that is difficult to solve for almostall existing nearest neighbor search approaches, and for which PUFFINNsignificantly outperform previous methods."
"295","arXiv:1906.12213","https://arxiv.org/abs/1906.12213","On the notion of number in humans and machines","Norbert Bátfai, Dávid Papp, Gergő Bogacsovics, Máté Szabó, Viktor Szilárd Simkó, Márió Bersenszki, Gergely Szabó, Lajos Kovács, Ferencz Kovács, Erik Szilveszter Varga","In this paper, we performed two types of software experiments to study thenumerosity classification (subitizing) in humans and machines. Experimentsfocus on a particular kind of task is referred to as Semantic MNIST or simplySMNIST where the numerosity of objects placed in an image must be determined.The experiments called SMNIST for Humans are intended to measure the capacityof the Object File System in humans. In this type of experiment the measurementresult is in well agreement with the value known from the cognitive psychologyliterature. The experiments called SMNIST for Machines serve similar purposesbut they investigate existing, well known (but originally developed for otherpurpose) and under development deep learning computer programs. Thesemeasurement results can be interpreted similar to the results from SMNIST forHumans. The main thesis of this paper can be formulated as follows: in machinesthe image classification artificial neural networks can learn to distinguishnumerosities with better accuracy when these numerosities are smaller than thecapacity of OFS in humans. Finally, we outline a conceptual framework toinvestigate the notion of number in humans and machines."
"296","arXiv:1906.12216","https://arxiv.org/abs/1906.12216","On the robust existence of piecewise quadratic Lyapunov functions for  hybrid models of gene regulatory networks","Mirko Pasquini, David Angeli","In this work we addressed the problem of stability analysis for an uncertainpiecewise affine model of a genetic regulatory network. In particular weconsidered polytopic parameter uncertainties on the proteins production ratefunctions, giving conditions for the existence of a piecewise quadraticLyapunov function for any possible realization of the system. In the spirit ofother works in literature, the resulting conditions will be given on thevertices of the parameter polytope, while still taking into consideration thepiecewise nature of the Lyapunov function and the presence, in general, ofsliding modes solutions. An example is shown to prove the validity andapplicability of the theoretical results."
"297","arXiv:1906.12218","https://arxiv.org/abs/1906.12218","Continual Rare-Class Recognition with Emerging Novel Subclasses","Hung Nguyen, Xuejian Wang, Leman Akoglu","Given a labeled dataset that contains a rare (or minority) class ofof-interest instances, as well as a large class of instances that are not ofinterest, how can we learn to recognize future of-interest instances over acontinuous stream? We introduce RaRecognize, which (i) estimates a generaldecision boundary between the rare and the majority class, (ii) learns torecognize individual rare subclasses that exist within the training data, aswell as (iii) flags instances from previously unseen rare subclasses as newlyemerging. The learner in (i) is general in the sense that by construction it isdissimilar to the specialized learners in (ii), thus distinguishes minorityfrom the majority without overly tuning to what is seen in the training data.Thanks to this generality, RaRecognize ignores all future instances that itlabels as majority and recognizes the recurrent as well as emerging raresubclasses only. This saves effort at test time as well as ensures that themodel size grows moderately over time as it only maintains specialized minoritylearners. Through extensive experiments, we show that RaRecognize outperformsstate-of-the art baselines on three real-world datasets that containcorporate-risk and disaster documents as rare classes."
"298","arXiv:1906.12220","https://arxiv.org/abs/1906.12220","Computing Haar Measures","Arno Pauly, Dongseong Seon, Martin Ziegler","According to Haar's Theorem, every compact group $G$ admits a uniqueleft-invariant Borel probability measure $\mu_G$. Let the Haar integral (of$G$) denote the functional $\int_G:\mathcal{C}(G)\ni f\mapsto \int f\,d\mu_G$integrating any continuous function $f:G\to\mathbb{R}$ with respect to $\mu_G$.This generalizes, and recovers for the additive group $G=[0;1)\mod 1$, theusual Riemann integral: computable (cmp. Weihrauch 2000, Theorem~6.4.1), and ofcomputational cost characterizing complexity class #P$_1$ (cmp. Ko 1991,Theorem~5.32). We establish that in fact every computably compact computablemetric group renders the Haar integral computable: once using an elegantsynthetic argument; and once presenting and analyzing an explicit, imperativealgorithm. Regarding computational complexity, for the groups $\mathcal{SO}(3)$and $\mathcal{SU}(2)$ we reduce the Haar integral to and from Euclidean/Riemannintegration. In particular both also characterize #P$_1$."
"299","arXiv:1906.12225","https://arxiv.org/abs/1906.12225","Modelling Airway Geometry as Stock Market Data using Bayesian  Changepoint Detection","Kin Quan, Ryutaro Tanno, Michael Duong, Arjun Nair, Rebecca Shipley, Mark Jones, Christopher Brereton, John Hurst, David Hawkes, Joseph Jacob","Numerous lung diseases, such as idiopathic pulmonary fibrosis (IPF), exhibitdilation of the airways. Accurate measurement of dilatation enables assessmentof the progression of disease. Unfortunately the combination of image noise andairway bifurcations causes high variability in the profiles of cross-sectionalareas, rendering the identification of affected regions very difficult. Here weintroduce a noise-robust method for automatically detecting the location ofprogressive airway dilatation given two profiles of the same airway acquired atdifferent time points. We propose a probabilistic model of abrupt relativevariations between profiles and perform inference via Reversible Jump MarkovChain Monte Carlo sampling. We demonstrate the efficacy of the proposed methodon two datasets; (i) images of healthy airways with simulated dilatation; (ii)pairs of real images of IPF-affected airways acquired at 1 year intervals. Ourmodel is able to detect the starting location of airway dilatation with anaccuracy of 2.5mm on simulated data. The experiments on the IPF dataset displayreasonable agreement with radiologists. We can compute a relative change inairway volume that may be useful for quantifying IPF disease progression."
"300","arXiv:1906.12230","https://arxiv.org/abs/1906.12230","FIESTA: Fast IdEntification of State-of-The-Art models using adaptive  bandit algorithms","Henry B. Moss, Andrew Moore, David S. Leslie, Paul Rayson","We present FIESTA, a model selection approach that significantly reduces thecomputational resources required to reliably identify state-of-the-artperformance from large collections of candidate models. Despite being known toproduce unreliable comparisons, it is still common practice to compare modelevaluations based on single choices of random seeds. We show that reliablemodel selection also requires evaluations based on multiple train-test splits(contrary to common practice in many shared tasks). Using bandit theory fromthe statistics literature, we are able to adaptively determine appropriatenumbers of data splits and random seeds used to evaluate each model, focusingcomputational resources on the evaluation of promising models whilst avoidingwasting evaluations on models with lower performance. Furthermore, ouruser-friendly Python implementation produces confidence guarantees of correctlyselecting the optimal model. We evaluate our algorithms by selecting between 8target-dependent sentiment analysis methods using dramatically fewer modelevaluations than current model selection approaches."
"301","arXiv:1906.12237","https://arxiv.org/abs/1906.12237","SybilQuorum: Open Distributed Ledgers Through Trust Networks","Alberto Sonnino, George Danezis","The Sybil attack plagues all peer-to-peer systems, and modern opendistributed ledgers employ a number of tactics to prevent it from proof ofwork, or other resources such as space, stake or memory, to traditionaladmission control in permissioned settings. With SybilQuorum we propose analternative approach to securing an open distributed ledger against Sybilattacks, and ensuring consensus amongst honest participants, leveraging socialnetwork based Sybil defences. We show how nodes expressing their trustrelationships through the ledger can bootstrap and operate a value system, andgeneral transaction system, and how Sybil attacks are thwarted. We empiricallyevaluate our system as a secure Federated Byzantine Agreement System, andextend the theory of those systems to do so."
"302","arXiv:1906.12239","https://arxiv.org/abs/1906.12239","L*-Based Learning of Markov Decision Processes (Extended Version)","Martin Tappler, Bernhard K. Aichernig, Giovanni Bacci, Maria Eichlseder, Kim G. Larsen","Automata learning techniques automatically generate system models from testobservations. These techniques usually fall into two categories: passive andactive. Passive learning uses a predetermined data set, e.g., system logs. Incontrast, active learning actively queries the system under learning, which isconsidered more efficient.An influential active learning technique is Angluin's L* algorithm forregular languages which inspired several generalisations from DFAs to otherautomata-based modelling formalisms. In this work, we study L*-based learningof deterministic Markov decision processes, first assuming an ideal settingwith perfect information. Then, we relax this assumption and present a novellearning algorithm that collects information by sampling system traces viatesting. Experiments with the implementation of our sampling-based algorithmsuggest that it achieves better accuracy than state-of-the-art passive learningtechniques with the same amount of test data. Unlike existing learningalgorithms with predefined states, our algorithm learns the complete modelstructure including the states."
"303","arXiv:1906.12242","https://arxiv.org/abs/1906.12242","Bidirectional Type Class Instances (Extended Version)","Koen Pauwels, Georgios Karachalias, Michiel Derhaeg, Tom Schrijvers","GADTs were introduced in Haskell's eco-system more than a decade ago, buttheir interaction with several mainstream features such as type classes andfunctional dependencies has a lot of room for improvement. More specifically,for some GADTs it can be surprisingly difficult to provide an instance for eventhe simplest of type classes.In this paper we identify the source of this shortcoming and address it byintroducing a conservative extension to Haskell's type classes: {\emBidirectional Type Class Instances}. In essence, under our interpretation classinstances correspond to logical bi-implications, in contrast to theirtraditional unidirectional interpretation. %counter-intuitive behaviorWe present a fully-fledged design of bidirectional instances, covering thespecification of typing and elaboration into System FC, as well as an algorithmfor type inference and elaboration. We provide a proof-of-conceptimplementation of our algorithm, and revisit the meta-theory of type classes inthe presence of our extension."
"304","arXiv:1906.12249","https://arxiv.org/abs/1906.12249","Anticipatory Thinking: A Metacognitive Capability","Adam Amos-Binks, Dustin Dannenhauer","Anticipatory thinking is a complex cognitive process for assessing andmanaging risk in many contexts. Humans use anticipatory thinking to identifypotential future issues and proactively take actions to manage their risks. Inthis paper we define a cognitive systems approach to anticipatory thinking as ametacognitive goal reasoning mechanism. The contributions of this paper include(1) defining anticipatory thinking in the MIDCA cognitive architecture, (2)operationalizing anticipatory thinking as a three step process for managingrisk in plans, and (3) a numeric risk assessment calculating an expectedcost-benefit ratio for modifying a plan with anticipatory actions."
"305","arXiv:1906.12286","https://arxiv.org/abs/1906.12286","RECURSIA-RRT: Recursive translatable point-set pattern discovery with  removal of redundant translators","David Meredith","Two algorithms, RECURSIA and RRT, are presented, designed to increase thecompression factor achieved using SIATEC-based point-set cover algorithms.RECURSIA recursively applies a TEC cover algorithm to the patterns in the TECsthat it discovers. RRT attempts to remove translators from each TEC withoutreducing its covered set. When evaluated with COSIATEC, SIATECCompress andForth's algorithm on the JKU Patterns Development Database, using RECURSIA withor without RRT increased compression factor and recall but reduced precision.Using RRT alone increased compression factor and reduced recall and precision,but had a smaller effect than RECURSIA."
"306","arXiv:1906.12250","https://arxiv.org/abs/1906.12250","Adaptation and learning over networks under subspace constraints -- Part  II: Performance Analysis","Roula Nassif, Stefan Vlaski, Ali H. Sayed","Part I of this paper considered optimization problems over networks whereagents have individual objectives to meet, or individual parameter vectors toestimate, subject to subspace constraints that require the objectives acrossthe network to lie in low-dimensional subspaces. Starting from the centralizedprojected gradient descent, an iterative and distributed solution was proposedthat responds to streaming data and employs stochastic approximations in placeof actual gradient vectors, which are generally unavailable. We examined thesecond-order stability of the learning algorithm and we showed that, for smallstep-sizes $\mu$, the proposed strategy leads to small estimation errors on theorder of $\mu$. This Part II examines steady-state performance. The resultsreveal explicitly the influence of the gradient noise, data characteristics,and subspace constraints, on the network performance. The results also showthat in the small step-size regime, the iterates generated by the distributedalgorithm achieve the centralized steady-state performance."
"307","arXiv:1906.12251","https://arxiv.org/abs/1906.12251","Engineering study on the use of Head-Mounted display for Brain- Computer  Interface","Anton Andreev (GIPSA-Services), Grégoire Cattan (GIPSA-VIBS, IHMTEK), M Congedo (GIPSA-VIBS)","In this article, we explore the availability of head-mounted display (HMD)devices which can be coupled in a seamless way with P300-based brain-computerinterfaces (BCI) using electroencephalography (EEG). The P300 is anevent-related potential appearing about 300ms after the onset of a stimulation.The recognition of this potential on the ongoing EEG requires the knowledge ofthe exact onset of the stimuli. In other words, the stimulations presented inthe HMD must be perfectly synced with the acquisition of the EEG signal. Thisis done through a process called tagging. The tagging must be performed in areliable and robust way so as to guarantee the recognition of the P300 and thusthe performance of the BCI. An HMD device should also be able to render imagesfast enough to allow an accurate perception of the stimulations, and equally tonot perturb the acquisition of the EEG signal. In addition, an affordable HMDdevice is needed for both research and entertainment purposes. In this study,we selected and tested two HMD configurations."
"308","arXiv:1906.12255","https://arxiv.org/abs/1906.12255","An Energy Stable BDF2 Fourier Pseudo-Spectral Numerical Scheme for the  Square Phase Field Crystal Equation","Kelong Cheng, Cheng Wang, Steven M. Wise","In this paper we propose and analyze an energy stable numerical scheme forthe square phase field crystal (SPFC) equation, a gradient flow modelingcrystal dynamics at the atomic scale in space but on diffusive scales in time.In particular, a modification of the free energy potential to the standardphase field crystal model leads to a composition of the 4-Laplacian and theregular Laplacian operators. To overcome the difficulties associated with thishighly nonlinear operator, we design numerical algorithms based on thestructures of the individual energy terms. A Fourier pseudo-spectralapproximation is taken in space, in such a way that the energy structure isrespected, and summation-by-parts formulae enable us to study the discreteenergy stability for such a high-order spatial discretization. In the temporalapproximation, a second order BDF stencil is applied, combined with anappropriate extrapolation for the concave diffusion term(s). A second orderartificial Douglas-Dupont-type regularization term is added to ensure energystability, and a careful analysis leads to the artificial linear diffusioncoming at an order lower that that of surface diffusion term. Such a choiceleads to reduced numerical dissipation. At a theoretical level, the uniquesolvability, energy stability are established, and an optimal rate convergenceanalysis is derived in the $\ell^\infty (0,T; \ell^2) \cap \ell^2 (0,T; H_N^3)$norm. In the numerical implementation, the preconditioned steepest descent(PSD) iteration is applied to solve for the composition of the highly nonlinear4-Laplacian term and the standard Laplacian term, and a geometric convergenceis assured for such an iteration. Finally, a few numerical experiments arepresented, which confirm the robustness and accuracy of the proposed scheme."
"309","arXiv:1906.12264","https://arxiv.org/abs/1906.12264","Accurate Robotic Pouring for Serving Drinks","Yongqiang Huang, Yu Sun","Pouring is the second most frequently executed motion in cooking scenarios.In this work, we present our system of accurate pouring that generates theangular velocities of the source container using recurrent neural networks. Wecollected demonstrations of human pouring water. We made a physical system onwhich the velocities of the source container were generated at each time stepand executed by a motor. We tested our system on pouring water from containersthat are not used for training and achieved an error of as low as 4milliliters. We also used the system to pour oil and syrup. The accuracyachieved with oil is slightly lower than but comparable with that of water."
"310","arXiv:1906.12266","https://arxiv.org/abs/1906.12266","Growing Action Spaces","Gregory Farquhar, Laura Gustafson, Zeming Lin, Shimon Whiteson, Nicolas Usunier, Gabriel Synnaeve","In complex tasks, such as those with large combinatorial action spaces,random exploration may be too inefficient to achieve meaningful learningprogress. In this work, we use a curriculum of progressively growing actionspaces to accelerate learning. We assume the environment is out of our control,but that the agent may set an internal curriculum by initially restricting itsaction space. Our approach uses off-policy reinforcement learning to estimateoptimal value functions for multiple action spaces simultaneously andefficiently transfers data, value estimates, and state representations fromrestricted action spaces to the full task. We show the efficacy of our approachin proof-of-concept control tasks and on challenging large-scale StarCraftmicromanagement tasks with large, multi-agent action spaces."
"311","arXiv:1906.12269","https://arxiv.org/abs/1906.12269","Certifiable Robustness and Robust Training for Graph Convolutional  Networks","Daniel Zügner, Stephan Günnemann","Recent works show that Graph Neural Networks (GNNs) are highly non-robustwith respect to adversarial attacks on both the graph structure and the nodeattributes, making their outcomes unreliable. We propose the first method forcertifiable (non-)robustness of graph convolutional networks with respect toperturbations of the node attributes. We consider the case of binary nodeattributes (e.g. bag-of-words) and perturbations that are L_0-bounded. If anode has been certified with our method, it is guaranteed to be robust underany possible perturbation given the attack model. Likewise, we can certifynon-robustness. Finally, we propose a robust semi-supervised training procedurethat treats the labeled and unlabeled nodes jointly. As shown in ourexperimental evaluation, our method significantly improves the robustness ofthe GNN with only minimal effect on the predictive accuracy."
"312","arXiv:1906.12274","https://arxiv.org/abs/1906.12274","Stable Matchings in Divorce Graphs","Jiehua Chen","In this paper, we study the Reaching Stable Marriage via Divorce Operationsproblem, which given a Stable Marriage instance and an initial matching, askswhether a stable matching for the instance is reachable by a sequence ofdivorce operations as introduced by Tamura [Journal of Combinatorial Theory,1993]. We show that for incomplete preferences with ties, Reaching StableMarriage via Divorce Operations is NP-complete."
"313","arXiv:1906.12278","https://arxiv.org/abs/1906.12278","Towards Assigning Priorities in Queues Using Age of Information","Jin Xu, Natarajan Gautam","We consider a priority queueing system where a single processor serves kclasses of packets that are generated randomly following Poisson processes. Ourobjective is to compute the expected Peak Age of Information (PAoI) undervarious scenarios. In particular, we consider two situations where the buffersizes are one and infinite, and in the infinite buffer size case we considerFirst Come First Serve (FCFS) and Last Come First Serve (LCFS) as servicedisciplines. We derive PAoI exactly for the exponential service time case andbounds (which are excellent approximations) for the general service time case.Using those we suggest optimal ordering of priorities for the variousscenarios. We perform extensive numerical studies to validate our results anddevelop insights."
"314","arXiv:1906.12279","https://arxiv.org/abs/1906.12279","Motion Prediction with Recurrent Neural Network Dynamical Models and  Trajectory Optimization","Philipp Kratzer, Marc Toussaint, Jim Mainprice","Predicting human motion in unstructured and dynamic environments is difficultas humans naturally exhibit complex behaviors that can change drastically fromone environment to the next. In order to alleviate this issue, we propose toencode the lower level aspects of human motion separately from the higher levelgeometrical aspects, which we believe will generalize better over environments.In contrast to our prior work~\cite{kratzer2018}, we encode the short-termbehavior by using a state-of-the-art recurrent neural network structure insteadof a Gaussian process. In order to perform longer-term behavior predictionsthat account for variation in tasks and environments, we propose to make use ofgradient-based trajectory optimization. Preliminary experiments on real motiondata demonstrate the efficacy of the approach."
"315","arXiv:1906.12280","https://arxiv.org/abs/1906.12280","Learning Arbitration for Shared Autonomy by Hindsight Data Aggregation","Yoojin Oh, Marc Toussaint, Jim Mainprice","In this paper we present a framework for the teleoperation of pick-and-placetasks. We define a shared control policy that allows to blend between directuser control and autonomous control based on user intent inference. One of themain challenges in shared autonomy systems is to define the arbitrationfunction, which decides when to let the autonomous agent take over. In thiswork, we propose a model and training method to learn the arbitration function.Our model is based on a recurrent neural network that takes as input the state,intent prediction scores and user command to produce an arbitration betweenuser and robot commands. This work extends our previous work on differentiablepolicies for shared autonomy. Differentiability of the policy is desirable tofurther train the shared autonomy system end-to-end. In this work we proposetraining of the arbitration function by using data from user performing thetask with shared control. We present initial results by teleoperating a gripperin a virtual environment using pre-trained motion generation and intentprediction. We compare our data aggregation training procedure to a handcraftedarbitration function. Our preliminary results show the efficacy of the approachand shed light on limitations that we believe demonstrate the need for useradaptability in shared autonomy systems."
"316","arXiv:1906.12282","https://arxiv.org/abs/1906.12282","Synaptic Delays for Temporal Feature Detection in Dynamic Neuromorphic  Processors","Fredrik Sandin, Mattias Nilsson","Spiking neural networks implemented in dynamic neuromorphic processors arewell suited for spatiotemporal feature detection and learning, for example inultra low-power embedded intelligence and deep edge applications. Such patternrecognition networks naturally involve a combination of dynamic delaymechanisms and coincidence detection. Inspired by an auditory feature detectioncircuit in crickets, featuring a delayed excitation by postinhibitory rebound,we investigate disynaptic delay elements formed by inhibitory-excitatory pairsof dynamic synapses. We configure such disynaptic delay elements in theDYNAP-SE neuromorphic processor and characterize the distribution of delayedexcitations resulting from device mismatch. Furthermore, we present a networkthat mimics the auditory feature detection circuit of crickets and demonstratehow varying synapse weights, input noise and processor temperature affects thecircuit. Interestingly, we find that the disynaptic delay elements can beconfigured such that the timing and magnitude of the delayed postsynapticexcitation depend mainly on the efficacy of the inhibitory and excitatorysynapses, respectively. Delay elements of this kind can be implemented in otherreconfigurable dynamic neuromorphic processors and opens up for synapse leveltemporal feature tuning with large fan-in and flexible delays of order 10-100ms."
"317","arXiv:1906.12283","https://arxiv.org/abs/1906.12283","Numerical method for scattering problems in periodic waveguides","Ruming Zhang","In this paper, we propose a new numerical method for scattering problems inperiodic waveguide, based on the newly established contour integralrepresentation of solutions in a previous paper by the author (see [Zhadf]).For this kind of problems, solutions are obtained via the Limiting AbsorptionPrinciple and we all them LAP solutions. Based on the Floquet-Bloch transformand analytic Fredholm theory, an LAP solution could be written explicitly as anintegral of quasi-periodic solutions on a contour, which depends on theperiodic structure. Compared to previous numerical methods for this kind ofproblems, we do not need to adopt the LAP for approximation, thus a standarderror estimation is easily carried out. Based on this method, we also develop anumerical solver for the halfguide problems. This method is also based on theresult from [Zhadf], which shows that any LAP solution of a halfguide problemcould be extended into a fullguide problem with a non-vanishing source term(notuniquely!). So first we approximate the source term from the boundary data by aregularization method, and then the LAP solution could be obtained from thecorresbonding fullguide problem. At the end of this paper, we also show somenumerical results to present the efficiency of our numerical methods."
"318","arXiv:1906.12284","https://arxiv.org/abs/1906.12284","Widening the Representation Bottleneck in Neural Machine Translation  with Lexical Shortcuts","Denis Emelin, Ivan Titov, Rico Sennrich","The transformer is a state-of-the-art neural translation model that usesattention to iteratively refine lexical representations with information drawnfrom the surrounding context. Lexical features are fed into the first layer andpropagated through a deep network of hidden layers. We argue that the need torepresent and propagate lexical features in each layer limits the model'scapacity for learning and representing other information relevant to the task.To alleviate this bottleneck, we introduce gated shortcut connections betweenthe embedding layer and each subsequent layer within the encoder and decoder.This enables the model to access relevant lexical content dynamically, withoutexpending limited resources on storing it within intermediate states. We showthat the proposed modification yields consistent improvements over a baselinetransformer on standard WMT translation tasks in 5 translation directions (0.9BLEU on average) and reduces the amount of lexical information passed along thehidden layers. We furthermore evaluate different ways to integrate lexicalconnections into the transformer architecture and present ablation experimentsexploring the effect of proposed shortcuts on model behavior."
"319","arXiv:1906.12298","https://arxiv.org/abs/1906.12298","Detecting Feedback Vertex Sets of Size $k$ in $O^\star(2.7^k)$ Time","Jason Li, Jesper Nederlof","In the Feedback Vertex Set problem, one is given an undirected graph $G$ andan integer $k$, and one needs to determine whether there exists a set of $k$vertices that intersects all cycles of $G$ (a so-called feedback vertex set).Feedback Vertex Set is one of the most central problems in parameterizedcomplexity: It served as an excellent test bed for many important algorithmictechniques in the field such as Iterative Compression~[Guo et al. (JCSS'06)],Randomized Branching~[Becker et al. (J. Artif. Intell. Res'00)] andCut\&Count~[Cygan et al. (FOCS'11)]. In particular, there has been a long racefor the smallest dependence $f(k)$ in run times of the type $O^\star(f(k))$,where the $O^\star$ notation omits factors polynomial in $n$. This race seemedto be run in 2011, when a randomized algorithm $O^\star(3^k)$ time algorithmbased on Cut\&Count was introduced.In this work, we show the contrary and give a $O^\star(2.7^k)$ timerandomized algorithm. Our algorithm combines all mentioned techniques withsubstantial new ideas: First, we show that, given a feedback vertex set of size$k$ of bounded average degree, a tree decomposition of width $(1-\Omega(1))k$can be found in polynomial time. Second, we give a randomized branchingstrategy inspired by the one from~[Becker et al. (J. Artif. Intell. Res'00)] toreduce to the aforementioned bounded average degree setting. Third, we obtainsignificant run time improvements by employing fast matrix multiplication."
"320","arXiv:1906.12300","https://arxiv.org/abs/1906.12300","Singular integration towards a spectrally accurate finite difference  operator","Andre Nachbin","It is an established fact that a finite difference operator approximates aderivative with a fixed algebraic rate of convergence. Nevertheless, we exhibita new finite difference operator and prove it has spectral accuracy. Its rateof convergence is not fixed and improves with the function's regularity. Forexample, the rate of convergence is exponential for analytic functions. Our newframework is conceptually nonstandard, making no use of polynomialinterpolation, nor any other expansion basis, such as typically considered inapproximation theory. Our new method arises solely from the numericalmanipulation of singular integrals, through an accurate quadrature for CauchyPrincipal Value convolutions. The kernel is a distribution which gives rise tomulti-resolution grid coefficients. The respective distributional finitedifference scheme is spatially structured having stencils of different supportwidths. These multi-resolution stencils test/estimate function variations in anonlocal fashion, giving rise to a highly accurate distributional finitedifference operator. Computational illustrations are presented, where theaccuracy and roundoff error structure are compared with the respective Fourierbased method. We also compare our method with a recent and popular complex-stepmethod."
"321","arXiv:1906.12307","https://arxiv.org/abs/1906.12307","Implementing Ethics in AI: An industrial multiple case study","Ville Vakkuri, Kai-Kristian Kemell, Pekka Abrahamsson","Solutions in artificial intelligence (AI) are becoming increasinglywidespread in system development endeavors. As the AI systems affect variousstakeholders due to their unique nature, the growing influence of these systemscalls for eth-ical considerations. Academic discussion and practical examplesof autonomous system failures have highlighted the need for implementing ethicsin software development. However, research on methods and tools forimplementing ethics into AI system design and development in practice is stilllacking. This paper be-gins to address this focal problem by providing abaseline for ethics in AI based software development. This is achieved byreporting results from an industrial multiple case study on AI systemsdevelopment in the health care sector. In the context of this study, ethicswere perceived as interplay of transparency, re-sponsibility andaccountability, upon which research model is outlined. Through these cases, weexplore the current state of practice out on the field in the ab-sence offormal methods and tools for ethically aligned design. Based on our data, wediscuss the current state of practice and outline existing good practic-es, aswell as suggest future research directions in the area."
"322","arXiv:1906.12314","https://arxiv.org/abs/1906.12314","The Winnability of Klondike and Many Other Single-Player Card Games","Charlie Blake, Ian P. Gent","The most famous single-player card game is 'Klondike', but our ignorance ofits winnability percentage has been called ""one of the embarrassments ofapplied mathematics"". Klondike is just one of many single-player card games,generically called 'patience' or 'solitaire' games, for which players have longwanted to know how likely a particular game is to be winnable for a randomdeal. A number of different games have been studied empirically in the academicliterature and by non-academic enthusiasts. Here we show that a single generalpurpose Artificial Intelligence program, called ""Solvitaire"", can be used todetermine the winnability percentage of approximately 30 differentsingle-player card games with a 95\% confidence interval of +/- 0.1\% orbetter. For example, we report the winnability of Klondike as 81.956% +/-0.096% (in the 'thoughtful' variant where the player knows the location of allcards), a 30-fold reduction in confidence interval over the best previousresult. Almost all our results are either entirely new or represent significantimprovements on previous knowledge."
"323","arXiv:1906.12315","https://arxiv.org/abs/1906.12315","Quantitative OCT reconstructions for dispersive media","Peter Elbau, Leonidas Mindrinos, Leopold Veselka","We consider the problem of reconstructing the position and the time-dependentoptical properties of a linear dispersive medium from OCT measurements. Themedium is multi-layered described by a piece-wise inhomogeneous refractiveindex. The measurement data are from a frequency-domain OCT system and weaddress also the phase retrieval problem. The parameter identification problemcan be formulated as an one-dimensional inverse problem. Initially, we dealwith a non-dispersive medium and we derive an iterative scheme that is the coreof the algorithm for the frequency-dependent parameter. The case of absorbingmedium is also addressed."
"324","arXiv:1906.12335","https://arxiv.org/abs/1906.12335","Critical Edge Identification: A K-Truss Based Model","Wenjie Zhu, Mengqi Zhang, Chen Chen, Xiaoyang Wang, Fan Zhang, Xuemin Lin","In a social network, the strength of relationships between users cansignificantly affect the stability of the network. In this paper, we use thek-truss model to measure the stability of a social network. To identifycritical connections, we propose a novel problem, named k-truss minimization.Given a social network G and a budget b, it aims to find b edges for deletionwhich can lead to the maximum number of edge breaks in the k-truss of G. Weshow that the problem is NP-hard. To accelerate the computation, novel pruningrules are developed to reduce the candidate size. In addition, we propose anupper bound based strategy to further reduce the searching space. Comprehensiveexperiments are conducted over real social networks to demonstrate theefficiency and effectiveness of the proposed techniques."
"325","arXiv:1906.12319","https://arxiv.org/abs/1906.12319","A Resilience-based Method for Prioritizing Post-event Building  Inspections","Ali Lenjani, Ilias Bilionis, Shirley Dyke, Chul Min Yeum, Ricardo Monteiro","Despite the wide range of possible scenarios in the aftermath of a disruptiveevent, each community can make choices to improve its resilience, or itsability to bounce back. A resilient community is one that has prepared for, andcan thus absorb, recover from, and adapt to the disruptive event. One importantaspect of the recovery phase is assessing the extent of the damage in the builtenvironment through post-event building inspections. In this paper, we developand demonstrate a resilience-based methodology intended to support rapidpost-event decision-making about inspection priorities with limitedinformation. The method uses the basic characteristics of the building stock ina community (floor area, number of stories, type of construction andconfiguration) to assign structure-specific fragility functions to eachbuilding. For an event with a given seismic intensity, the probability of eachbuilding reaching a particular damage state is determined, and is used topredict the actual building states and priorities for inspection. Losses arecomputed based on building usage category, estimated inspection costs, theconsequences of erroneous decisions, and the potential for unnecessaryrestrictions in access. The aim is to provide a means for a community to makerapid cost-based decisions related to inspection of their building inventory.We pose the decision problem as an integer optimization problem that attemptsto minimize the expected loss to the community. The advantages of this approachare that it: (i) is simple, (ii) requires minimal inventory data, (iii) iseasily scalable, and (iv) does not require significant computing power. Use ofthis approach before the hazard event can also provide a community with themeans to plan and allocate resources in advance of an event to achieve thedesirable resiliency goals of the community."
"326","arXiv:1906.12320","https://arxiv.org/abs/1906.12320","PointFlow: 3D Point Cloud Generation with Continuous Normalizing Flows","Guandao Yang, Xun Huang, Zekun Hao, Ming-Yu Liu, Serge Belongie, Bharath Hariharan","As 3D point clouds become the representation of choice for multiple visionand graphics applications, the ability to synthesize or reconstructhigh-resolution, high-fidelity point clouds becomes crucial. Despite the recentsuccess of deep learning models in discriminative tasks of point clouds,generating point clouds remains challenging. This paper proposes a principledprobabilistic framework to generate 3D point clouds by modeling them as adistribution of distributions. Specifically, we learn a two-level hierarchy ofdistributions where the first level is the distribution of shapes and thesecond level is the distribution of points given a shape. This formulationallows us to both sample shapes and sample an arbitrary number of points from ashape. Our generative model, named PointFlow, learns each level of thedistribution with a continuous normalizing flow. The invertibility ofnormalizing flows enables the computation of the likelihood during training andallows us to train our model in the variational inference framework.Empirically, we demonstrate that PointFlow achieves state-of-the-artperformance in point cloud generation. We additionally show that our model canfaithfully reconstruct point clouds and learn useful representations in anunsupervised manner. Codes will be available athttps://github.com/stevenygd/PointFlow."
"327","arXiv:1906.12321","https://arxiv.org/abs/1906.12321","The Online Resources Shared on Twitter About the #MeToo Movement: The  Pareto Principle","Iman Tahamtan, Javad Seif","In this paper we examine the information sharing behavior of Twitter usersregarding the MeToo hashtag (#MeToo), and whether the Pareto principle appliesto domain names and URLs used in the tweets containing this hashtag. RStudioand Python were used to retrieve and analyze the data. Results demonstratedthat the most frequent domain name was twitter.com (47.20%), followed bynytimes.com (4.42%) and youtube.com (3.69%). The most frequently shared contentwas a recent poll which indicated ""men are afraid to mentor women after the#MeToo movement"". Domain names exhibited the Pareto Principle: 8% of domainnames accounted for 80% of the shared content on Twitter that contained #MeToo.The Pareto Principle did not hold when considering the URLs. This studyprovides a better understanding of what online resources people rely on toshare information about the #MeToo movement."
"328","arXiv:1906.12322","https://arxiv.org/abs/1906.12322","Breadcrumbs: A Feature Rich Mobility Dataset with Point of Interest  Annotation","Arielle Moro, Vaibhav Kulkarni, Pierre-Adrien Ghiringhelli, Bertil Chapuis, Benoit Garbinato","In this paper, we present Breadcrumbs, a mobility dataset collected in thecity of Lausanne (Switzerland) from multiple mobile phone sensors (GPS, WiFi,Bluetooth) from 81 users for a duration of 12 weeks. Currently availablemobility datasets are restricted to geospatial information obtained through asingle sensor at low spatiotemporal granularities. Furthermore, this passivelycollected data lacks ground-truth information regarding points of interest andtheir semantic labels. These features are critical in order to push thepossibilities of geospatial data analysis towards analyzing mobility behaviorsand movement patterns at a fine-grained scale. To this end, Breadcrumbsprovides ground-truth and semantic labels for the points of interest of all theparticipants. The dataset also contains fine-grained demographic attributes,contact records, calendar events and social relationship tags between theparticipants. In order to demonstrate the significance of the ground-truthannotations, we discuss several use cases of this dataset. Furthermore, wecompare four contrasting and widely used unsupervised clustering approaches forpoint of interest extraction from geolocation trajectories. Using theground-truth information, we perform a detailed performance validation of thesetechniques and highlight their strengths and weaknesses. Given that mobilitydata is derived from an individuals inherent need of participating inactivities, narrowing the gap between raw trajectory data points and completetrip annotation in essential. We thus make Breadcrumbs accessible to theresearch community in order to facilitate research in the direction ofsupervised human mobility learning schemes."
"329","arXiv:1906.12323","https://arxiv.org/abs/1906.12323","Modeling of User Portrait Through Social Media","Haiqian Gu, Jie Wang, Ziwen Wang, Bojin Zhuang, Fei Su","Nowadays, massive useful data of user information and social behavior havebeen accumulated on the Internet, providing a possibility of profiling user'spersonality traits online. In this paper, we propose a psychological modelingmethod based on computational linguistic features to profile Big Fivepersonality traits of users on Sina Weibo (a Twitter-like microblogging servicein China) and their correlations with user's social behaviors. To the best ofour knowledge, this is the first research on investigating the potentialrelationship between profile information, social-network behaviors andpersonality traits of users on Sina Weibo. Our results demonstrate an effectivemodeling approach to understanding demographic and psychological portraits ofusers on social media without customer disruption, which is useful forcommercial incorporations to provide better personalized products and services."
"330","arXiv:1906.12324","https://arxiv.org/abs/1906.12324","Cross-Platform Modeling of Users' Behavior on Social Media","Haiqian Gu, Jie Wang, Ziwen Wang, Bojin Zhuang, Wenhao Bian, Fei Su","With the booming development and popularity of mobile applications, differentverticals accumulate abundant data of user information and social behavior,which are spontaneous, genuine and diversified. However, each platformdescribes user's portraits in only certain aspect, resulting in difficultcombination of those internet footprints together. In our research, we proposeda modeling approach to analyze user's online behavior across different socialmedia platforms. Structured and unstructured data of same users shared byNetEase Music and Sina Weibo have been collected for cross-platform analysis ofcorrelations between music preference and other users' characteristics. Basedon music tags of genre and mood, genre cluster of five groups and mood clusterof four groups have been formed by computing their collected song lists withK-means method. Moreover, with the help of user data of Weibo, correlationsbetween music preference (i.e. genre, mood) and Big Five personalities (BFPs)and basic information (e.g. gender, resident region, tags) have beencomprehensively studied, building up full-scale user portraits with finergrain. Our findings indicate that people's music preference could be linkedwith their real social activities. For instance, people living in mountainousareas generally prefer folk music, while those in urban areas like pop musicmore. Interestingly, dog lovers could love sad music more than cat lovers.Moreover, our proposed cross-platform modeling approach could be adapted toother verticals, providing an online automatic way for profiling users in amore precise and comprehensive way."
"331","arXiv:1906.12326","https://arxiv.org/abs/1906.12326","Can Marton Coding Alone Ensure Individual Secrecy?","Jin Yeong Tan, Lawrence Ong, Behzad Asadi","For communications in the presence of eavesdroppers, random components areoften used in code design to camouflage information from eavesdroppers. Inbroadcast channels without eavesdroppers, Marton coding comprises randomcomponents which allow correlation between auxiliary random variablesrepresenting independent messages. In this paper, we study if Marton codingalone can ensure individual secrecy in the two-receiver discrete memorylessbroadcast channel with a passive eavesdropper. Our results show that this ispossible and Marton coding guarantees individual secrecy in accordance to theprinciple of Wyner secrecy coding. However, this comes with a penalty ofrequiring stricter channel conditions."
"332","arXiv:1906.12328","https://arxiv.org/abs/1906.12328","Anomaly Detection with Joint Representation Learning of Content and  Connection","Junhao Wang, Renhao Wang, Aayushi Kulshrestha, Reihaneh Rabbany","Social media sites are becoming a key factor in politics. These platforms areeasy to manipulate for the purpose of distorting information space to confuseand distract voters. Past works to identify disruptive patterns are mostlyfocused on analyzing the content of tweets. In this study, we jointly embed theinformation from both user posted content as well as a user's follower network,to detect groups of densely connected users in an unsupervised fashion. We theninvestigate these dense sub-blocks of users to flag anomalous behavior. In ourexperiments, we study the tweets related to the upcoming 2019 CanadianElections, and observe a set of densely-connected users engaging in localpolitics in different provinces, and exhibiting troll-like behavior."
"333","arXiv:1906.12330","https://arxiv.org/abs/1906.12330","Graph Star Net for Generalized Multi-Task Learning","Lu Haonan, Seth H. Huang, Tian Ye, Guo Xiuyan","In this work, we present graph star net (GraphStar), a novel and unifiedgraph neural net architecture which utilizes message-passing relay andattention mechanism for multiple prediction tasks - node classification, graphclassification and link prediction. GraphStar addresses many earlier challengesfacing graph neural nets and achieves non-local representation withoutincreasing the model depth or bearing heavy computational costs. We alsopropose a new method to tackle topic-specific sentiment analysis based on nodeclassification and text classification as graph classification. Our work showsthat 'star nodes' can learn effective graph-data representation and improve oncurrent methods for the three tasks. Specifically, for graph classification andlink prediction, GraphStar outperforms the current state-of-the-art models by2-5% on several key benchmarks."
"334","arXiv:1906.12331","https://arxiv.org/abs/1906.12331","Modeling Food Popularity Dependencies using Social Media data","Devashish Khulbe, Manu Pathak","The rise in popularity of major social media platforms have enabled people toshare photos and textual information about their daily life. One of the populartopics about which information is shared is food. Since a lot of media aboutfood are attributed to particular locations and restaurants, information likepopularity of spatio-temporal popularity of various cuisines can be analysed.Tracking the popularity of food types and retail locations across space andtime can also be useful for business owners and restaurant investors. In thiswork, we present an approach using off-the shelf machine learning techniques toidentify trends and popularity of cuisine types in an area using geo-taggeddata from social media, Google images and Yelp. After adjusting for time, weuse the Kernel Density Estimation to get hot spots across the location andmodel the dependencies among food cuisines popularity using Bayesian Networks.We consider the Manhattan borough of New York City as the location for ouranalyses but the approach can be used for any area with social media data andinformation about retail businesses."
"335","arXiv:1906.12332","https://arxiv.org/abs/1906.12332","Automatic Discovery of Families of Network Generative Processes","Telmo Menezes (CMB), Camille Roth (CMB)","Designing plausible network models typically requires scholars to form apriori intuitions on the key drivers of network formation. Oftentimes, theseintuitions are supported by the statistical estimation of a selection ofnetwork evolution processes which will form the basis of the model to bedeveloped. Machine learning techniques have lately been introduced to assistthe automatic discovery of generative models. These approaches may more broadlybe described as ""symbolic regression"", where fundamental network dynamicfunctions, rather than just parameters, are evolved through geneticprogramming. This chapter first aims at reviewing the principles, efforts andthe emerging literature in this direction, which is very much aligned with theidea of creating artificial scientists. Our contribution then aims morespecifically at building upon an approach recently developed by us [Menezes \&Roth, 2014] in order to demonstrate the existence of families of networks thatmay be described by similar generative processes. In other words, symbolicregression may be used to group networks according to their inferred genotype(in terms of generative processes) rather than their observed phenotype (interms of statistical/topological features). Our empirical case is based on anoriginal data set of 238 anonymized ego-centered networks of Facebook friends,further yielding insights on the formation of sociability networks."
"336","arXiv:1906.12337","https://arxiv.org/abs/1906.12337","Deep Sketch-Based Modeling of Man-Made Shapes","Dmitriy Smirnov, Mikhail Bessmeltsev, Justin Solomon","Sketch-based modeling aims to model 3D geometry using a concise and easy tocreate---but extremely ambiguous---input: artist sketches. Most conventionalsketch-based modeling systems target smooth shapes and, to counter theambiguity, put manually-designed priors on the 3D shape; they also typicallyrequire clean, vectorized input. Recent approaches attempt to learn thosepriors from data but often produce low-quality output. Focusing onpiecewise-smooth man-made shapes, we address these issues by presenting a deeplearning-based system to infer a complete man-made 3D shape from a singlebitmap sketch. Given a sketch, our system infers a set of parametric surfacesthat realize the drawing in 3D. To capture the piecewise smooth geometry ofman-made shapes, we learn a special shape representation---a deformableparametric template composed of Coons patches. Naively training such a system,however, would suffer from lack of data and from self-intersections of theparametric surfaces. To address this, we introduce a synthetic sketchaugmentation pipeline as well as a loss function that biases the network tooutput non-self-intersecting shapes. We demonstrate the efficacy of our systemon a gallery of synthetic and real artist sketches as well as via comparison torelated work."
"337","arXiv:1906.12338","https://arxiv.org/abs/1906.12338","High Speed Cognitive Domain Ontologies for Asset Allocation Using Loihi  Spiking Neurons","Chris Yakopcic, Nayim Rahman, Tanvir Atahary, Tarek M. Taha, Alex Beigh, Scott Douglass","Cognitive agents are typically utilized in autonomous systems for automateddecision making. These systems interact at real time with their environment andare generally heavily power constrained. Thus, there is a strong need for areal time agent running on a low power platform. The agent examined is theCognitively Enhanced Complex Event Processing (CECEP) architecture. This is anautonomous decision support tool that reasons like humans and enables enhancedagent-based decision-making. It has applications in a large variety of domainsincluding autonomous systems, operations research, intelligence analysis, anddata mining. One of the key components of CECEP is the mining of knowledge froma repository described as a Cognitive Domain Ontology (CDO). One problem thatis often tasked to CDOs is asset allocation. Given the number of possiblesolutions in this allocation problem, determining the optimal solution via CDOcan be very time consuming. In this work we show that a grid of isolatedspiking neurons is capable of generating solutions to this problem veryquickly, although some degree of approximation is required to achieve thespeedup. However, the approximate spiking approach presented in this work wasable to complete all allocation simulations with greater than 99.9% accuracy.To show the feasibility of low power implementation, this algorithm wasexecuted using the Intel Loihi manycore neuromorphic processor. Given the vastincrease in speed (greater than 1000 times in larger allocation problems), aswell as the reduction in computational requirements, the presented algorithm isideal for moving asset allocation to low power, portable, embedded hardware."
"338","arXiv:1906.12340","https://arxiv.org/abs/1906.12340","Using Self-Supervised Learning Can Improve Model Robustness and  Uncertainty","Dan Hendrycks, Mantas Mazeika, Saurav Kadavath, Dawn Song","Self-supervision provides effective representations for downstream taskswithout requiring labels. However, existing approaches lag behind fullysupervised training and are often not thought beneficial beyond obviating theneed for annotations. We find that self-supervision can benefit robustness in avariety of ways, including robustness to adversarial examples, labelcorruption, and common input corruptions. Additionally, self-supervisiongreatly benefits out-of-distribution detection on difficult, near-distributionoutliers, so much so that it exceeds the performance of fully supervisedmethods. These results demonstrate the promise of self-supervision forimproving robustness and uncertainty estimation and establish these tasks asnew axes of evaluation for future self-supervised learning research."
"339","arXiv:1906.12348","https://arxiv.org/abs/1906.12348","MLFriend: Interactive Prediction Task Recommendation for Event-Driven  Time-Series Data","Lei Xu, Shubhra Kanti Karmaker Santu, Kalyan Veeramachaneni","Most automation in machine learning focuses on model selection and hyperparameter tuning, and many overlook the challenge of automatically definingpredictive tasks. We still heavily rely on human experts to define predictiontasks, and generate labels by aggregating raw data. In this paper, we tacklethe challenge of defining useful prediction problems on event-driventime-series data. We introduce MLFriend to address this challenge. MLFriendfirst generates all possible prediction tasks under a predefined space, theninteracts with a data scientist to learn the context of the data and recommendgood prediction tasks from all the tasks in the space. We evaluate our systemon three different datasets and generate a total of 2885 prediction tasks andsolve them. Out of these 722 were deemed useful by expert data scientists. Wealso show that an automatic prediction task discovery system is able toidentify top 10 tasks that a user may like within a batch of 100 tasks."
"340","arXiv:1906.12350","https://arxiv.org/abs/1906.12350","Split Q Learning: Reinforcement Learning with Two-Stream Rewards","Baihan Lin, Djallel Bouneffouf, Guillermo Cecchi","Drawing an inspiration from behavioral studies of human decision making, wepropose here a general parametric framework for a reinforcement learningproblem, which extends the standard Q-learning approach to incorporate atwo-stream framework of reward processing with biases biologically associatedwith several neurological and psychiatric conditions, including Parkinson's andAlzheimer's diseases, attention-deficit/hyperactivity disorder (ADHD),addiction, and chronic pain. For AI community, the development of agents thatreact differently to different types of rewards can enable us to understand awide spectrum of multi-agent interactions in complex real-world socioeconomicsystems. Moreover, from the behavioral modeling perspective, our parametricframework can be viewed as a first step towards a unifying computational modelcapturing reward processing abnormalities across multiple mental conditions anduser preferences in long-term recommendation systems."
"341","arXiv:1907.00945","https://arxiv.org/abs/1907.00945","ICDAR2019 Robust Reading Challenge on Multi-lingual Scene Text Detection  and Recognition -- RRC-MLT-2019","Nibal Nayef, Yash Patel, Michal Busta, Pinaki Nath Chowdhury, Dimosthenis Karatzas, Wafa Khlif, Jiri Matas, Umapada Pal, Jean-Christophe Burie, Cheng-lin Liu, Jean-Marc Ogier","With the growing cosmopolitan culture of modern cities, the need of robustMulti-Lingual scene Text (MLT) detection and recognition systems has never beenmore immense. With the goal to systematically benchmark and push thestate-of-the-art forward, the proposed competition builds on top of theRRC-MLT-2017 with an additional end-to-end task, an additional language in thereal images dataset, a large scale multi-lingual synthetic dataset to assistthe training, and a baseline End-to-End recognition method. The real datasetconsists of 20,000 images containing text from 10 languages. The challenge has4 tasks covering various aspects of multi-lingual scene text: (a) textdetection, (b) cropped word script classification, (c) joint text detection andscript classification and (d) end-to-end detection and recognition. In total,the competition received 60 submissions from the research and industrialcommunities. This paper presents the dataset, the tasks and the findings of thepresented RRC-MLT-2019 challenge."
"342","arXiv:1907.00962","https://arxiv.org/abs/1907.00962","Claim Extraction in Biomedical Publications using Deep Discourse Model  and Transfer Learning","Titipat Achakulvisut, Chandra Bhagavatula, Daniel Acuna, Konrad Kording","Claims are a fundamental unit of scientific discourse. The exponential growthin the number of scientific publications makes automatic claim extraction animportant problem for researchers who are overwhelmed by this informationoverload. Such an automated claim extraction system is useful for both manualand programmatic exploration of scientific knowledge. In this paper, weintroduce an online claim extraction system and a dataset of 1,500 scientificabstracts from the biomedical domain with expert annotations for each sentenceindicating whether the sentence presents a scientific claim. We compare ourproposed model with several baseline models including rule-based and deeplearning techniques. Our transfer learning approach with a fine-tuning stepallows us to bootstrap from a large discourse-annotated dataset (Pubmed-RCT)and obtains F1-score over 0.78 for claim detection while using a smallannotated dataset of 750 papers. We show that using this pre-trained modelbased on the discourse prediction task improves F1-score by over 14 percentabsolute points compared to a baseline model without discourse structure. Werelease a publicly accessible tool for discourse model, claim detection model,along with an annotation tool. We discuss further applications beyondBiomedical literature."
"343","arXiv:1907.00961","https://arxiv.org/abs/1907.00961","On the development of symmetry-preserving finite element schemes for  ordinary differential equations","Alex Bihlo, James Jackaman, Francis Valiquette","In this paper we introduce a procedure, based on the method of equivariantmoving frames, for formulating continuous Galerkin finite element schemes thatpreserve the Lie point symmetries of initial value ordinary differentialequations. Our methodology applies to projectable and non-projectable actionsfor ordinary differential equations of arbitrary order, and interpolatingfunctions of arbitrary degree. Several examples are included to illustratevarious features of the symmetry-preserving process. We summarise extensivenumerical experiments showing that symmetry-preserving finite element schemesmay provide better long term accuracy than their non-invariant counterparts andcan be implemented on larger elements."
"344","arXiv:1907.00960","https://arxiv.org/abs/1907.00960","Going Deeper with Point Networks","Eric-Tuan Le, Iasonas Kokkinos, Niloy J. Mitra","In this work, we introduce three generic point cloud processing blocks thatimprove both accuracy and memory consumption of state-of-the-art networks thusallowing to design deeper and more accurate networks. The novel processingblocks are: a multi-resolution point cloud processing block; a convolution-typeoperation for point sets that blends neighborhood information in amemory-efficient manner; and a crosslink block that efficiently sharesinformation across low- and high-resolution processing branches. Combiningthese blocks allows us to design significantly wider and deeper architectures.We extensively evaluate the proposed architectures on multiple pointsegmentation benchmarks (ShapeNet-Part, ScanNet, PartNet) and report systematicimprovements in terms of both accuracy and memory consumption by using ourgeneric modules in conjunction with multiple recent architectures (PointNet++,DGCNN, SpiderCNN, PointCNN). We report a 3.4% increase in IoU on the -mostcomplex- PartNet dataset while decreasing memory footprint by 57%."
"345","arXiv:1907.00959","https://arxiv.org/abs/1907.00959","Single-Path Mobile AutoML: Efficient ConvNet Design and NAS  Hyperparameter Optimization","Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos, Bodhi Priyantha, Jie Liu, Diana Marculescu","Can we reduce the search cost of Neural Architecture Search (NAS) from daysdown to only few hours? NAS methods automate the design of ConvolutionalNetworks (ConvNets) under hardware constraints and they have emerged as keycomponents of AutoML frameworks. However, the NAS problem remains challengingdue to the combinatorially large design space and the significant search time(at least 200 GPU-hours). In this work, we alleviate the NAS search cost downto less than 3 hours, while achieving state-of-the-art image classificationresults under mobile latency constraints. We propose a novel differentiable NASformulation, namely Single-Path NAS, that uses one single-pathover-parameterized ConvNet to encode all architectural decisions based onshared convolutional kernel parameters, hence drastically decreasing the searchoverhead. Single-Path NAS achieves state-of-the-art top-1 ImageNet accuracy(75.62%), hence outperforming existing mobile NAS methods in similar latencysettings (~80ms). In particular, we enhance the accuracy-runtime trade-off indifferentiable NAS by treating the Squeeze-and-Excitation path as a fullysearchable operation with our novel single-path encoding. Our method has anoverall cost of only 8 epochs (24 TPU-hours), which is up to 5,000x fastercompared to prior work. Moreover, we study how different NAS formulationchoices affect the performance of the designed ConvNets. Furthermore, weexploit the efficiency of our method to answer an interesting question: insteadof empirically tuning the hyperparameters of the NAS solver (as in prior work),can we automatically find the hyperparameter values that yield the desiredaccuracy-runtime trade-off? We open-source our entire codebase at:https://github.com/dstamoulis/single-path-nas."
"346","arXiv:1907.00956","https://arxiv.org/abs/1907.00956","Fast and Reliable Dispersal of Crash-Prone Agents on Graphs","Michael Amir, Alfred M. Bruckstein","We study the ability of mobile agents performing simple local computations tocompletely cover an unknown graph environment while implicitly constructing adistributed spanning tree. Whenever an agent moves, it may crash and disappearfrom the environment. The agents activate autonomously at exponential waitingtimes of mean $1$ and enter the graph over time at a source vertex $s$. Theyare able to settle at vertices of the graph and mark a neighbour. The agentsare identical and make decisions driven by the same local rule of behaviour.The local rule is only based on the presence of neighbouring agents, andwhether a neighbour marks the agent's current location.An implicit spanning tree is gradually constructed by having certain agentssettle and act as its vertices, marking their parent. Each vertex in theenvironment has limited physical space and may contain at most a settled and anunsettled agent. Our goal is to show that even under conditions ofasynchronicity, frequent crashing, and limited physical space, the simplemobile agents successfully cover the environment and construct a distributedspanning tree in linear time. Specifically, we show that, assuming at most$ct/4$ crashes happen before time $t$ for all times $t$, the agents cancomplete the tree asymptotically almost surely in $8\big((1-c)^{-1}+o(1)\big)n$time where $n$ is the number of vertices. The analysis relates our algorithm tothe ``totally asymmetric simple exclusion process'' in statistical mechanics."
"347","arXiv:1907.00953","https://arxiv.org/abs/1907.00953","Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a  Latent Variable Model","Alex X. Lee, Anusha Nagabandi, Pieter Abbeel, Sergey Levine","Deep reinforcement learning (RL) algorithms can use high-capacity deepnetworks to learn directly from image observations. However, these kinds ofobservation spaces present a number of challenges in practice, since the policymust now solve two problems: a representation learning problem, and a tasklearning problem. In this paper, we aim to explicitly learn representationsthat can accelerate reinforcement learning from images. We propose thestochastic latent actor-critic (SLAC) algorithm: a sample-efficient andhigh-performing RL algorithm for learning policies for complex continuouscontrol tasks directly from high-dimensional image inputs. SLAC learns acompact latent representation space using a stochastic sequential latentvariable model, and then learns a critic model within this latent space. Bylearning a critic within a compact state space, SLAC can learn much moreefficiently than standard RL methods. The proposed model improves performancesubstantially over alternative representations as well, such as variationalautoencoders. In fact, our experimental evaluation demonstrates that the sampleefficiency of our resulting method is comparable to that of model-based RLmethods that directly use a similar type of model for control. Furthermore, ourmethod outperforms both model-free and model-based alternatives in terms offinal performance and sample efficiency, on a range of difficult image-basedcontrol tasks."
"348","arXiv:1907.00909","https://arxiv.org/abs/1907.00909","An Open Source AutoML Benchmark","Pieter Gijsbers, Erin LeDell, Janek Thomas, Sébastien Poirier, Bernd Bischl, Joaquin Vanschoren","In recent years, an active field of research has developed around automatedmachine learning (AutoML). Unfortunately, comparing different AutoML systems ishard and often done incorrectly. We introduce an open, ongoing, and extensiblebenchmark framework which follows best practices and avoids common mistakes.The framework is open-source, uses public datasets and has a website withup-to-date results. We use the framework to conduct a thorough comparison of 4AutoML systems across 39 datasets and analyze the results."
"349","arXiv:1907.00943","https://arxiv.org/abs/1907.00943","Estimating brain age based on a healthy population with deep learning  and structural MRI","Xinyang Feng, Zachary C. Lipton, Jie Yang, Scott A. Small, Frank A. Provenzano","Numerous studies have established that estimated brain age, as derived fromstatistical models trained on healthy populations, constitutes a valuablebiomarker that is predictive of cognitive decline and various neurologicaldiseases. In this work, we curate a large-scale heterogeneous dataset (N =10,158, age range 18 - 97) of structural brain MRIs in a healthy populationfrom multiple publicly-available sources, upon which we train a deep learningmodel for brain age estimation. The availability of the large-scale datasetenables a more uniform age distribution across adult life-span for effectiveage estimation with no bias toward certain age groups. We demonstrate that theage estimation accuracy, evaluated with mean absolute error (MAE) andcorrelation coefficient (r), outperforms previously reported methods in both ahold-out test set reflective of the custom population (MAE = 4.06 years, r =0.970) and an independent life-span evaluation dataset (MAE = 4.21 years, r =0.960) on which a previous study has evaluated. We further demonstrate theutility of the estimated age in life-span aging analysis of cognitivefunctions. Furthermore, we conduct extensive ablation tests and employfeature-attribution techniques to analyze which regions contribute the mostpredictive value, demonstrating the prominence of the frontal lobe as well aspattern shift across life-span. In summary, we achieve superior age estimationperformance confirming the efficacy of deep learning and the added utility oftraining with data both in larger number and more uniformly distributed than inprevious studies. We demonstrate the regional contribution to our brain agepredictions through multiple routes and confirm the association of divergencebetween estimated and chronological brain age with neuropsychological measures."
"350","arXiv:1907.00939","https://arxiv.org/abs/1907.00939","Pano Popups: Indoor 3D Reconstruction with a Plane-Aware Network","Marc Eder, Pierre Moulon, Li Guan","In this work we present a method to train a plane-aware convolutional neuralnetwork for dense depth and surface normal estimation as well as planeboundaries from a single indoor \threesixty image. Using our proposed lossfunction, our network outperforms existing methods for single-view, indoor,omnidirectional depth estimation and provides an initial benchmark for surfacenormal prediction from \threesixty images. Our improvements are due to the useof a novel plane-aware loss that leverages principal curvature as an indicatorof planar boundaries. We also show that including geodesic coordinate maps asnetwork priors provides a significant boost in surface normal predictionaccuracy. Finally, we demonstrate how we can combine our network's outputs togenerate high quality 3D ``pop-up"" models of indoor scenes."
"351","arXiv:1907.00937","https://arxiv.org/abs/1907.00937","Semantic Product Search","Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian (Allen)Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, Bing Yin","We study the problem of semantic matching in product search, that is, given acustomer query, retrieve all semantically related products from the catalog.Pure lexical matching via an inverted index falls short in this respect due toseveral factors: a) lack of understanding of hypernyms, synonyms, and antonyms,b) fragility to morphological variants (e.g. ""woman"" vs. ""women""), and c)sensitivity to spelling errors. To address these issues, we train a deeplearning model for semantic matching using customer behavior data. Much of therecent work on large-scale semantic search using deep learning focuses onranking for web search. In contrast, semantic matching for product searchpresents several novel challenges, which we elucidate in this paper. We addressthese challenges by a) developing a new loss function that has an inbuiltthreshold to differentiate between random negative examples, impressed but notpurchased examples, and positive examples (purchased items), b) using averagepooling in conjunction with n-grams to capture short-range linguistic patterns,c) using hashing to handle out of vocabulary tokens, and d) using a modelparallel training architecture to scale across 8 GPUs. We present compellingoffline results that demonstrate at least 4.7% improvement in Recall@100 and14.5% improvement in mean average precision (MAP) over baselinestate-of-the-art semantic search methods using the same tokenization method.Moreover, we present results and discuss learnings from online A/B tests whichdemonstrate the efficacy of our method."
"352","arXiv:1907.00935","https://arxiv.org/abs/1907.00935","One-Time Programs made Practical","Lianying Zhao, Joseph I. Choi, Didem Demirag, Kevin R. B. Butler, Mohammad Mannan, Erman Ayday, Jeremy Clark","A one-time program (OTP) works as follows: Alice provides Bob with theimplementation of some function. Bob can have the function evaluatedexclusively on a single input of his choosing. Once executed, the program willfail to evaluate on any other input. State-of-the-art one-time programs haveremained theoretical, requiring custom hardware that iscost-ineffective/unavailable, or confined to adhoc/unrealistic assumptions. Tobridge this gap, we explore how the Trusted Execution Environment (TEE) ofmodern CPUs can realize the OTP functionality. Specifically, we build twoflavours of such a system: in the first, the TEE directly enforces theone-timeness of the program; in the second, the program is represented with agarbled circuit and the TEE ensures Bob's input can only be wired into thecircuit once, equivalent to a smaller cryptographic primitive called one-timememory. These have different performance profiles: the first is best whenAlice's input is small and Bob's is large, and the second for the converse."
"353","arXiv:1907.00934","https://arxiv.org/abs/1907.00934","Ich weiß, was du nächsten Sommer getan haben wirst: Predictive  Policing in Österreich","Angelika Adensamer, Lukas Daniel Klausner","Predictive policing is a data-based, predictive analytical technique used inlaw enforcement. In this paper, we give an overview of the current situation inAustria and discuss technical, sociopolitical and legal questions raised by theuse of PP, such as the lack of awareness of discriminatory structures insociety, the biases in data underlying PP and the lack of reflexion on thebasic premises and feedback mechanisms of PP. Violations of fundamental rightswithout cause are not allowed by the Austrian Code of Criminal Procedure(Strafproze{\ss}ordnung, StPO), the Security Police Act(Sicherheitspolizeigesetz, SPG) or the Act concerning Police Protection of theState (Polizeiliches Staatsschutzgesetz, PStSG); the principle of allowingpolice intervention only on the basis of concrete threats or suspicion mustremain absolute. Considering the numerous problems (not least the from thepoint of view of legal policy), we conclude that the use of PP should beeschewed and that resources and planning should instead be focussed on solvingthe social problems which actually cause crime."
"354","arXiv:1907.00932","https://arxiv.org/abs/1907.00932","A Framework For Identifying Group Behavior Of Wild Animals","Guido Muscioni, Riccardo Pressiani, Matteo Foglio, Margaret C. Crofoot, Marco D. Santambrogio, Tanya Berger-Wolf","Activity recognition and, more generally, behavior inference tasks aregaining a lot of interest. Much of it is work in the context of human behavior.New available tracking technologies for wild animals are generating datasetsthat indirectly may provide information about animal behavior. In this work, wepropose a method for classifying these data into behavioral annotation,particularly collective behavior of a social group. Our method is based onsequence analysis with a direct encoding of the interactions of a group of wildanimals. We evaluate our approach on a real world dataset, showing significantaccuracy improvements over baseline methods."
"355","arXiv:1907.00930","https://arxiv.org/abs/1907.00930","A Joint Optimization Approach of LiDAR-Camera Fusion for Accurate Dense  3D Reconstructions","Weikun Zhen, Yaoyu Hu, Jingfeng Liu, Sebastian Scherer","Fusing data from LiDAR and camera is conceptually attractive because of theircomplementary properties. For instance, camera images are higher resolution andhave colors, while LiDAR data provide more accurate range measurements and havea wider Field Of View (FOV). However, the sensor fusion problem remainschallenging since it is difficult to find reliable correlations between data ofvery different characteristics (geometry vs. texture, sparse vs. dense). Thispaper proposes an offline LiDAR-camera fusion method to build dense, accurate3D models. Specifically, our method jointly solves a bundle adjustment (BA)problem and a cloud registration problem to compute camera poses and the sensorextrinsic calibration. In experiments, we show that our method can achieve anaveraged accuracy of 2.7mm and resolution of 70 points per square cm bycomparing to the ground truth data from a survey scanner. Furthermore, theextrinsic calibration result is discussed and shown to outperform thestate-of-the-art method."
"356","arXiv:1907.00929","https://arxiv.org/abs/1907.00929","Computing a Smaller Unit-Distance Graph with Chromatic Number 5 via  Proof Trimming","Marijn J.H. Heule","We present a method to gradually compute a smaller and smaller unsatisfiablecore of a propositional formula by minimizing proofs of unsatisfiability. Thegoal is to compute a minimal unsatisfiable core that is relatively smallcompared to other minimal unsatisfiable cores of the same formula. We try toachieve this goal by postponing deletion of arbitrary clauses from the formulaas long as possible---in contrast to existing minimal unsatisfiable corealgorithms. We applied this method to reduce the smallest known unit-distancegraph with chromatic number 5 from 553 vertices and 2720 edges to 529 verticesand 2670 edges."
"357","arXiv:1907.00928","https://arxiv.org/abs/1907.00928","Trading Off Computation with Transmission in Status Update Systems","Peng Zou, Omur Ozel, Suresh Subramaniam","This paper is motivated by emerging edge computing applications in whichgenerated data are pre-processed at the source and then transmitted to an edgeserver. In such a scenario, there is typically a tradeoff between the amount ofpre-processing and the amount of data to be transmitted. We model such a systemby considering two non-preemptive queues in tandem whose service times areindependent over time but the transmission service time is dependent on thecomputation service time in mean value. The first queue is in M/GI/1/1 formwith a single server, memoryless exponential arrivals, general independentservice and no extra buffer to save incoming status update packets. The secondqueue is in GI/M/1/2* form with a single server receiving packets from thefirst queue, memoryless service and a single data buffer to save incomingpackets. Additionally, mean service times of the first and second queues aredependent through a deterministic monotonic function. We perform stationarydistribution analysis in this system and obtain closed form expressions foraverage age of information (AoI) and average peak AoI. Our numerical resultsillustrate the analytical findings and highlight the tradeoff between averageAoI and average peak AoI generated by the tandem nature of the queueing systemwith dependent service times."
"358","arXiv:1907.00924","https://arxiv.org/abs/1907.00924","Mise en abyme with artificial intelligence: how to predict the accuracy  of NN, applied to hyper-parameter tuning","Giorgia Franchini, Mathilde Galinier, Micaela Verucchi","In the context of deep learning, the costliest phase from a computationalpoint of view is the full training of the learning algorithm. However, thisprocess is to be used a significant number of times during the design of a newartificial neural network, leading therefore to extremely expensive operations.Here, we propose a low-cost strategy to predict the accuracy of the algorithm,based only on its initial behaviour. To do so, we train the network of interestup to convergence several times, modifying its characteristics at eachtraining. The initial and final accuracies observed during this beforehandprocess are stored in a database. We then make use of both curve fitting andSupport Vector Machines techniques, the latter being trained on the createddatabase, to predict the accuracy of the network, given its accuracy on theprimary iterations of its learning. This approach can be of particular interestwhen the space of the characteristics of the network is notably large or whenits full training is highly time-consuming. The results we obtained arepromising and encouraged us to apply this strategy to a topical issue:hyper-parameter optimisation (HO). In particular, we focused on the HO of aconvolutional neural network for the classification of the databases MNIST andCIFAR-10. By using our method of prediction, and an algorithm implemented by usfor a probabilistic exploration of the hyper-parameter space, we were able tofind the hyper-parameter settings corresponding to the optimal accuraciesalready known in literature, at a quite low-cost."
"359","arXiv:1907.00921","https://arxiv.org/abs/1907.00921","Active Learning within Constrained Environments through Imitation of an  Expert Questioner","Kalesha Bullard, Yannick Schroecker, Sonia Chernova","Active learning agents typically employ a query selection algorithm whichsolely considers the agent's learning objectives. However, this may beinsufficient in more realistic human domains. This work uses imitation learningto enable an agent in a constrained environment to concurrently reason aboutboth its internal learning goals and environmental constraints externallyimposed, all within its objective function. Experiments are conducted on aconcept learning task to test generalization of the proposed algorithm todifferent environmental conditions and analyze how time and resourceconstraints impact efficacy of solving the learning problem. Our findings showthe environmentally-aware learning agent is able to statistically outperformall other active learners explored under most of the constrained conditions. Akey implication is adaptation for active learning agents to more realistichuman environments, where constraints are often externally imposed on thelearner."
"360","arXiv:1907.00913","https://arxiv.org/abs/1907.00913","Nonlinearization of two-parameter eigenvalue problems","Emil Ringh, Elias Jarlebring","We investigate a technique to transform a linear two-parameter eigenvalueproblem, into a nonlinear eigenvalue problem (NEP). The transformation stemsfrom an elimination of one of the equations in the two-parameter eigenvalueproblem, by considering it as a (standard) generalized eigenvalue problem. Wecharacterize the equivalence between the original and the nonlinearized problemtheoretically and show how to use the transformation computationally. Specialcases of the transformation can be interpreted as a reversed companionlinearization for polynomial eigenvalue problems, as well as a reversed (lessknown) linearization technique for certain algebraic eigenvalue problems withsquare-root terms. Moreover, by exploiting the structure of the NEP we presentalgorithm specializations for NEP methods, although the technique also allowsgeneral solution methods for NEPs to be directly applied to the problem. Thenonlinearization is illustrated in examples and simulations, with focus onproblems where the eliminated equation is of much smaller dimensions than theother two-parameter eigenvalue equation, in particular applications in domaindecomposition. A general analysis is also carried out under the assumption thata backward stable eigenvalue solver method is used to solve the eliminatedproblem, leading to the conclusion that the error is benign."
"361","arXiv:1907.00903","https://arxiv.org/abs/1907.00903","Resolving the Multiple Withdrawal Attack on ERC20 Tokens","Reza Rahimian, Shayan Eskandari, Jeremy Clark","Custom tokens are an integral component of decentralized applications (dapps)deployed on Ethereum and other blockchain platforms. For Ethereum, the ERC20standard is a widely used token interface and is interoperable with manyexisting dapps, user interface platforms, and popular web applications (e.g.,exchange services). An ERC20 security issue, known as the ""multiple withdrawalattack"", was raised on GitHub and has been open since November 2016. The issueconcerns ERC20's defined method approve() which was envisioned as a way fortoken holders to give permission for other users and dapps to withdraw a cappednumber of tokens. The security issue arises when a token holder wants to adjustthe amount of approved tokens from N to M (this could be an increase ordecrease). If malicious, a user or dapp who is approved for N tokens canfront-run the adjustment transaction to first withdraw N tokens, then allow theapproval to be confirmed, and withdraw an additional M tokens. In this paper,we evaluate 10 proposed mitigations for this issues and find that no solutionis fully satisfactory. We then propose 2 new solutions that mitigate theattack, one of which fully fulfills constraints of the standard, and the secondone shows a general limitation in addressing this issue from ERC20's approvemethod."
"362","arXiv:1907.00900","https://arxiv.org/abs/1907.00900","Post-editese: an Exacerbated Translationese","Antonio Toral","Post-editing (PE) machine translation (MT) is widely used for disseminationbecause it leads to higher productivity than human translation from scratch(HT). In addition, PE translations are found to be of equal or better qualitythan HTs. However, most such studies measure quality solely as the number oferrors. We conduct a set of computational analyses in which we compare PEagainst HT on three different datasets that cover five translation directionswith measures that address different translation universals and laws oftranslation: simplification, normalisation and interference. We find out thatPEs are simpler and more normalised and have a higher degree of interferencefrom the source language than HTs."
"363","arXiv:1907.00899","https://arxiv.org/abs/1907.00899","Engineering Token Economy with System Modeling","Zixuan Zhang","Cryptocurrencies and blockchain networks have attracted tremendous attentionfrom their volatile price movements and the promise of decentralization.However, most projects run on business narratives with no way to test andverify their assumptions and promises about the future. The complex nature ofsystem dynamics within networked economies has rendered it difficult to reasonabout the growth and evolution of these networks. This paper drew concepts fromdifferential games, classical control engineering, and stochastic dynamicalsystem to come up with a framework and example to model, simulate, and engineernetworked token economies. A model on a generalized token economy is proposedwhere miners provide service to a platform in exchange for a cryptocurrency andusers consume service from the platform. Simulations of this model allow us toobserve outcomes of complex dynamics and reason about the evolution of thesystem. Speculative price movements and engineered block rewards were thenexperimented to observe their impact on system dynamics and network-levelgoals. The model presented is necessarily limited so we conclude by exploringthose limitations and outlining future research directions."
"364","arXiv:1907.00895","https://arxiv.org/abs/1907.00895","Comment on ""Adv-BNN: Improved Adversarial Defense through Robust  Bayesian Neural Network""","Roland S. Zimmermann","A recent paper by Liu et al. combines the topics of adversarial training andBayesian Neural Networks (BNN) and suggests that adversarially trained BNNs aremore robust against adversarial attacks than their non-Bayesian counterparts.Here, I analyze the proposed defense and suggest that one needs to adjust theadversarial attack to incorporate the stochastic nature of a Bayesian networkto perform an accurate evaluation of its robustness. Using this new type ofattack I show that there appears to be no strong evidence for higher robustnessof the adversarially trained BNNs."
"365","arXiv:1907.00893","https://arxiv.org/abs/1907.00893","Computational Design of Skinned Quad-Robots","Xudong Feng, Jiafeng Liu, Huamin Wang, Yin Yang, Hujun Bao, Bernd Bickel, Weiwei Xu","We present a computational design system that assists users to model,optimize, and fabricate quad-robots with soft skins.Our system addresses thechallenging task of predicting their physical behavior by fully integrating themultibody dynamics of the mechanical skeleton and the elastic behavior of thesoft skin. The developed motion control strategy uses an alternatingoptimization scheme to avoid expensive full space time-optimization,interleaving space-time optimization for the skeleton and frame-by-frameoptimization for the full dynamics. The output are motor torques to drive therobot to achieve a user prescribed motion trajectory.We also provide acollection of convenient engineering tools and empirical manufacturing guidanceto support the fabrication of the designed quad-robot. We validate thefeasibility of designs generated with our system through physics simulationsand with a physically-fabricated prototype."
"366","arXiv:1907.00887","https://arxiv.org/abs/1907.00887","An Efficient Solution for Breast Tumor Segmentation and Classification  in Ultrasound Images Using Deep Adversarial Learning","Vivek Kumar Singh, Hatem A. Rashwan, Mohamed Abdel-Nasser, Md. Mostafa Kamal Sarker, Farhan Akram, Nidhi Pandey, Santiago Romani, Domenec Puig","This paper proposes an efficient solution for tumor segmentation andclassification in breast ultrasound (BUS) images. We propose to add an atrousconvolution layer to the conditional generative adversarial network (cGAN)segmentation model to learn tumor features at different resolutions of BUSimages. To automatically re-balance the relative impact of each of the highestlevel encoded features, we also propose to add a channel-wise weighting blockin the network. In addition, the SSIM and L1-norm loss with the typicaladversarial loss are used as a loss function to train the model. Our modeloutperforms the state-of-the-art segmentation models in terms of the Dice andIoU metrics, achieving top scores of 93.76% and 88.82%, respectively. In theclassification stage, we show that few statistics features extracted from theshape of the boundaries of the predicted masks can properly discriminatebetween benign and malignant tumors with an accuracy of 85%$"
"367","arXiv:1907.00811","https://arxiv.org/abs/1907.00811","Location Anomalies Detection for Connected and Autonomous Vehicles","Xiaoyang Wang, Ioannis Mavromatis, Andrea Tassi, Raul Santos-Rodriguez, Robert J. Piechocki","Future Connected and Automated Vehicles (CAV), and more generally ITS, willform a highly interconnected system. Such a paradigm is referred to as theInternet of Vehicles (herein Internet of CAVs) and is a prerequisite toorchestrate traffic flows in cities. For optimal decision making andsupervision, traffic centres will have access to suitably anonymized CAVmobility information. Safe and secure operations will then be contingent onearly detection of anomalies. In this paper, a novel unsupervised learningmodel based on deep autoencoder is proposed to detect the self-reportedlocation anomaly in CAVs, using vehicle locations and the Received SignalStrength Indicator (RSSI) as features. Quantitative experiments on simulationdatasets show that the proposed approach is effective and robust in detectingself-reported location anomalies."
"368","arXiv:1907.00884","https://arxiv.org/abs/1907.00884","On mechanisms for transfer using landmark value functions in multi-task  lifelong reinforcement learning","Nick Denis","Transfer learning across different reinforcement learning (RL) tasks isbecoming an increasingly valuable area of research. We consider a goal-basedmulti-task RL framework and mechanisms by which previously solved tasks canreduce sample complexity and regret when the agent is faced with a new task.Specifically, we introduce two metrics on the state space that encode notionsof traversibility of the state space for an agent. Using these metrics atopological covering is constructed by way of a set of landmark states in afully self-supervised manner. We show that these landmark coverings confertheoretical advantages for transfer learning within the goal-based multi-taskRL setting. Specifically, we demonstrate three mechanisms by which landmarkcoverings can be used for successful transfer learning. First, we extend theLandmark Options Via Reflection (LOVR) framework to this new topologicalcovering; second, we use the landmark-centric value functions themselves asfeatures and define a greedy zombie policy that achieves near oracleperformance on a sequence of zero-shot transfer tasks; finally, motivated bythe second transfer mechanism, we introduce a learned reward function thatprovides a more dense reward signal for goal-based RL. Our novel topologicallandmark covering confers beneficial theoretical results, bounding the Q valuesat each state-action pair. In doing so, we introduce a mechanism that performsaction-pruning at infeasible actions which cannot possibly be part of anoptimal policy for the current goal."
"369","arXiv:1907.00883","https://arxiv.org/abs/1907.00883","HyST: A Hybrid Approach for Flexible and Accurate Dialogue State  Tracking","Rahul Goel, Shachi Paul, Dilek Hakkani-Tür","Recent works on end-to-end trainable neural network based approaches havedemonstrated state-of-the-art results on dialogue state tracking. The bestperforming approaches estimate a probability distribution over all possibleslot values. However, these approaches do not scale for large value setscommonly present in real-life applications and are not ideal for tracking slotvalues that were not observed in the training set. To tackle these issues,candidate-generation-based approaches have been proposed. These approachesestimate a set of values that are possible at each turn based on theconversation history and/or language understanding outputs, and hence enablestate tracking over unseen values and large value sets however, they fall shortin terms of performance in comparison to the first group. In this work, weanalyze the performance of these two alternative dialogue state trackingmethods, and present a hybrid approach (HyST) which learns the appropriatemethod for each slot type. To demonstrate the effectiveness of HyST on arich-set of slot types, we experiment with the recently released MultiWOZ-2.0multi-domain, task-oriented dialogue-dataset. Our experiments show that HySTscales to multi-domain applications. Our best performing model results in arelative improvement of 24% and 10% over the previous SOTA and our bestbaseline respectively."
"370","arXiv:1907.00879","https://arxiv.org/abs/1907.00879","Distributed-Memory Load Balancing with Cyclic Token-based Work-Stealing  Applied to Reverse Time Migration","Ítalo A. S. Assis, Antônio D. S. Oliveira, Tiago Barros, Idalmis M. Sardina, Calebe P. Bianchini, Samuel Xavier-de-Souza","Reverse time migration (RTM) is a prominent technique in seismic imaging. Itsresulting subsurface images are used in the industry to investigate with higherconfidence the existence and the conditions of oil and gas reservoirs. Becauseof its high computational cost, RTM must make use of parallel computers.Balancing the workload distribution of an RTM is a growing challenge indistributed computing systems. The heterogeneity of the current parallelsystems, the competition for shared resources and the differently-sized tasksof the RTM are some of the possible sources of load imbalance. Although manyload balancing techniques exist, scaling up for large problems and largesystems remains a challenge because synchronization overhead also scales. Thispaper introduces a load balancing method for distributed-memory systems thatemploys a cyclic token-based work-stealing to avoid synchronous communicationoverhead. The proposed method is implemented as a C library using the one-sidedcommunication feature of the message passing interface (MPI) standard. Resultsobtained by applying the proposed technique to balance the workload of a 3D RTMrunning in a homogeneous computational system present a factor of 2 speedupwhen compared to the conventional static distribution."
"371","arXiv:1907.00878","https://arxiv.org/abs/1907.00878","Neural Logic Rule Layers","Jan Niclas Reimann, Andreas Schwung","Despite their great success in recent years, deep neural networks (DNN) aremainly black boxes where the results obtained by running through the networkare difficult to understand and interpret. Compared to e.g. decision trees orbayesian classifiers, DNN suffer from bad interpretability where we understandby interpretability, that a human can easily derive the relations modeled bythe network. A reasonable way to provide interpretability for humans arelogical rules. In this paper we propose neural logic rule layers (NLRL) whichare able to represent arbitrary logic rules in terms of their conjunctive anddisjunctive normal forms. Using various NLRL within one layer andcorrespondingly stacking various layers, we are able to represent arbitrarycomplex rules by the resulting neural network architecture. The NLRL areend-to-end trainable allowing to learn logic rules directly from available datasets. Experiments show that NLRL-enhanced neural networks can learn to modelarbitrary complex logic and perform arithmetic operation over the input values."
"372","arXiv:1907.00874","https://arxiv.org/abs/1907.00874","System Misuse Detection via Informed Behavior Clustering and Modeling","Linara Adilova, Livin Natious, Siming Chen, Olivier Thonnard, Michael Kamp","One of the main tasks of cybersecurity is recognizing malicious interactionswith an arbitrary system. Currently, the logging information from eachinteraction can be collected in almost unrestricted amounts, but identificationof attacks requires a lot of effort and time of security experts. We propose anapproach for identifying fraud activity through modeling normal behavior ininteractions with a system via machine learning methods, in particular LSTMneural networks. In order to enrich the modeling with system specificknowledge, we propose to use an interactive visual interface that allowssecurity experts to identify semantically meaningful clusters of interactions.These clusters incorporate domain knowledge and lead to more precise behaviormodeling via informed machine learning. We evaluate the proposed approach on adataset containing logs of interactions with an administrative interface oflogin and security server. Our empirical results indicate that the informedmodeling is capable of capturing normal behavior, which can then be used todetect abnormal behavior."
"373","arXiv:1907.00872","https://arxiv.org/abs/1907.00872","Improved hardness for H-colourings of G-colourable graphs","Marcin Wrochna, Stanislav Živný","We present new results on approximate colourings of graphs and, moregenerally, approximate H-colourings and promise constraint satisfactionproblems.First, we show NP-hardness of colouring $k$-colourable graphs with$\binom{k}{\lfloor k/2\rfloor}-1$ colours for every $k\geq 4$. This improvesthe result of Bul\'in, Krokhin, and Opr\v{s}al [STOC'19], who gave NP-hardnessof colouring $k$-colourable graphs with $2k-1$ colours for $k\geq 3$, and theresult of Huang [APPROX-RANDOM'13], who gave NP-hardness of colouring$k$-colourable graphs with $2^{k^{1/3}}$ colours for sufficiently large $k$.Thus, for $k\geq 4$, we improve from known linear/sub-exponential gaps toexponential gaps.Second, we show that the topology of the box complex of H alone determineswhether H-colouring of G-colourable graphs is NP-hard for all (non-bipartite,H-colourable) G. This formalises the topological intuition behind the result ofKrokhin and Opr\v{s}al [FOCS'19] that 3-colouring of G-colourable graphs isNP-hard for all (3-colourable, non-bipartite) G. We use this technique toestablish NP-hardness of H-colouring of G-colourable graphs for H that includebut go beyond $K_3$, including square-free graphs and circular cliques (leaving$K_4$ and larger cliques open).Underlying all of our proofs is a very general observation that adjointfunctors give reductions between promise constraint satisfaction problems."
"374","arXiv:1907.00868","https://arxiv.org/abs/1907.00868","MULEX: Disentangling Exploitation from Exploration in Deep RL","Lucas Beyer, Damien Vincent, Olivier Teboul, Sylvain Gelly, Matthieu Geist, Olivier Pietquin","An agent learning through interactions should balance its action selectionprocess between probing the environment to discover new rewards and using theinformation acquired in the past to adopt useful behaviour. This trade-off isusually obtained by perturbing either the agent's actions (e.g., e-greedy orGibbs sampling) or the agent's parameters (e.g., NoisyNet), or by modifying thereward it receives (e.g., exploration bonus, intrinsic motivation, orhand-shaped rewards). Here, we adopt a disruptive but simple and genericperspective, where we explicitly disentangle exploration and exploitation.Different losses are optimized in parallel, one of them coming from the trueobjective (maximizing cumulative rewards from the environment) and others beingrelated to exploration. Every loss is used in turn to learn a policy thatgenerates transitions, all shared in a single replay buffer. Off-policy methodsare then applied to these transitions to optimize each loss. We showcase ourapproach on a hard-exploration environment, show its sample-efficiency androbustness, and discuss further implications."
"375","arXiv:1907.00863","https://arxiv.org/abs/1907.00863","Understanding GCC Builtins to Develop Better Tools","Manuel Rigger, Stefan Marr, Bram Adams, Hanspeter Mössenböck","C programs can use compiler builtins to provide functionality that the Clanguage lacks. On Linux, GCC provides several thousands of builtins that arealso supported by other mature compilers, such as Clang and ICC. Maintainers ofother tools lack guidance on whether and which builtins should be implementedto support popular projects. To assist tool developers who want to support GCCbuiltins, we analyzed builtin use in 4,913 C projects from GitHub. We foundthat 37% of these projects relied on at least one builtin. Supporting anincreasing proportion of projects requires support of an exponentiallyincreasing number of builtins; however, implementing only 10 builtins alreadycovers over 30% of the projects. Since we found that many builtins in ourcorpus remained unused, the effort needed to support 90% of the projects ismoderate, requiring about 110 builtins to be implemented. For each project, weanalyzed the evolution of builtin use over time and found that the majority ofprojects mostly added builtins. This suggests that builtins are not a legacyfeature and must be supported in future tools. Systematic testing of builtinsupport in existing tools revealed that many lacked support for builtins eitherpartially or completely; we also discovered incorrect implementations invarious tools, including the formally verified CompCert compiler."
"376","arXiv:1907.00860","https://arxiv.org/abs/1907.00860","Energy Efficient Transmission Based on Grouped Spatial Modulation for  upstream DSL Systems","Jiankang Zhang, Chao Xu, Tong Bai, Fasong Wang, Shida Zhong","The digital Subscriber Line (DSL) remains an important component ofheterogeneous networking, especially in historic city-centers, where usingoptical fibre is less realistic. Recently, the power consumption has become animportant performance metric in telecommunication due to the associatedenvironmental issues. In the recent bonding model, customer sites have beenequipped with two/four copper pairs, which may be exploited for designinggrouped spatial modulation (SM) aiming for reducing the power consumption andmitigating the stubborn crosstalk in DSL communications. Explicitly, we viewthe two pair copper pairs equipped for each user as a group and propose anenergy efficient transmission scheme based on grouped SM strategy for theupstream DSL systems, which is capable of reducing the power consumption of theupstream transmitters by activating a single copper line of each user. Moreespecially, in order to compensate for the potential bit-rate reduction imposedby reducing the number of activated lines, the proposed scheme implicitlydelivers ``virtual bits"" via activating/deactivating the lines in addition tothe classic modulation scheme. This is particularly beneficial in the DSLcontext, because the cross-talk imposed by activating several lines may swampthe desired signal. Furthermore, a pair of near-optimal soft turbo detectionschemes are proposed for exploiting the unique properties of the DSL channel inorder to eliminate the error propagation problem of SM detection routinelyencountered in wireless channels. Both the attainable energy-efficiency and theachievable Bit Error Ratio (BER) are investigated. Our simulation resultsdemonstrate that the proposed group-based SM is capable of outperforming thevectoring scheme both in terms of its energy efficiency for all the examinedloop lengths and transmit powers."
"377","arXiv:1907.00856","https://arxiv.org/abs/1907.00856","MobileGAN: Skin Lesion Segmentation Using a Lightweight Generative  Adversarial Network","Md. Mostafa Kamal Sarker, Hatem A. Rashwan, Mohamed Abdel-Nasser, Vivek Kumar Singh, Syeda Furruka Banu, Farhan Akram, Forhad U H Chowdhury, Kabir Ahmed Choudhury, Sylvie Chambon, Petia Radeva, Domenec Puig","Skin lesion segmentation in dermoscopic images is a challenge due to theirblurry and irregular boundaries. Most of the segmentation approaches based ondeep learning are time and memory consuming due to the hundreds of millions ofparameters. Consequently, it is difficult to apply them to real dermatoscopedevices with limited GPU and memory resources. In this paper, we propose alightweight and efficient Generative Adversarial Networks (GAN) model, calledMobileGAN for skin lesion segmentation. More precisely, the MobileGAN combines1D non-bottleneck factorization networks with position and channel attentionmodules in a GAN model. The proposed model is evaluated on the test dataset ofthe ISBI 2017 challenges and the validation dataset of ISIC 2018 challenges.Although the proposed network has only 2.35 millions of parameters, it is stillcomparable with the state-of-the-art. The experimental results show that ourMobileGAN obtains comparable performance with an accuracy of 97.61%."
"378","arXiv:1907.00855","https://arxiv.org/abs/1907.00855","Type Checking Program Code using SHACL (Extended Version)","Martin Leinberger, Philipp Seifer, Claudia Schon, Ralf Lämmel, Steffen Staab","It is a strength of graph-based data formats, like RDF, that they are veryflexible with representing data. To avoid run-time errors, program code thatprocesses highly-flexible data representations exhibits the difficulty that itmust always include the most general case, in which attributes might beset-valued or possibly not available. The Shapes Constraint Language (SHACL)has been devised to enforce constraints on otherwise random data structures. Wepresent our approach, Type checking using SHACL (TyCuS), for type checking codethat queries RDF data graphs validated by a SHACL shape graph. To this end, wederive SHACL shapes from queries and integrate data shapes and query shapes astypes into a $\lambda$-calculus. We provide the formal underpinnings and aproof of type safety for TyCuS. A programmer can use our method in order toprocess RDF data with simplified, type checked code that will not encounterrun-time errors (with usual exceptions as type checking cannot preventaccessing empty lists)."
"379","arXiv:1907.00854","https://arxiv.org/abs/1907.00854","Katecheo: A Portable and Modular System for Multi-Topic Question  Answering","Shirish Hirekodi, Seban Sunny, Leonard Topno, Alwin Daniel, Daniel Whitenack, Reuben Skewes, Stuart Cranney","We introduce a modular system that can be deployed on any Kubernetes clusterfor question answering via REST API. This system, called Katecheo, includesfour configurable modules that collectively enable identification of questions,classification of those questions into topics, a search of knowledge basearticles, and reading comprehension. We demonstrate the system using publiclyavailable, pre-trained models and knowledge base articles extracted from StackExchange sites. However, users can extend the system to any number of topics,or domains, without the need to modify any of the model serving code. Allcomponents of the system are open source and available under a permissiveApache 2 License."
"380","arXiv:1907.00852","https://arxiv.org/abs/1907.00852","EGG: a toolkit for research on Emergence of lanGuage in Games","Eugene Kharitonov, Rahma Chaabouni, Diane Bouchacourt, Marco Baroni","There is renewed interest in simulating language emergence among deep neuralagents that communicate to jointly solve a task, spurred by the practical aimto develop language-enabled interactive AIs, as well as by theoreticalquestions about the evolution of human language. However, optimizing deeparchitectures connected by a discrete communication channel (such as that inwhich language emerges) is technically challenging. We introduce EGG, a toolkitthat greatly simplifies the implementation of emergent-language communicationgames. EGG's modular design provides a set of building blocks that the user cancombine to create new games, easily navigating the optimization andarchitecture space. We hope that the tool will lower the technical barrier, andencourage researchers from various backgrounds to do original work in thisexciting area."
"381","arXiv:1907.00850","https://arxiv.org/abs/1907.00850","Following wrong suggestions: self-blame in human and computer scenarios","Andrea Beretta, Massimo Zancanaro, Bruno Lepri","This paper investigates the specific experience of following a suggestion byan intelligent machine that has a wrong outcome and the emotions people feel.By adopting a typical task employed in studies on decision-making, we presentedparticipants with two scenarios in which they follow a suggestion and have awrong outcome by either an expert human being or an intelligent machine. Wefound a significant decrease in the perceived responsibility on the wrongchoice when the machine offers the suggestion. At present, few studies haveinvestigated the negative emotions that could arise from a bad outcome afterfollowing the suggestion given by an intelligent system, and how to cope withthe potential distrust that could affect the long-term use of the system andthe cooperation. This preliminary research has implications in the study ofcooperation and decision making with intelligent machines. Further research mayaddress how to offer the suggestion in order to better cope with user'sself-blame."
"382","arXiv:1907.00845","https://arxiv.org/abs/1907.00845","Graph-based Nearest Neighbor Search: From Practice to Theory","Liudmila Prokhorenkova","Graph-based approaches are empirically shown to be very successful forapproximate nearest neighbor (ANN) search. However, there has been very littleresearch on their theoretical guarantees. In this work, we consider bothlow-dimensional (d << log(n)) and high-dimensional (d >> log(n)) regimes andrigorously analyze the performance of graph-based nearest neighbor algorithmswhen the dataset is uniformly distributed on a d-dimensional sphere. For bothregimes, we provide the conditions which guarantee that a graph-based algorithmsolves the ANN problem in just one iteration. In the low-dimensional regime, wealso show that it is possible to solve the exact nearest neighbor problem.Finally, we discuss how the ""small-world"" property affects the performance ofgraph-based approaches."
"383","arXiv:1907.00844","https://arxiv.org/abs/1907.00844","Coherence of Type Class Resolution","Gert-Jan Bottu, Ningning Xie, Koar Marntirosian, Tom Schrijvers","Elaboration-based type class resolution, as found in languages like Haskell,Mercury and PureScript, is generally nondeterministic: there can be multipleways to satisfy a wanted constraint in terms of global instances and locallygiven constraints. Coherence is the key property that keeps this sane; itguarantees that, despite the nondeterminism, programs still behave predictably.Even though elaboration-based resolution is generally assumed coherent, as faras we know, there is no formal proof of this property in the presence ofsources of nondeterminism, like superclasses and flexible contexts.This paper provides a formal proof to remedy the situation. The proof isnon-trivial because the semantics elaborates resolution into a target languagewhere different elaborations can be distinguished by contexts that do not havea source language counterpart. Inspired by the notion of full abstraction, wepresent a two-step strategy that first elaborates nondeterministically into anintermediate language that preserves contextual equivalence, and thendeterministically elaborates from there into the target language. We use anapproach based on logical relations to establish contextual equivalence andthus coherence for the first step of elaboration, while the second step'sdeterminism straightforwardly preserves this coherence property."
"384","arXiv:1907.00677","https://arxiv.org/abs/1907.00677","Towards the Definition of Enterprise Architecture Debts","Simon Hacks, Hendrik Höfert, Johannes Salentin, Yoon Chow Yeong, Horst Lichter","In the software development industry, technical debt is regarded as acritical issue in term of the negative consequences such as increased softwaredevelopment cost, low product quality, decreased maintainability, and slowedprogress to the long-term success of developing software. However, despite thevast research contributions in technical debt management for softwareengineering, the idea of technical debt fails to provide a holisticconsideration to include both IT and business aspects. Further, implementing anenterprise architecture (EA) project might not always be a success due touncertainty and unavailability of resources. Therefore, we relate theconsequences of EA implementation failure with a new metaphor --EnterpriseArchitecture Debt (EA Debt). We anticipate that the accumulation of EA Debtwill negatively influence EA quality, also expose the business into risk."
"385","arXiv:1907.00837","https://arxiv.org/abs/1907.00837","XNect: Real-time Multi-person 3D Human Pose Estimation with a Single RGB  Camera","Dushyant Mehta, Oleksandr Sotnychenko, Franziska Mueller, Weipeng Xu, Mohamed Elgharib, Pascal Fua, Hans-Peter Seidel, Helge Rhodin, Gerard Pons-Moll, Christian Theobalt","We present a real-time approach for multi-person 3D motion capture at over 30fps using a single RGB camera. It operates in generic scenes and is robust todifficult occlusions both by other people and objects. Our method operates insubsequent stages. The first stage is a convolutional neural network (CNN) thatestimates 2D and 3D pose features along with identity assignments for allvisible joints of all individuals. We contribute a new architecture for thisCNN, called SelecSLS Net, that uses novel selective long and short range skipconnections to improve the information flow allowing for a drastically fasternetwork without compromising accuracy. In the second stage, a fully-connectedneural network turns the possibly partial (on account of occlusion) 2D pose and3D pose features for each subject into a complete 3D pose estimate perindividual. The third stage applies space-time skeletal model fitting to thepredicted 2D and 3D pose per subject to further reconcile the 2D and 3D pose,and enforce temporal coherence. Our method returns the full skeletal pose injoint angles for each subject. This is a further key distinction from previouswork that neither extracted global body positions nor joint angle results of acoherent skeleton in real time for multi-person scenes. The proposed systemruns on consumer hardware at a previously unseen speed of more than 30 fpsgiven 512x320 images as input while achieving state-of-the-art accuracy, whichwe will demonstrate on a range of challenging real-world scenes."
"386","arXiv:1907.00835","https://arxiv.org/abs/1907.00835","UltraSuite: A Repository of Ultrasound and Acoustic Data from Child  Speech Therapy Sessions","Aciel Eshky, Manuel Sam Ribeiro, Joanne Cleland, Korin Richmond, Zoe Roxburgh, James Scobbie, Alan Wrench","We introduce UltraSuite, a curated repository of ultrasound and acousticdata, collected from recordings of child speech therapy sessions. This releaseincludes three data collections, one from typically developing children and twofrom children with speech sound disorders. In addition, it includes a set ofannotations, some manual and some automatically produced, and software tools toprocess, transform and visualise the data."
"387","arXiv:1907.00832","https://arxiv.org/abs/1907.00832","iPool -- Information-based Pooling in Hierarchical Graph Neural Networks","Xing Gao, Hongkai Xiong, Pascal Frossard","With the advent of data science, the analysis of network or graph data hasbecome a very timely research problem. A variety of recent works have beenproposed to generalize neural networks to graphs, either from a spectral graphtheory or a spatial perspective. The majority of these works however focus onadapting the convolution operator to graph representation. At the same time,the pooling operator also plays an important role in distilling multiscale andhierarchical representations but it has been mostly overlooked so far. In thispaper, we propose a parameter-free pooling operator, called iPool, that permitsto retain the most informative features in arbitrary graphs. With the argumentthat informative nodes dominantly characterize graph signals, we propose acriterion to evaluate the amount of information of each node given itsneighbors, and theoretically demonstrate its relationship to neighborhoodconditional entropy. This new criterion determines how nodes are selected andcoarsened graphs are constructed in the pooling layer. The resultinghierarchical structure yields an effective isomorphism-invariant representationof networked data in arbitrary topologies. The proposed strategy is evaluatedin terms of graph classification on a collection of public graph datasets,including bioinformatics and social networks, and achieves state-of-the-artperformance on most of the datasets."
"388","arXiv:1907.00831","https://arxiv.org/abs/1907.00831","Online Multiple Pedestrian Tracking using Deep Temporal Appearance  Matching Association","Young-Chul Yoon, Du Yong Kim, Kwangjin Yoon, Young-min Song, Moongu Jeon","In online multiple pedestrian tracking it is of great importance to constructreliable cost matrix for assigning observations to tracks. Each element of costmatrix is constructed by using similarity measure. Many previous works haveproposed their own similarity calculation methods consisting of geometric model(e.g. bounding box coordinates) and appearance model. In particular, appearancemodel contains information with higher dimension compared to geometric model.Thanks to the recent success of deep learning based methods, handling of highdimensional appearance information becomes possible. Among many deep networks,a siamese network with triplet loss is popularly adopted as an appearancefeature extractor. Since the siamese network can extract features of each inputindependently, it is possible to adaptively model tracks (e.g. linear update).However, it is not suitable for multi-object setting that requires comparisonwith other inputs. In this paper we propose a novel track appearance modelingbased on joint inference network to address this issue. The proposed methodenables comparison of two inputs to be used for adaptive appearance modeling.It contributes to disambiguating target-observation matching and consolidatingthe identity consistency. Intensive experimental results support effectivenessof our method."
"389","arXiv:1907.00829","https://arxiv.org/abs/1907.00829","Translating Asynchronous Games for Distributed Synthesis (Full Version)","Raven Beutner, Bernd Finkbeiner, Jesko Hecking-Harbusch","In distributed synthesis, we generate a set of process implementations that,together, accomplish an objective against all possible behaviors of theenvironment. A lot of recent work has focussed on systems with causal memory,i.e., sets of asynchronous processes that exchange their causal histories uponsynchronization. Decidability results for this problem have been stated eitherin terms of control games, which extend Zielonka's asynchronous automata bypartitioning the actions into controllable and uncontrollable, or in terms ofPetri games, which extend Petri nets by partitioning the tokens into system andenvironment players. The precise connection between these two models was sofar, however, an open question. In this paper, we provide the first formalconnection between control games and Petri games. We establish the equivalenceof the two game models based on weak bisimulations between their strategies.For both directions, we show that a game of one type can be translated into anequivalent game of the other type. We provide exponential upper and lowerbounds for the translations. Our translations make it possible to transfer andcombine decidability results between the two types of games. Exemplarily, wetranslate decidability in acyclic communication architectures, originallyobtained for control games, to Petri games, and decidability in single-processsystems, originally obtained for Petri games, to control games."
"390","arXiv:1907.00824","https://arxiv.org/abs/1907.00824","Designing Deep Reinforcement Learning for Human Parameter Exploration","Hugo Scurto, Bavo Van Kerrebroeck, Baptiste Caramiaux, Frédéric Bevilacqua","Software tools for generating digital sound often present users withhigh-dimensional, parametric interfaces, that may not facilitate exploration ofdiverse sound designs. In this paper, we propose to investigate artificialagents using deep reinforcement learning to explore parameter spaces inpartnership with users for sound design. We describe a series of user-centredstudies to probe the creative benefits of these agents and adapting theirdesign to exploration. Preliminary studies observing users' explorationstrategies with parametric interfaces and testing different agent explorationbehaviours led to the design of a fully-functioning prototype, calledCo-Explorer, that we evaluated in a workshop with professional sound designers.We found that the Co-Explorer enables a novel creative workflow centred onhuman-machine partnership, which has been positively received by practitioners.We also highlight varied user exploration behaviors throughout partnering withour system. Finally, we frame design guidelines for enabling suchco-exploration workflow in creative digital applications."
"391","arXiv:1907.00822","https://arxiv.org/abs/1907.00822","On consistency types for lattice-based distributed programming languages","Xin Zhao, Philipp Haller","Distributed systems address an increasing demand for fast access to resourcesand provide fault tolerance for data. However, due to scalability requirements,software developers need to trade consistency for performance. For certaindata, consistency guarantees may be weakened if application correctness isunaffected. In contrast, data flows from data with weak consistency to datawith strong consistency requirements are problematic, since applicationcorrectness may be broken.In this paper, we propose LatCalculus, a language and type system fordistributed programming languages with replicated data types. There are twoprincipal new features: first, the type system statically enforcesnoninterference between data types with weak consistency and data types withstrong consistency; second, static encapsulation enables replication of objectgraphs with internal aliasing."
"392","arXiv:1907.00821","https://arxiv.org/abs/1907.00821","Equation Discovery for Nonlinear System Identification","Nikola Simidjievski, Ljupčo Todorovski, Juš Kocijan, Sašo Džeroski","Equation discovery methods enable modelers to combine domain-specificknowledge and system identification to construct models most suitable for aselected modeling task. The method described and evaluated in this paper can beused as a nonlinear system identification method for gray-box modeling. Itconsists of two interlaced parts of modeling that are computer-aided. The firstperforms computer-aided identification of a model structure composed ofelements selected from user-specified domain-specific modeling knowledge, whilethe second part performs parameter estimation. In this paper, recentdevelopments of the equation discovery method called process-based modeling,suited for nonlinear system identification, are elaborated and illustrated ontwo continuous-time case studies. The first case study illustrates the use ofthe process-based modeling on synthetic data while the second case-studyevaluates on measured data for a standard system-identification benchmark. Theexperimental results clearly demonstrate the ability of process-based modelingto reconstruct both model structure and parameters from measured data."
"393","arXiv:1907.00820","https://arxiv.org/abs/1907.00820","Understanding Memory Modules on Learning Simple Algorithms","Kexin Wang, Yu Zhou, Shaonan Wang, Jiajun Zhang, Chengqing Zong","Recent work has shown that memory modules are crucial for the generalizationability of neural networks on learning simple algorithms. However, we stillhave little understanding of the working mechanism of memory modules. Toalleviate this problem, we apply a two-step analysis pipeline consisting offirst inferring hypothesis about what strategy the model has learned accordingto visualization and then verify it by a novel proposed qualitative analysismethod based on dimension reduction. Using this method, we have analyzed twopopular memory-augmented neural networks, neural Turing machine andstack-augmented neural network on two simple algorithm tasks includingreversing a random sequence and evaluation of arithmetic expressions. Resultshave shown that on the former task both models can learn to generalize and onthe latter task only the stack-augmented model can do so. We show thatdifferent strategies are learned by the models, in which specific categories ofinput are monitored and different policies are made based on that to change thememory."
"394","arXiv:1907.00817","https://arxiv.org/abs/1907.00817","The directed 2-linkage problem with length constraints","Jørgen Bang-Jensen, Thomas Bellitto, William Lochet, Anders Yeo","The {\sc weak 2-linkage} problem for digraphs asks for a given digraph andvertices $s_1,s_2,t_1,t_2$ whether $D$ contains a pair of arc-disjoint paths$P_1,P_2$ such that $P_i$ is an $(s_i,t_i)$-path. This problem is NP-completefor general digraphs but polynomially solvable for acyclic digraphs\cite{fortuneTCS10}. Recently it was shown \cite{bercziESA17} that if $D$ isequipped with a weight function $w$ on the arcswhich satisfies that all edges have positive weight, then there is apolynomial algorithm for the variant of the weak-2-linkage problem when bothpaths have to be shortest paths in $D$. In this paper we consider the unitweight case and prove that for every pair constants $k_1,k_2$, there is apolynomial algorithm which decides whether the input digraph $D$ has a pair ofarc-disjoint paths $P_1,P_2$ such that $P_i$ is an $(s_i,t_i)$-path and thelength of $P_i$ is no more than $d(s_i,t_i)+k_i$, for $i=1,2$, where$d(s_i,t_i)$ denotes the length of the shortest $(s_i,t_i)$-path. We provethat, unless the exponential time hypothesis (ETH) fails, there is nopolynomial algorithm for deciding the existence of a solution $P_1,P_2$ to the{\sc weak 2-linkage} problem where each path $P_i$ has length at most$d(s_i,t_i)+ c\log^{1+\epsilon}{}n$ for some constant $c$.We also prove that the {\sc weak 2-linkage} problem remains NP-complete if werequire one of the two paths to be a shortest path while the other path has norestriction on the length."
"395","arXiv:1907.00813","https://arxiv.org/abs/1907.00813","Exponential Separations in Local Differential Privacy Through  Communication Complexity","Matthew Joseph, Jieming Mao, Aaron Roth","We prove a general connection between the communication complexity oftwo-player games and the sample complexity of their multi-player locallyprivate analogues. We use this connection to prove sample complexity lowerbounds for locally differentially private protocols as straightforwardcorollaries of results from communication complexity. In particular, we 1) usea communication lower bound for the hidden layers problem to prove anexponential sample complexity separation between sequentially and fullyinteractive locally private protocols, and 2) use a communication lower boundfor the pointer chasing problem to prove an exponential sample complexityseparation between $k$ round and $k+1$ round sequentially interactive locallyprivate protocols, for every $k$."
"396","arXiv:1907.00810","https://arxiv.org/abs/1907.00810","Multilingual, Multi-scale and Multi-layer Visualization of Intermediate  Representations","Carlos Escolano, Marta R. Costa-jussà, Elora Lacroux, Pere-Pau Vázquez","The main alternatives nowadays to deal with sequences are Recurrent NeuralNetworks (RNN), Convolutional Neural Networks (CNN) architectures and theTransformer. In this context, RNN's, CNN's and Transformer have most commonlybeen used as an encoder-decoder architecture with multiple layers in eachmodule. Far beyond this, these architectures are the basis for the contextualword embeddings which are revolutionizing most natural language downstreamapplications. However, intermediate layer representations in sequence-basedarchitectures can be difficult to interpret. To make each layer representationwithin these architectures more accessible and meaningful, we introduce aweb-based tool that visualizes them both at the sentence and token level. Wepresent three use cases. The first analyses gender issues in contextual wordembeddings. The second and third are showing multilingual intermediaterepresentations for sentences and tokens and the evolution of theseintermediate representations along the multiple layers of the decoder and inthe context of multilingual machine translation."
"397","arXiv:1907.00806","https://arxiv.org/abs/1907.00806","A data-driven approach for multiscale elliptic PDEs with random  coefficients based on intrinsic dimension reduction","Sijing Li, Zhiwen Zhang, Hongkai Zhao","We propose a data-driven approach to solve multiscale elliptic PDEs withrandom coefficients based on the intrinsic low dimension structure of theunderlying elliptic differential operators. Our method consists of offline andonline stages. At the offline stage, a low dimension space and its basis areextracted from the data to achieve significant dimension reduction in thesolution space. At the online stage, the extracted basis will be used to solvea new multiscale elliptic PDE efficiently. The existence of low dimensionstructure is established by showing the high separability of the underlyingGreen's functions. Different online construction methods are proposed dependingon the problem setup. We provide error analysis based on the sampling error andthe truncation threshold in building the data-driven basis. Finally, we presentnumerical examples to demonstrate the accuracy and efficiency of the proposedmethod."
"398","arXiv:1907.00802","https://arxiv.org/abs/1907.00802","Simultaneous Achievement of Driver Assistance and Skill Development in  Shared and Cooperative Controls","Takahiro Wada","Advanced driver assistance systems have successfully reduced drivers'workloads and increased safety. On the other hand, the excessive use of suchsystems can impede the development of driving skills. However, there existcollaborative driver assistance systems, including shared and cooperativecontrols, which can promote effective collaboration between an assistancesystem and a human operator under appropriate system settings. Given aneffective collaboration setup, we address the goal of simultaneously developingor maintaining driving skills while reducing workload. As there has been apaucity of research on such systems and their methodologies, we discuss amethodology applying shared and cooperative controls by considering relatedconcepts in the skill training field. Reverse parking assisted by haptic sharedcontrol is presented as a means of increasing performance during assistance,while skill improvement following assistance is used to demonstrate thepossibility of simultaneous achievement of driver assistance through thereduction of workload and skill improvement."
"399","arXiv:1907.00801","https://arxiv.org/abs/1907.00801","On Characterizations for Subclasses of Directed Co-Graphs","Frank Gurski, Dominique Komander, Carolin Rehs","Undirected co-graphs are those graphs which can be generated from the singlevertex graph by disjoint union and join operations. Co-graphs are exactly theP_4-free graphs (where P_4 denotes the path on 4 vertices). Co-graphs itselfand several subclasses haven been intensively studied. Among these aretrivially perfect graphs, threshold graphs, weakly quasi threshold graphs, andsimple co-graphs.Directed co-graphs are precisely those digraphs which can be defined from thesingle vertex graph by applying the disjoint union, order composition, andseries composition. By omitting the series composition we obtain the subclassof oriented co-graphs which has been analyzed by Lawler in the 1970s and therestriction to linear expressions was recently studied by Boeckner. There areonly a few versions of subclasses of directed co-graphs until now. Bytransmitting the restrictions of undirected subclasses to the directed classes,we define the corresponding subclasses for directed co-graphs. We considerdirected and oriented versions of threshold graphs, simple co-graphs, co-simpleco-graphs, trivially perfect graphs, co-trivially perfect graphs, weakly quasithreshold graphs and co-weakly quasi threshold graphs. For all these classes weprovide characterizations by finite sets of minimal forbidden inducedsubdigraphs. Further we analyze relations between these graph classes."
"400","arXiv:1907.00793","https://arxiv.org/abs/1907.00793","Results and Tools for Evaluating the Effectiveness of Focusing Systems  to Improve Accessibility in Wireless Networks","Volodymyr Astapenya, Volodymyr Sokolov, Mahyar TajDini","The widespread use of wireless technologies leads to an ever-increasingnumber of users and permanently functioning devices. However, the growth of thenumber of wireless users in a limited space and a limited frequency range leadsto an increase in their mutual influence, which ultimately affects thethroughput of wireless channels and even the performance of the system as awhole. The article presents the statistics and tendencies of the distributionof wireless networks of the IEEE 802.11 standard systems, as well as analyzesthe main problems that arise during the expansion of their use. Substantiationand choice of ways to overcome these difficulties largely depends on theobjective control of radiation parameters of access points and subscriber fundsin a particular environment. The review of the state control facilitiesprovided by the developers of the equipment is presented, and author's variantsof experimental measuring complexes are offered, allowing to control signal andinformation parameters of Wi-Fi systems. The experimental results obtained withthe use of the indicated means, obtained using the accelerating metal-platelens as an additional autonomous element for focusing the field, including forMIMO systems, the effect of the accelerating metal-plate lens on the spatialdistribution of the field, on the spectral structure of the signal arepresented. In addition, polarization effects were investigated. Possible waysto further increase the availability, integrity of information and energyefficiency of wireless access systems are discussed. The authors proposesimpler and less costly options for increasing the direction of radiation onthe basis of an accelerating metal-plate lens, experimentally tested, as wellas the use of zone zoning on the path of the computer."
"401","arXiv:1907.00784","https://arxiv.org/abs/1907.00784","On list decoding of 5G-NR polar codes","Charles Pillet, Valerio Bioglio, Carlo Condo","The 5G standardization process of the 3GPP included polar codes concatenatedwith distributed cyclic redundancy check (CRC) as a channel coding scheme fordownlink control information. Whereas CRC bits allow to improve the performanceof successive cancellation list (SCL) decoders by improving distanceproperties, distributed CRC bits allow for path pruning and decodingearly-termination. In this letter, we show how to take advantage of thedistributed CRC to improve SCL decoding, proposing various schemes havingdifferent early-termination and error correction properties. Simulation resultscompare the proposed decoding schemes, showing different tradeoffs betweenerror-correction performance and early-termination with different decoderparameters."
"402","arXiv:1907.00783","https://arxiv.org/abs/1907.00783","Exploiting Relevance for Online Decision-Making in High-Dimensions","Eralp Turgay, Cem Bulucu, Cem Tekin","Many sequential decision-making tasks require choosing at each decision stepthe right action out of the vast set of possibilities by extracting actionableintelligence from high-dimensional data streams. Most of the times, thehigh-dimensionality of actions and data makes learning of the optimal actionsby traditional learning methods impracticable. In this work, we investigate howto discover and leverage the low-dimensional structure in actions and data toenable fast learning. As our learning model, we consider a structuredcontextual multi-armed bandit (CMAB) with high-dimensional arm (action) andcontext (data) sets, where the rewards depend only on a few relevant dimensionsof the joint context-arm set. We depart from the prior work by assuming ahigh-dimensional and uncountable arm set, and allow relevant context dimensionsto vary for each arm. We propose a new online learning algorithm called CMABwith Relevance Learning (CMAB-RL) and prove that its time-averaged regretasymptotically goes to zero. CMAB-RL enjoys a substantially improved regretbound compared to classical CMAB algorithms whose regrets depend on thedimensions $d_x$ and $d_a$ of the context and arm sets. Importantly, we showthat if the learner knows upper bounds $\overline{d}_x$ and $\overline{d}_a$ onthe number of relevant context and arm dimensions, then CMAB-RL achieves$\tilde{O}(T^{1 - 1 /(2 + 2\overline{d}_x + \overline{d}_a)})$ regret. Finally,we illustrate how CMAB algorithms can be used for optimal personalized bloodglucose control in type 1 diabetes mellitus patients, and show that CMAB-RLoutperforms other contextual MAB algorithms in this task, where the contextsrepresent multimodal physiological data streams obtained from sensor readingsand the arms represent bolus insulin doses that are appropriate for injection."
"403","arXiv:1907.00782","https://arxiv.org/abs/1907.00782","Collecting and Analyzing Multidimensional Data with Local Differential  Privacy","Ning Wang, Xiaokui Xiao, Yin Yang, Jun Zhao, Siu Cheung Hui, Hyejin Shin, Junbum Shin, Ge Yu","Local differential privacy (LDP) is a recently proposed privacy standard forcollecting and analyzing data, which has been used, e.g., in the Chromebrowser, iOS and macOS. In LDP, each user perturbs her information locally, andonly sends the randomized version to an aggregator who performs analyses, whichprotects both the users and the aggregator against private information leaks.Although LDP has attracted much research attention in recent years, themajority of existing work focuses on applying LDP to complex data and/oranalysis tasks. In this paper, we point out that the fundamental problem ofcollecting multidimensional data under LDP has not been addressed sufficiently,and there remains much room for improvement even for basic tasks such ascomputing the mean value over a single numeric attribute under LDP. Motivatedby this, we first propose novel LDP mechanisms for collecting a numericattribute, whose accuracy is at least no worse (and usually better) thanexisting solutions in terms of worst-case noise variance. Then, we extend thesemechanisms to multidimensional data that can contain both numeric andcategorical attributes, where our mechanisms always outperform existingsolutions regarding worst-case noise variance. As a case study, we apply oursolutions to build an LDP-compliant stochastic gradient descent algorithm(SGD), which powers many important machine learning tasks. Experiments usingreal datasets confirm the effectiveness of our methods, and their advantagesover existing solutions."
"404","arXiv:1907.00775","https://arxiv.org/abs/1907.00775","First Occurrence of Parity Vectors and the Regular Structure of $k$-Span  Predecessor Sets in the Collatz Graph","Tristan Stérin","We study finite paths in the Collatz graph, a directed graph with naturalnumber nodes and where there is an edge from node $x$ to node $T(x) = T_0(x) =x/2$ if $x$ is even, or to node $T(x) = T_1(x) = (3x+1)/2$ if $x$ is odd. Ourfirst result is an algorithm that, when given a sequence of $n$ parity bits $p= b_0 b_1 \cdots b_{n-1} \in \{ 0,1 \}^n$, called a parity vector, finds theoccurrences of this parity vector in the Collatz graph which are all the paths$o$, of length $n+1$, where the first $n$ nodes of $o$ have exactly theparities given by $p$. In particular, our algorithm can be used to find thefirst occurrence of such parity vectors $p$ (has smallest integer nodes out ofall paths $o$), or indeed the $i^\text{th}$ for any $i \in\mathbb{N}$. In orderto give this algorithm, we introduce $\mathcal{E}(p)$, the ""Collatz encoding""of a parity vector $p$, and the $(\alpha_{0,-1})$-tree, a binary tree whichdictates the structure of first occurrence of parity vectors in the Collatzgraph by using modular arithmetic in $\mathbb{Z}/{3^k}\mathbb{Z}$.Our main result, which generalizes Colussi [TCS 2011], exploits theproperties of first occurrence of parity vectors via their encoding$\mathcal{E}(p)$ and the symmetries of the $(\alpha_{0,-1})$-tree in order tohighlight some regular structure in the Collatz graph. We show that the$k$-span predecessor set of $x\in\mathbb{N}$ in the Collatz graph, whichcontains any ancestor $y$ of $x$ that uses exactly $k$ times the map $T_1$ (andany number of times the map $T_0$) in order to reach $x$, can be defined, inbinary, by a regular expression $\texttt{reg}_k(x)$. Hence, we exhibit ageneral regular structure in the Collatz graph.Finally, throughout this work, we state three conjectures that are equivalentto the Collatz conjecture and are related to the objects we have introduced inthis paper."
"405","arXiv:1907.00765","https://arxiv.org/abs/1907.00765","Ambient vibrations of age-old masonry towers: results of long-term  dynamic monitoring in the historic centre of Lucca","Riccardo Mario Azzara, Maria Girardi, Valerio Iafolla, David Lucchesi, Cristina Padovani, Daniele Pellegrini","The paper presents the results of an ambient vibration monitoring campaignconducted on so-called Clock Tower (Torre delle Ore), one the best known andmost visited monuments in the historic centre of Lucca. The vibrations of thetower were continuously monitored from November 2017 to March 2018 usinghigh-sensitivity instrumentation. In particular, four seismic stations providedby the Istituto Nazionale di Geofisica e Vulcanologia and two three-axialaccelerometers developed by AGI S.r.l., spin-off of the Istituto Nazionale diAstrofisica, were installed on the tower. The measured vibration level wasgenerally very low, since the structure lies in the middle of a limited trafficarea. Nevertheless, the availability of two different types of highly sensitiveand accurate instruments allowed the authors to follow the dynamic behaviour ofthe tower during the entire monitoring period and has moreover providedcross-validation of the results."
"406","arXiv:1907.00762","https://arxiv.org/abs/1907.00762","Open Problem: The Oracle Complexity of Convex Optimization with Limited  Memory","Blake Woodworth, Nathan Srebro","We note that known methods achieving the optimal oracle complexity for firstorder convex optimization require quadratic memory, and ask whether this isnecessary, and more broadly seek to characterize the minimax number of firstorder queries required to optimize a convex Lipschitz function subject to amemory constraint."
"407","arXiv:1907.00676","https://arxiv.org/abs/1907.00676","Space-Efficient Vertex Separators for Treewidth","Frank Kammer, Johannes Meintrup, Andrej Sajenko","Practical applications that use treewidth algorithms have graphs withtreewidth k = O(\sqrt[3]n). Given such n-vertex graphs we present a word-RAMalgorithm to compute vertex separators using only O(n) bits of working memory.As an application of our algorithm, we show an O(1)- approximation algorithmfor tree decomposition. Our algorithm computes a tree decomposition in c^kn(log^* n) log log n time using O(n) bits for some constant c.We finally show that our tree-decomposition algorithm can be used to solveseveral monadic second-order problems using O(n) bits as long as the treewidthof the graph is smaller than c' log n for some constant 0 < c' < 1."
"408","arXiv:1907.00758","https://arxiv.org/abs/1907.00758","Synchronising audio and ultrasound by learning cross-modal embeddings","Aciel Eshky, Manuel Sam Ribeiro, Korin Richmond, Steve Renals","Audiovisual synchronisation is the task of determining the time offsetbetween speech audio and a video recording of the articulators. In child speechtherapy, audio and ultrasound videos of the tongue are captured usinginstruments which rely on hardware to synchronise the two modalities atrecording time. Hardware synchronisation can fail in practice, and no mechanismexists to synchronise the signals post hoc. To address this problem, we employa two-stream neural network which exploits the correlation between the twomodalities to find the offset. We train our model on recordings from 69speakers, and show that it correctly synchronises 82.9% of test utterances fromunseen therapy sessions and unseen speakers, thus considerably reducing thenumber of utterances to be manually synchronised. An analysis of modelperformance on the test utterances shows that directed phone articulations aremore difficult to automatically synchronise compared to utterances containingnatural variation in speech such as words, sentences, or conversations."
"409","arXiv:1907.00752","https://arxiv.org/abs/1907.00752","Incomplete Preferences in Single-Peaked Electorates","Zack Fitzsimmons, Martin Lackner","Incomplete preferences are likely to arise in real-world preferenceaggregation scenarios. This paper deals with determining whether an incompletepreference profile is single-peaked. This is valuable information since manyintractable voting problems become tractable given single-peaked preferences.We prove that the problem of recognizing single-peakedness is NP-complete forincomplete profiles consisting of partial orders. Despite this intractabilityresult, we find several polynomial-time algorithms for reasonably restrictedsettings. In particular, we give polynomial-time recognition algorithms forweak orders, which can be viewed as preferences with indifference."
"410","arXiv:1907.00749","https://arxiv.org/abs/1907.00749","Deep Multi-Task Learning for Anomalous Driving Detection Using CAN Bus  Scalar Sensor Data","Vidyasagar Sadhu, Teruhisa Misu, Dario Pompili","Corner cases are the main bottlenecks when applying Artificial Intelligence(AI) systems to safety-critical applications. An AI system should beintelligent enough to detect such situations so that system developers canprepare for subsequent planning. In this paper, we propose semi-supervisedanomaly detection considering the imbalance of normal situations. Inparticular, driving data consists of multiple positive/normal situations (e.g.,right turn, going straight), some of which (e.g., U-turn) could be as rare asanomalous situations. Existing machine learning based anomaly detectionapproaches do not fare sufficiently well when applied to such imbalanced data.In this paper, we present a novel multi-task learning based approach thatleverages domain-knowledge (maneuver labels) for anomaly detection in drivingdata. We evaluate the proposed approach both quantitatively and qualitativelyon 150 hours of real-world driving data and show improved performance overbaseline approaches."
"411","arXiv:1907.00748","https://arxiv.org/abs/1907.00748","Creek: a General Mixed-Consistency Transactional Replication Scheme","Tadeusz Kobus, Maciej Kokociński, Paweł T. Wojciechowski","In this paper we introduce Creek, a low-latency, eventually consistentreplication scheme that also enables execution of strongly consistent requests.Creek disseminates the messages among the replicas using only a gossipprotocol. Similarly to state machine replication (SMR), Creek totally-ordersall requests, but does so using two different mechanisms: a timestamp-based oneand one built on top of our novel broadcast primitive, conditional atomicbroadcast (CAB). The former is used to establish a tentative order of allrequests for speculative execution and works also within each partition, whenpartitioning of network occurs. On the other hand, CAB is used only for thestrongly consistent requests to ensure their linearizable execution, and isavailable whenever distributed consensus can be solved. The execution of astrongly consistent request also stabilizes the execution order of the causallyrelated weakly consistent requests. Creek uses multiversion concurrency controlto efficiently handle requests' rollbacks and reexecutions resulting from themismatch between the tentative and the final execution orders. In the testsconducted using the TPC-C benchmark, Creek offers up to 3 times lower latencyin returning client responses compared to the state-of-the-art speculative SMRscheme, while maintaining high accuracy of the speculative execution (92-100%)."
"412","arXiv:1907.00736","https://arxiv.org/abs/1907.00736","TRIDENT: A load-balancing Clos-network Packet Switch with Queues between  Input and Central Stages and In-Order Forwarding","Oladele Theophilus Sule, Roberto Rojas-Cessa","We propose a three-stage load balancing packet switch and its configurationscheme. The input- and central-stage switches are bufferless crossbars, and theoutput-stage switches are buffered crossbars. We call this switch ThRee-stageClos-network swItch with queues at the middle stage and DEtermiNisTicscheduling (TRIDENT), and the switch is cell based. The proposed configurationscheme uses predetermined and periodic interconnection patterns in the inputand central modules to load-balance and route traffic, therefore; it has lowconfiguration complexity. The operation of the switch includes a mechanismapplied at input and output modules to forward cells in sequence. TRIDENTachieves 100% throughput under uniform and nonuniform admissible traffic withindependent and identical distributions (i.i.d.). The switch achieves this highperformance using a low-complexity architecture while performing in-sequenceforwarding and no central-stage expansion or memory speedup. Our discussionincludes throughput analysis, where we describe the operations theconfiguration mechanism performs on the traffic traversing the switch, andproof of in-sequence forwarding. We present a simulation analysis as apractical demonstration of the switch performance under uniform and nonuniformi.i.d. traffic."
"413","arXiv:1907.00735","https://arxiv.org/abs/1907.00735","From Bilingual to Multilingual Neural Machine Translation by Incremental  Training","Carlos Escolano, Marta R. Costa-Jussà, José A. R. Fonollosa","Multilingual Neural Machine Translation approaches are based on the use oftask-specific models and the addition of one more language can only be done byretraining the whole system. In this work, we propose a new training schedulethat allows the system to scale to more languages without modification of theprevious components based on joint training and language-independentencoder/decoder modules allowing for zero-shot translation. This work inprogress shows close results to the state-of-the-art in the WMT task."
"414","arXiv:1907.00589","https://arxiv.org/abs/1907.00589","Strong equivalences of approximation numbers and tractability of  weighted anisotropic Sobolev embeddings","JiDong Hao, Heping Wang","In this paper, we study multivariate approximation defined over weightedanisotropic Sobolev spaces which depend on two sequences ${\bfa}=\{a_j\}_{j\geq1}$ and ${\bf b}=\{b_j\}_{j\geq1}$ of positive numbers. Weobtain strong equivalences of the approximation numbers, and necessary andsufficient conditions on ${\bf a}$, ${\bf b}$ to achieve various notions oftractability of the weighted anisotropic Sobolev embeddings."
"415","arXiv:1907.00734","https://arxiv.org/abs/1907.00734","Learning Objectness from Sonar Images for Class-Independent Object  Detection","Matias Valdenegro-Toro","Detecting novel objects without class information is not trivial, as it isdifficult to generalize from a small training set. This is an interestingproblem for underwater robotics, as modeling marine objects is inherently moredifficult in sonar images, and training data might not be available apriori.Detection proposals algorithms can be used for this purpose but usuallyrequires a large amount of output bounding boxes. In this paper we propose theuse of a fully convolutional neural network that regresses an objectness valuedirectly from a Forward-Looking sonar image. By ranking objectness, we canproduce high recall (96 %) with only 100 proposals per image. In comparison,EdgeBoxes requires 5000 proposals to achieve a slightly better recall of 97 %,while Selective Search requires 2000 proposals to achieve 95 % recall. We alsoshow that our method outperforms a template matching baseline by a considerablemargin, and is able to generalize to completely new objects. We expect thatthis kind of technique can be used in the field to find lost objects under thesea."
"416","arXiv:1907.00725","https://arxiv.org/abs/1907.00725","Social Media-based User Embedding: A Literature Review","Shimei Pan, Tao Ding","Automated representation learning is behind many recent success stories inmachine learning. It is often used to transfer knowledge learned from a largedataset (e.g., raw text) to tasks for which only a small number of trainingexamples are available. In this paper, we review recent advance in learning torepresent social media users in low-dimensional embeddings. The technology iscritical for creating high performance social media-based human traits andbehavior models since the ground truth for assessing latent human traits andbehavior is often expensive to acquire at a large scale. In this survey, wereview typical methods for learning a unified user embeddings fromheterogeneous user data (e.g., combines social media texts with images to learna unified user representation). Finally we point out some current issues andfuture directions."
"417","arXiv:1907.00720","https://arxiv.org/abs/1907.00720","Constructing Information-Lossless Biological Knowledge Graphs from  Conditional Statements","Tianwen Jiang, Tong Zhao, Bing Qin, Ting Liu, Nitesh V. Chawla, Meng Jiang","Conditions are essential in the statements of biological literature. Withoutthe conditions (e.g., environment, equipment) that were precisely specified,the facts (e.g., observations) in the statements may no longer be valid. Onebiological statement has one or multiple fact(s) and/or condition(s). Theirsubject and object can be either a concept or a concept's attribute. Existinginformation extraction methods do not consider the role of condition in thebiological statement nor the role of attribute in the subject/object. In thiswork, we design a new tag schema and propose a deep sequence tagging frameworkto structure conditional statement into fact and condition tuples frombiological text. Experiments demonstrate that our method yields ainformation-lossless structure of the literature."
"418","arXiv:1907.00719","https://arxiv.org/abs/1907.00719","Recovering the distribution of fluorophore for FDOT using cuboid  approximation","Chunlong Sun, Yu Jiang, Jijun Liu, Manabu Machida, Gen Nakamura, Goro Nishimura","The time-domain fluorescence diffuse optical tomography (FDOT) istheoretically and numerically investigated based on analytic expressions for athree space dimensional diffusion model. The emission light is analyticallycalculated by an initial boundary value problem for coupled diffusion equationsin the half space. The inverse problem of FDOT is to recover the distributionof fluorophores in biological tissue, which is solved using the time-resolvedmeasurement data on the boundary surface. We identify the location of afluorescence target by assuming that it has a cuboidal shape. The aim of thispaper is to propose a strategy which is a combination of of theoreticalarguments and numerical arguments for a inversion, which enables to obtain astable inversion and accelerate the speed of convergence. Its effectivity andperformance are tested numerically using simulated data and experimental dataobtained from an ex vivo beef phantom."
"419","arXiv:1907.00716","https://arxiv.org/abs/1907.00716","Evidential distance measure in complex belief function theory","Fuyuan Xiao","In this paper, an evidential distance measure is proposed which can measurethe difference or dissimilarity between complex basic belief assignments(CBBAs), in which the CBBAs are composed of complex numbers. When the CBBAs aredegenerated from complex numbers to real numbers, i.e., BBAs, the proposeddistance will degrade into the Jousselme et al.'s distance. Therefore, theproposed distance provides a promising way to measure the differences betweenevidences in a more general framework of complex plane space."
"420","arXiv:1907.00713","https://arxiv.org/abs/1907.00713","Verifying that a compiler preserves concurrent value-dependent  information-flow security","Robert Sison (Data61, CSIRO and UNSW Sydney), Toby Murray (University of Melbourne)","It is common to prove by reasoning over source code that programs do not leaksensitive data. But doing so leaves a gap between reasoning and reality thatcan only be filled by accounting for the behaviour of the compiler. This taskis complicated when programs enforce value-dependent information-flow securityproperties (in which classification of locations can vary depending on valuesin other locations) and complicated further when programs exploitshared-variable concurrency.Prior work has formally defined a notion of concurrency-aware refinement forpreserving value-dependent security properties. However, that notion isconsiderably more complex than standard refinement definitions typicallyapplied in the verification of semantics preservation by compilers. To date itremains unclear whether it can be applied to a realistic compiler, becausethere exist no general decomposition principles for separating it into smaller,more familiar, proof obligations.In this work, we provide such a decomposition principle, which we show canalmost halve the complexity of proving secure refinement. Further, wedemonstrate its applicability to secure compilation, by proving in Isabelle/HOLthe preservation of value-dependent security by a proof-of-concept compilerfrom an imperative While language to a generic RISC-style assembly language,for programs with shared-memory concurrency mediated by locking primitives.Finally, we execute our compiler in Isabelle on a While language model of theCross Domain Desktop Compositor, demonstrating to our knowledge the first useof a compiler verification result to carry an information-flow securityproperty down to the assembly-level model of a non-trivial concurrent program."
"421","arXiv:1907.00576","https://arxiv.org/abs/1907.00576","Average case tractability of additive random fields with Korobov kernels","Jia Chen, Heping Wang","We investigate average case tractability of approximation of additive randomfields with marginal random processes corresponding to the Korobov kernels forthe non-homogeneous case. We use the absolute error criterion (ABS) or thenormalized error criterion (NOR). We show that the problem is alwayspolynomially tractable for ABS or NOR, and give sufficient and necessaryconditions for strong polynomial tractability for ABS or NOR."
"422","arXiv:1907.00710","https://arxiv.org/abs/1907.00710","Deep Conversational Recommender in Travel","Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang, Tat-Seng Chua","When traveling to a foreign country, we are often in dire need of anintelligent conversational agent to provide instant and informative responsesto our various queries. However, to build such a travel agent is non-trivial.First of all, travel naturally involves several sub-tasks such as hotelreservation, restaurant recommendation and taxi booking etc, which invokes theneed for global topic control. Secondly, the agent should consider variousconstraints like price or distance given by the user to recommend anappropriate venue. In this paper, we present a Deep Conversational Recommender(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)models with a neural latent topic component to better guide response generationand make the training easier. To consider the various constraints for venuerecommendation, we leverage a graph convolutional network (GCN) based approachto capture the relationships between different venues and the match betweenvenue and dialog context. For response generation, we combine the topic-basedcomponent with the idea of pointer networks, which allows us to effectivelyincorporate recommendation results. We perform extensive evaluation on amulti-turn task-oriented dialog dataset in travel domain and the results showthat our method achieves superior performance as compared to a wide range ofbaselines."
"423","arXiv:1907.00708","https://arxiv.org/abs/1907.00708","EQuANt (Enhanced Question Answer Network)","François-Xavier Aubet, Dominic Danks, Yuchen Zhu","Machine Reading Comprehension (MRC) is an important topic in the domain ofautomated question answering and in natural language processing more generally.Since the release of the SQuAD 1.1 and SQuAD 2 datasets, progress in the fieldhas been particularly significant, with current state-of-the-art models nowexhibiting near-human performance at both answering well-posed questions anddetecting questions which are unanswerable given a corresponding context. Inthis work, we present Enhanced Question Answer Network (EQuANt), an MRC modelwhich extends the successful QANet architecture of Yu et al. to cope withunanswerable questions. By training and evaluating EQuANt on SQuAD 2, we showthat it is indeed possible to extend QANet to the unanswerable domain. Weachieve results which are close to 2 times better than our chosen baselineobtained by evaluating a lightweight version of the original QANet architectureon SQuAD 2. In addition, we report that the performance of EQuANt on SQuAD 1.1after being trained on SQuAD2 exceeds that of our lightweight QANetarchitecture trained and evaluated on SQuAD 1.1, demonstrating the utility ofmulti-task learning in the MRC context."
"424","arXiv:1907.00701","https://arxiv.org/abs/1907.00701","Anomaly Subsequence Detection with Dynamic Local Density for Time Series","Chunkai Zhang, Yingyang Chen, Ao Yin","Anomaly subsequence detection is to detect inconsistent data, which alwayscontains important information, among time series. Due to the highdimensionality of the time series, traditional anomaly detection often requiresa large time overhead; furthermore, even if the dimensionality reductiontechniques can improve the efficiency, they will lose some information andsuffer from time drift and parameter tuning. In this paper, we propose a newanomaly subsequence detection with Dynamic Local Density Estimation (DLDE) toimprove the detection effect without losing the trend information bydynamically dividing the time series using Time Split Tree. In order to avoidthe impact of the hash function and the randomness of dynamic time segments,ensemble learning is used. Experimental results on different types of data setsverify that the proposed model outperforms the state-of-art methods, and theaccuracy has big improvement."
"425","arXiv:1907.00700","https://arxiv.org/abs/1907.00700","An Improvement of PAA on Trend-Based Approximation for Time Series","Chunkai Zhang, Yingyang Chen, Ao Yin, Zhen Qin, Xing Zhang, Keli Zhang, Zoe L. Jiang","Piecewise Aggregate Approximation (PAA) is a competitive basic dimensionreduction method for high-dimensional time series mining. When deployed,however, the limitations are obvious that some important information will bemissed, especially the trend. In this paper, we propose two new approaches fortime series that utilize approximate trend feature information. Our firstmethod is based on relative mean value of each segment to record the trend,which divide each segment into two parts and use the numerical averagerespectively to represent the trend. We proved that this method satisfies lowerbound which guarantee no false dismissals. Our second method uses a binarystring to record the trend which is also relative to mean in each segment. Ourmethods are applied on similarity measurement in classification and anomalydetection, the experimental results show the improvement of accuracy andeffectiveness by extracting the trend feature suitably."
"426","arXiv:1907.00697","https://arxiv.org/abs/1907.00697","The Trustworthy Pal: Controlling the False Discovery Rate in Boolean  Matrix Factorization","Sibylle Hess, Nico Piatkowski, Katharina Morik","Boolean matrix factorization (BMF) is a popular and powerful technique forinferring knowledge from data. The mining result is the Boolean product of twomatrices, approximating the input dataset. The Boolean product is a disjunctionof rank-1 binary matrices, each describing a feature-relation, called pattern,for a group of samples. Yet, there are no guarantees that any of the returnedpatterns do not actually arise from noise, i.e., are false discoveries. In thispaper, we propose and discuss the usage of the false discovery rate in theunsupervised BMF setting. We prove two bounds on the probability that a foundpattern is constituted of random Bernoulli-distributed noise. Each boundexploits a specific property of the factorization which minimizes theapproximation error---yielding new insights on the minimizers of Boolean matrixfactorization. This leads to improved BMF algorithms by replacing heuristicrank selection techniques with a theoretically well-based approach. Ourempirical demonstration shows that both bounds deliver excellent results invarious practical settings."
"427","arXiv:1907.00695","https://arxiv.org/abs/1907.00695","Automated Image Registration Quality Assessment Utilizing Deep-learning  based Ventricle Extraction in Clinical Data","Florian Dubost, Marleen de Bruijne, Marco Nardin, Adrian V. Dalca, Kathleen L. Donahue, Anne-Katrin Giese, Mark R. Etherton, Ona Wu, Marius de Groot, Wiro Niessen, Meike Vernooij, Natalia S. Rost, Markus D. Schirmer","Registration is a core component of many imaging pipelines. In case ofclinical scans, with lower resolution and sometimes substantial motionartifacts, registration can produce poor results. Visual assessment ofregistration quality in large clinical datasets is inefficient. In this work,we propose to automatically assess the quality of registration to an atlas inclinical FLAIR MRI scans of the brain. The method consists of automaticallysegmenting the ventricles of a given scan using a neural network, and comparingthe segmentation to the atlas' ventricles propagated to image space. We usedthe proposed method to improve clinical image registration to a general atlasby computing multiple registrations and then selecting the registration thatyielded the highest ventricle overlap. Methods were evaluated in a single-sitedataset of more than 1000 scans, as well as a multi-center dataset comprising142 clinical scans from 12 sites. The automated ventricle segmentation reacheda Dice coefficient with manual annotations of 0.89 in the single-site dataset,and 0.83 in the multi-center dataset. Registration via age-specific atlasescould improve ventricle overlap compared to a direct registration to thegeneral atlas (Dice similarity coefficient increase up to 0.15). Experimentsalso showed that selecting scans with the registration quality assessmentmethod could improve the quality of average maps of white matter hyperintensityburden, instead of using all scans for the computation of the white matterhyperintensity map. In this work, we demonstrated the utility of an automatedtool for assessing image registration quality in clinical scans. This imagequality assessment step could ultimately assist in the translation of automatedneuroimaging pipelines to the clinic."
"428","arXiv:1907.00693","https://arxiv.org/abs/1907.00693","Scene Text Magnifier","Toshiki Nakamura, Anna Zhu, Seiichi Uchida","Scene text magnifier aims to magnify text in natural scene images withoutrecognition. It could help the special groups, who have myopia or dyslexia tobetter understand the scene. In this paper, we design the scene text magnifierthrough interacted four CNN-based networks: character erasing, characterextraction, character magnify, and image synthesis. The architecture of thenetworks are extended based on the hourglass encoder-decoders. It inputs theoriginal scene text image and outputs the text magnified image while keeps thebackground unchange. Intermediately, we can get the side-output results of texterasing and text extraction. The four sub-networks are first trainedindependently and fine-tuned in end-to-end mode. The training samples for eachstage are processed through a flow with original image and text annotation inICDAR2013 and Flickr dataset as input, and corresponding text erased image,magnified text annotation, and text magnified scene image as output. Toevaluate the performance of text magnifier, the Structural Similarity is usedto measure the regional changes in each character region. The experimentalresults demonstrate our method can magnify scene text effectively withouteffecting the background."
"429","arXiv:1907.00692","https://arxiv.org/abs/1907.00692","Event extraction based on open information extraction and ontology","Sihem Sahnoun","The work presented in this master thesis consists of extracting a set ofevents from texts written in natural language. For this purpose, we have basedourselves on the basic notions of the information extraction as well as theopen information extraction. First, we applied an open informationextraction(OIE) system for the relationship extraction, to highlight theimportance of OIEs in event extraction, and we used the ontology to the eventmodeling. We tested the results of our approach with test metrics. As a result,the two-level event extraction approach has shown good performance results butrequires a lot of expert intervention in the construction of classifiers andthis will take time. In this context we have proposed an approach that reducesthe expert intervention in the relation extraction, the recognition of entitiesand the reasoning which are automatic and based on techniques of adaptation andcorrespondence. Finally, to prove the relevance of the extracted results, weconducted a set of experiments using different test metrics as well as acomparative study."
"430","arXiv:1907.00687","https://arxiv.org/abs/1907.00687","A Capsule Network for Recommendation and Explaining What You Like and  Dislike","Chenliang Li, Cong Quan, Li Peng, Yunwei Qi, Yuming Deng, Libing Wu","User reviews contain rich semantics towards the preference of users tofeatures of items. Recently, many deep learning based solutions have beenproposed by exploiting reviews for recommendation. The attention mechanism ismainly adopted in these works to identify words or aspects that are importantfor rating prediction. However, it is still hard to understand whether a userlikes or dislikes an aspect of an item according to what viewpoint the userholds and to what extent, without examining the review details. Here, weconsider a pair of a viewpoint held by a user and an aspect of an item as alogic unit. Reasoning a rating behavior by discovering the informative logicunits from the reviews and resolving their corresponding sentiments couldenable a better rating prediction with explanation. To this end, in this paper,we propose a capsule network based model for rating prediction with userreviews, named CARP. For each user-item pair, CARP is devised to extract theinformative logic units from the reviews and infer their correspondingsentiments. The model firstly extracts the viewpoints and aspects from the userand item review documents respectively. Then we derive the representation ofeach logic unit based on its constituent viewpoint and aspect. A sentimentcapsule architecture with a novel Routing by Bi-Agreement mechanism is proposedto identify the informative logic unit and the sentiment based representationsin user-item level for rating prediction. Extensive experiments are conductedover seven real-world datasets with diverse characteristics. Our resultsdemonstrate that the proposed CARP obtains substantial performance gain overrecently proposed state-of-the-art models in terms of prediction accuracy.Further analysis shows that our model can successfully discover theinterpretable reasons at a finer level of granularity."
"431","arXiv:1907.00684","https://arxiv.org/abs/1907.00684","Enabling Dialogue Management with Dynamically Created Dialogue Actions","Juliana Miehle, Louisa Pragst, Wolfgang Minker, Stefan Ultes","In order to take up the challenge of realising user-adaptive systembehaviour, we present an extension for the existing OwlSpeak Dialogue Managerwhich enables the handling of dynamically created dialogue actions. This leadsto an increase in flexibility which can be used for adaptation tasks. After theimplementation of the modifications and the integration of the Dialogue Managerinto a full Spoken Dialogue System, an evaluation of the system has beencarried out. The results indicate that the participants were able to conductmeaningful dialogues and that the system performs satisfactorily, showing thatthe implementation of the Dialogue Manager was successful."
"432","arXiv:1907.00680","https://arxiv.org/abs/1907.00680","The SpectACl of Nonconvex Clustering: A Spectral Approach to  Density-Based Clustering","Sibylle Hess, Wouter Duivesteijn, Philipp Honysz, Katharina Morik","When it comes to clustering nonconvex shapes, two paradigms are used to findthe most suitable clustering: minimum cut and maximum density. The most popularalgorithms incorporating these paradigms are Spectral Clustering and DBSCAN.Both paradigms have their pros and cons. While minimum cut clusterings aresensitive to noise, density-based clusterings have trouble handling clusterswith varying densities. In this paper, we propose \textsc{SpectACl}: a methodcombining the advantages of both approaches, while solving the two mentioneddrawbacks. Our method is easy to implement, such as spectral clustering, andtheoretically founded to optimize a proposed density criterion of clusterings.Through experiments on synthetic and real-world data, we demonstrate that ourapproach provides robust and reliable clusterings."
"433","arXiv:1907.00678","https://arxiv.org/abs/1907.00678","Two-stage Optimization for Machine Learning Workflow","Alexandre Quemy","Machines learning techniques plays a preponderant role in dealing withmassive amount of data and are employed in almost every possible domain.Building a high quality machine learning model to be deployed in production isa challenging task, from both, the subject matter experts and the machinelearning practitioners.For a broader adoption and scalability of machine learning systems, theconstruction and configuration of machine learning workflow need to gain inautomation. In the last few years, several techniques have been developed inthis direction, known as autoML.In this paper, we present a two-stage optimization process to build datapipelines and configure machine learning algorithms. First, we study the impactof data pipelines compared to algorithm configuration in order to show theimportance of data preprocessing over hyperparameter tuning. The second partpresents policies to efficiently allocate search time between data pipelineconstruction and algorithm configuration. Those policies are agnostic from themetaoptimizer. Last, we present a metric to determine if a data pipeline isspecific or independent from the algorithm, enabling fine-grain pipelinepruning and meta-learning for the coldstart problem."
"434","arXiv:1907.00671","https://arxiv.org/abs/1907.00671","Online Primary Channel Selection for Dynamic Channel Bonding in  High-Density WLANs","Sergio Barrachina-Muñoz, Francesc Wilhelmi, Boris Bellalta","In order to dynamically adapt the transmission bandwidth in wireless localarea networks (WLANs), dynamic channel bonding (DCB) was introduced in IEEE802.11n. It has been extended since then, and it is expected to be a keyelement in IEEE 802.11ax and future amendments such as IEEE 802.11be. While DCBis proven to be a compelling mechanism by itself, its performance is deeplytied to the primary channel selection, especially in high-density (HD)deployments, where multiple nodes contend for the spectrum. Traditionally, thisprimary channel selection relied on picking the most free one without anyfurther consideration. In this paper, in contrast, we propose dynamic-wise(DyWi), a light-weight, decentralized, online primary channel selectionalgorithm for DCB that maximizes the expected WLAN throughput by consideringnot only the occupancy of the target primary channel but also the activity ofthe secondary channels. Even when assuming important delay costs due to primaryswitching, simulation results show a significant improvement both in terms ofaverage delay and throughput."
"435","arXiv:1907.00670","https://arxiv.org/abs/1907.00670","Fully-Asynchronous Fully-Implicit Variable-Order Variable-Timestep  Simulation of Neural Networks","Bruno Magalhães, Michael Hines, Thomas Sterling, Felix Schuermann","State-of-the-art simulations of detailed neural models follow the BulkSynchronous Parallel execution model. Execution is divided in equidistantcommunication intervals, equivalent to the shortest synaptic delay in thenetwork. Neurons stepping is performed independently, with collectivecommunication guiding synchronization and exchange of synaptic events.The interpolation step size is fixed and chosen based on some prior knowledgeof the fastest possible dynamics in the system. However, simulations driven bystiff dynamics or a wide range of time scales - such as multiscale simulationsof neural networks - struggle with fixed step interpolation methods, yieldingexcessive computation of intervals of quasi-constant activity, inaccurateinterpolation of periods of high volatility solution, and being incapable ofhandling unknown or distinct time constants. A common alternative is the usageof adaptive stepping methods, however they have been deemed inefficient inparallel executions due to computational load imbalance at the synchronizationbarriers that characterize the BSP execution model.We introduce a distributed fully-asynchronous execution model that removesglobal synchronization, allowing for longer variable timestep interpolations.Asynchronicity is provided by active point-to-point communication notifyingneurons' time advancement to synaptic connectivities. Time stepping is drivenby scheduled neuron advancements based on synaptic delays across neurons,yielding an ""exhaustive yet not speculative"" adaptive-step execution. Executionbenchmarks on 64 Cray XE6 compute nodes demonstrate a reduced number ofinterpolation steps, higher numerical accuracy and lower time to solution,compared to state-of-the-art methods. Efficiency is shown to beactivity-dependent, with scaling of the algorithm demonstrated on a simulationof a laboratory experiment."
"436","arXiv:1907.00667","https://arxiv.org/abs/1907.00667","Lossy Compression for Large Scale PDE Problems","Sebastian Götschel, Martin Weiser","Solvers for partial differential equations (PDE) are one of the cornerstonesof computational science. For large problems, they involve huge amounts of datathat needs to be stored and transmitted on all levels of the memory hierarchy.Often, bandwidth is the limiting factor due to relatively small arithmeticintensity, and increasingly so due to the growing disparity between computingpower and bandwidth. Consequently, data compression techniques have beeninvestigated and tailored towards the specific requirements of PDE solversduring the last decades. This paper surveys data compression challenges andcorresponding solution approaches for PDE problems, covering all levels of thememory hierarchy from mass storage up to main memory. Exemplarily, weillustrate concepts at particular methods, and give references to alternatives."
"437","arXiv:1907.00664","https://arxiv.org/abs/1907.00664","Learning World Graphs to Accelerate Hierarchical Reinforcement Learning","Wenling Shang, Alex Trott, Stephan Zheng, Caiming Xiong, Richard Socher","In many real-world scenarios, an autonomous agent often encounters varioustasks within a single complex environment. We propose to build a graphabstraction over the environment structure to accelerate the learning of thesetasks. Here, nodes are important points of interest (pivotal states) and edgesrepresent feasible traversals between them. Our approach has two stages. First,we jointly train a latent pivotal state model and a curiosity-drivengoal-conditioned policy in a task-agnostic manner. Second, provided with theinformation from the world graph, a high-level Manager quickly finds solutionto new tasks and expresses subgoals in reference to pivotal states to alow-level Worker. The Worker can then also leverage the graph to easilytraverse to the pivotal states of interest, even across long distance, andexplore non-locally. We perform a thorough ablation study to evaluate ourapproach on a suite of challenging maze tasks, demonstrating significantadvantages from the proposed framework over baselines that lack world graphknowledge in terms of performance and efficiency."
"438","arXiv:1907.00661","https://arxiv.org/abs/1907.00661","The Resale Price Prediction of Secondhand Jewelry Items Using a  Multi-modal Deep Model with Iterative Co-Attention","Yusuke Yamaura, Nobuya Kanemaki, Yukihiro Tsuboshita","The resale price assessment of secondhand jewelry items relies heavily on theindividual knowledge and skill of domain experts. In this paper, we propose amethodology for reconstructing an AI system that autonomously assesses theresale prices of secondhand jewelry items without the need for professionalknowledge. As shown in recent studies on fashion items, multimodal approachescombining specifications and visual information of items have succeeded inobtaining fine-grained representations of fashion items, although theygenerally apply simple vector operations through a multimodal fusion. Wesimilarly build a multimodal model using images and attributes of the productand further employ state-of-the-art multimodal deep neural networks applied incomputer vision to achieve a practical performance level. In addition, we modelthe pricing procedure of an expert using iterative co-attention networks inwhich the appearance and attributes of the product are carefully anditeratively observed. Herein, we demonstrate the effectiveness of our modelusing a large dataset of secondhand no brand jewelry items received from acollaborating fashion retailer, and show that the iterative co-attentionprocess operates effectively in the context of resale price prediction. Ourmodel architecture is widely applicable to other fashion items where appearanceand specifications are important aspects."
"439","arXiv:1907.00659","https://arxiv.org/abs/1907.00659","Modernizing Historical Documents: a User Study","Miguel Domingo, Francisco Casacuberta","Accessibility to historical documents is mostly limited to scholars. This isdue to the language barrier inherent in human language and the linguisticproperties of these documents. Given a historical document, modernization aimsto generate a new version of it, written in the modern version of thedocument's language. Its goal is to tackle the language barrier, decreasing thecomprehension difficulty and making historical documents accessible to abroader audience. In this work, we proposed a new neural machine translationapproach that profits from modern documents to enrich its systems. We testedthis approach with both automatic and human evaluation, and conducted a userstudy. Results showed that modernization is successfully reaching its goal,although it still has room for improvement."
"440","arXiv:1907.00657","https://arxiv.org/abs/1907.00657","Optical Reservoir Computing using multiple light scattering for chaotic  systems prediction","Jonathan Dong, Mushegh Rafayelyan, Florent Krzakala, Sylvain Gigan","Reservoir Computing is a relatively recent computational framework based on alarge Recurrent Neural Network with fixed weights. Many physicalimplementations of Reservoir Computing have been proposed to improve speed andenergy efficiency. In this study, we report new advances in Optical ReservoirComputing using multiple light scattering to accelerate the recursivecomputation of the reservoir states. Two different spatial light modulationtechnologies, namely, phase or binary amplitude modulations, are compared.Phase modulation is a promising direction already employed in other photonicimplementations of Reservoir Computing. Additionally, we report aDigital-Micromirror-based Reservoir Computing at up to 640 Hz, more than doublethe previously reported frequency using a remotely controlled optical devicedeveloped by LightOn, and present new binarization strategies to improve theperformance of binarized Reservoir Computing."
"441","arXiv:1907.00652","https://arxiv.org/abs/1907.00652","Avoiding Implementation Pitfalls of ""Matrix Capsules with EM Routing"" by  Hinton et al","Ashley Daniel Gritzman","The recent progress on capsule networks by Hinton et al. has generatedconsiderable excitement in the machine learning community. The idea behind acapsule is inspired by a cortical minicolumn in the brain, whereby a verticallyorganised group of around 100 neurons receive common inputs, have commonoutputs, are interconnected, and may well constitute a fundamental computationunit of the cerebral cortex. However, Hinton's paper on ""Matrix Capsule with EMRouting'"" was unfortunately not accompanied by a release of source code, whichleft interested researchers attempting to implement the architecture andreproduce the benchmarks on their own. This has certainly slowed the progressof research building on this work. While writing our own implementation, wenoticed several common mistakes in other open source implementations that wecame across. In this paper we share some of these learnings, specificallyfocusing on three implementation pitfalls and how to avoid them: (1) parentcapsules with only one child; (2) normalising the amount of data assigned toparent capsules; (3) parent capsules at different positions compete for childcapsules. While our implementation is a considerable improvement over currentlyavailable implementations, it still falls slightly short of the performancereported by Hinton et al. (2018). The source code for this implementation isavailable on GitHub at the following URL:https://github.com/IBM/matrix-capsules-with-em-routing."
"442","arXiv:1907.00651","https://arxiv.org/abs/1907.00651","Self-supervised Hyperspectral Image Restoration using Separable Image  Prior","Ryuji Imamura, Tatsuki Itasaka, Masahiro Okuda","Supervised learning with a convolutional neural network is recognized as apowerful means of image restoration. However, most such methods have beendesigned for application to grayscale and/or color images; therefore, they havelimited success when applied to hyperspectral image restoration. This ispartially owing to large datasets being difficult to collect, and also theheavy computational load associated with the restoration of an image with manyspectral bands. To address this difficulty, we propose a novel self-supervisedlearning strategy for application to hyperspectral image restoration. Ourmethod automatically creates a training dataset from a single degraded imageand trains a denoising network without any clear images. Another notablefeature of our method is the use of a separable convolutional layer. Weundertake experiments to prove that the use of a separable network allows us toacquire the prior of a hyperspectral image and to realize efficientrestoration. We demonstrate the validity of our method through extensiveexperiments and show that our method has better characteristics than those thatare currently regarded as state-of-the-art."
"443","arXiv:1907.00650","https://arxiv.org/abs/1907.00650","Neural Dynamics Discovery via Gaussian Process Recurrent Neural Networks","Qi She, Anqi Wu","Latent dynamics discovery is challenging in extracting complex dynamics fromhigh-dimensional noisy neural data. Many dimensionality reduction methods havebeen widely adopted to extract low-dimensional, smooth and time-evolving latenttrajectories. However, simple state transition structures, linear embeddingassumptions, or inflexible inference networks impede the accurate recovery ofdynamic portraits. In this paper, we propose a novel latent dynamic model thatis capable of capturing nonlinear, non-Markovian, long short-termtime-dependent dynamics via recurrent neural networks and tackling complexnonlinear embedding via non-parametric Gaussian process. Due to the complexityand intractability of the model and its inference, we also provide a powerfulinference network with bi-directional long short-term memory networks thatencode both past and future information into posterior distributions. In theexperiment, we show that our model outperforms other state-of-the-art methodsin reconstructing insightful latent dynamics from both simulated andexperimental neural datasets with either Gaussian or Poisson observations,especially in the low-sample scenario. Our codes and additional materials areavailable at https://github.com/sheqi/GP-RNN_UAI2019."
"444","arXiv:1907.00641","https://arxiv.org/abs/1907.00641","Permutohedral Attention Module for Efficient Non-Local Neural Networks","Samuel Joutard, Reuben Dorent, Amanda Isaac, Sebastien Ourselin, Tom Vercauteren, Marc Modat","Medical image processing tasks such as segmentation often require capturingnon-local information. As organs, bones, and tissues share commoncharacteristics such as intensity, shape, and texture, the contextualinformation plays a critical role in correctly labeling them. Segmentation andlabeling is now typically done with convolutional neural networks (CNNs) butthe context of the CNN is limited by the receptive field which itself islimited by memory requirements and other properties. In this paper, we proposea new attention module, that we call Permutohedral Attention Module (PAM), toefficiently capture non-local characteristics of the image. The proposed methodis both memory and computationally efficient. We provide a GPU implementationof this module suitable for 3D medical imaging problems. We demonstrate theefficiency and scalability of our module with the challenging task of vertebraesegmentation and labeling where context plays a crucial role because of thevery similar appearance of different vertebrae."
"445","arXiv:1907.00635","https://arxiv.org/abs/1907.00635","Dermtrainer: A Decision Support System for Dermatological Diseases","Gernot Salzer, Agata Ciabattoni, Christian Fermüller, Martin Haiduk, Harald Kittler, Arno Lukas, Rosa María Rodríguez Domínguez, Antonia Wesinger, Elisabeth Riedl","Dermtrainer is a medical decision support system that assists generalpractitioners in diagnosing skin diseases and serves as a training platform fordermatologists. Its key components are a comprehensive dermatological knowledgebase, a clinical algorithm for diagnosing skin diseases, a reasoning componentfor deducing the most likely differential diagnoses for a patient, and alibrary of high-quality images. This report describes the technical componentsof the system, in particular the ranking algorithm for retrieving appropriatediseases as diagnoses."
"446","arXiv:1907.00631","https://arxiv.org/abs/1907.00631","Automatic reconstruction of fully volumetric 3D building models from  point clouds","Sebastian Ochmann, Richard Vock, Reinhard Klein","We present a novel method for reconstructing parametric, volumetric,multi-story building models from unstructured, unfiltered indoor point cloudsby means of solving an integer linear optimization problem. Our approachovercomes limitations of previous methods in several ways: First, we dropassumptions about the input data such as the availability of separate scans asan initial room segmentation. Instead, a fully automatic room segmentation andoutlier removal is performed on the unstructured point clouds. Second,restricting the solution space of our optimization approach to arrangements ofvolumetric wall entities representing the structure of a building enforces aconsistent model of volumetric, interconnected walls fitted to the observeddata instead of unconnected, paper-thin surfaces. Third, we formulate theoptimization as an integer linear programming problem which allows for an exactsolution instead of the approximations achieved with most previous techniques.Lastly, our optimization approach is designed to incorporate hard constraintswhich were difficult or even impossible to integrate before. We evaluate anddemonstrate the capabilities of our proposed approach on a variety of complexreal-world point clouds."
"447","arXiv:1907.00625","https://arxiv.org/abs/1907.00625","On-chip learning in a conventional silicon MOSFET based Analog Hardware  Neural Network","Nilabjo Dey, Janak Sharda, Utkarsh Saxena, Divya Kaushik, Utkarsh Singh, Debanjan Bhowmik","On-chip learning in a crossbar array based analog hardware Neural Network(NN) has been shown to have major advantages in terms of speed and energycompared to training NN on a traditional computer. However analog hardware NNproposals and implementations thus far have mostly involved Non Volatile Memory(NVM) devices like Resistive Random Access Memory (RRAM), Phase Change Memory(PCM), spintronic devices or floating gate transistors as synapses. Fabricatingsystems based on RRAM, PCM or spintronic devices need in-house laboratoryfacilities and cannot be done through merchant foundries, unlike conventionalsilicon based CMOS chips. Floating gate transistors need large voltage pulsesfor weight update, making on-chip learning in such systems energy inefficient.This paper proposes and implements through SPICE simulations on-chip learningin analog hardware NN using only conventional silicon based MOSFETs (withoutany floating gate) as synapses since they are easy to fabricate. We first modelthe synaptic characteristic of our single transistor synapse using SPICEcircuit simulator and benchmark it against experimentally obtainedcurrent-voltage characteristics of a transistor. Next we design a FullyConnected Neural Network (FCNN) crossbar array using such transistor synapses.We also design analog peripheral circuits for neuron and synaptic weight updatecalculation, needed for on-chip learning, again using conventional transistors.Simulating the entire system on SPICE simulator, we obtain high training andtest accuracy on the standard Fisher's Iris dataset, widely used in machinelearning. We also compare the speed and energy performance of our transistorbased implementation of analog hardware NN with some previous implementationsof NN with NVM devices and show comparable performance with respect to on-chiplearning."
"448","arXiv:1907.00624","https://arxiv.org/abs/1907.00624","Using Deep Learning to Predict Plant Growth and Yield in Greenhouse  Environments","Bashar Alhnaity, Simon Pearson, Georgios Leontidis, Stefanos Kollias","Effective plant growth and yield prediction is an essential task forgreenhouse growers and for agriculture in general. Developing models which caneffectively model growth and yield can help growers improve the environmentalcontrol for better production, match supply and market demand and lower costs.Recent developments in Machine Learning (ML) and, in particular, Deep Learning(DL) can provide powerful new analytical tools. The proposed study utilises MLand DL techniques to predict yield and plant growth variation across twodifferent scenarios, tomato yield forecasting and Ficus benjamina stem growth,in controlled greenhouse environments. We deploy a new deep recurrent neuralnetwork (RNN), using the Long Short-Term Memory (LSTM) neuron model, in theprediction formulations. Both the former yield, growth and stem diametervalues, as well as the microclimate conditions, are used by the RNNarchitecture to model the targeted growth parameters. A comparative study ispresented, using ML methods, such as support vector regression and randomforest regression, utilising the mean square error criterion, in order toevaluate the performance achieved by the different methods. Very promisingresults, based on data that have been obtained from two greenhouses, in Belgiumand the UK, in the framework of the EU Interreg SMARTGREEN project (2017-2021),are presented."
"449","arXiv:1907.00620","https://arxiv.org/abs/1907.00620","Using Database Rule for Weak Supervised Text-to-SQL Generation","Tong Guo, Huilin Gao","We present a simple and novel way to do the task of text-to-SQL problem withweak supervision. We call it Rule-SQL. Given the question and the answer fromthe database table without the SQL logic form, Rule-SQL use the database rulesfor the SQL exploration first and then use the explored SQL for supervisedtraining. We design several rules for reducing the exploration search space.For the deep model, we leverage BERT for the representation layer and separatethe model to SELECT, AGG and WHERE parts. The experiment result on WikiSQLoutperforms the strong baseline of full supervision and is comparable to thestart-of-the-art weak supervised mothods."
"450","arXiv:1907.00618","https://arxiv.org/abs/1907.00618","CDTB: A Color and Depth Visual Object Tracking Dataset and Benchmark","Alan Lukežič, Ugur Kart, Jani Käpylä, Ahmed Durmush, Joni-Kristian Kämäräinen, Jiří Matas, Matej Kristan","A long-term visual object tracking performance evaluation methodology and abenchmark are proposed. Performance measures are designed by following along-term tracking definition to maximize the analysis probing strength. Thenew measures outperform existing ones in interpretation potential and in betterdistinguishing between different tracking behaviors. We show that thesemeasures generalize the short-term performance measures, thus linking the twotracking problems. Furthermore, the new measures are highly robust to temporalannotation sparsity and allow annotation of sequences hundreds of times longerthan in the current datasets without increasing manual annotation labor. A newchallenging dataset of carefully selected sequences with many targetdisappearances is proposed. A new tracking taxonomy is proposed to positiontrackers on the short-term/long-term spectrum. The benchmark contains anextensive evaluation of the largest number of long-term tackers and comparisonto state-of-the-art short-term trackers. We analyze the influence of trackingarchitecture implementations to long-term performance and explore variousre-detection strategies as well as influence of visual model update strategiesto long-term tracking drift. The methodology is integrated in the VOT toolkitto automate experimental analysis and benchmarking and to facilitate futuredevelopment of long-term trackers."
"451","arXiv:1907.00178","https://arxiv.org/abs/1907.00178","Music Performance Analysis: A Survey","Alexander Lerch, Claire Arthur, Ashis Pati, Siddharth Gururani","Music Information Retrieval (MIR) tends to focus on the analysis of audiosignals. Often, a single music recording is used as representative of a ""song""even though different performances of the same song may reveal differentproperties. A performance is distinct in many ways from a (arguably moreabstract) representation of a ""song,"" ""piece,"" or musical score. Thecharacteristics of the (recorded) performance -- as opposed to the score ormusical idea -- can have a major impact on how a listener perceives music. Theanalysis of music performance, however, has been traditionally only aperipheral topic for the MIR research community. This paper surveys the fieldof Music Performance Analysis (MPA) from various perspectives, discusses itssignificance to the field of MIR, and points out opportunities for futureresearch in this field."
"452","arXiv:1907.00612","https://arxiv.org/abs/1907.00612","One Network for Multi-Domains: Domain Adaptive Hashing with Intersectant  Generative Adversarial Network","Tao He, Yuan-Fang Li, Lianli Gao, Dongxiang Zhang, Jingkuan Song","With the recent explosive increase of digital data, image recognition andretrieval become a critical practical application. Hashing is an effectivesolution to this problem, due to its low storage requirement and high queryspeed. However, most of past works focus on hashing in a single (source)domain. Thus, the learned hash function may not adapt well in a new (target)domain that has a large distributional difference with the source domain. Inthis paper, we explore an end-to-end domain adaptive learning framework thatsimultaneously and precisely generates discriminative hash codes and classifiestarget domain images. Our method encodes two domains images into a semanticcommon space, followed by two independent generative adversarial networksarming at crosswise reconstructing two domains' images, reducing domaindisparity and improving alignment in the shared space. We evaluate ourframework on {four} public benchmark datasets, all of which show that ourmethod is superior to the other state-of-the-art methods on the tasks of objectrecognition and image retrieval."
"453","arXiv:1907.00607","https://arxiv.org/abs/1907.00607","Weak Supervision Enhanced Generative Network for Question Generation","Yutong Wang, Jiyuan Zheng, Qijiong Liu, Zhou Zhao, Jun Xiao, Yueting Zhuang","Automatic question generation according to an answer within the given passageis useful for many applications, such as question answering system, dialoguesystem, etc. Current neural-based methods mostly take two steps which extractseveral important sentences based on the candidate answer through manual rulesor supervised neural networks and then use an encoder-decoder framework togenerate questions about these sentences. These approaches neglect the semanticrelations between the answer and the context of the whole passage which issometimes necessary for answering the question. To address this problem, wepropose the Weak Supervision Enhanced Generative Network (WeGen) whichautomatically discovers relevant features of the passage given the answer spanin a weakly supervised manner to improve the quality of generated questions.More specifically, we devise a discriminator, Relation Guider, to capture therelations between the whole passage and the associated answer and then theMulti-Interaction mechanism is deployed to transfer the knowledge dynamicallyfor our question generation system. Experiments show the effectiveness of ourmethod in both automatic evaluations and human evaluations."
"454","arXiv:1907.00605","https://arxiv.org/abs/1907.00605","Online Multidimensional Packing Problems in the Random-Order Model","David Naori (1), Danny Raz (1) ((1) Computer Science Department, Technion, Israel)","We study online multidimensional variants of the generalized assignmentproblem which are used to model prominent real-world applications, such as theassignment of virtual machines with multiple resource requirements to physicalinfrastructure in cloud computing. These problems can be seen as an extensionof the well known secretary problem and thus the standard online worst-casemodel cannot provide any performance guarantee. The prevailing model in thiscase is the random-order model, which provides a useful realistic and robustalternative. Using this model, we study the $d$-dimensional generalizedassignment problem, where we introduce a novel technique that achieves an$O(d)$-competitive algorithms and prove a matching lower bound of $\Omega(d)$.Furthermore, our algorithm improves upon the best-known competitive-ratio forthe online (one-dimensional) generalized assignment problem and the onlineknapsack problem."
"455","arXiv:1907.00598","https://arxiv.org/abs/1907.00598","On an Equivalence Between Single-Server PIR with Side Information and  Locally Recoverable Codes","Swanand Kadhe, Anoosheh Heidarzadeh, Alex Sprintson, O. Ozan Koyluoglu","Private Information Retrieval (PIR) problem has recently attracted asignificant interest in the information-theory community. In this problem, auser wants to privately download one or more messages belonging to a databasewith copies stored on a single or multiple remote servers. In the single serverscenario, the user must have prior side information, i.e., a subset of messagesunknown to the server, to be able to privately retrieve the required messagesin an efficient way.In the last decade, there has also been a significant interest in LocallyRecoverable Codes (LRC), a class of storage codes in which each symbol can berecovered from a limited number of other symbols. More recently, there is aninterest in 'cooperative' locally recoverable codes, i.e., codes in whichmultiple symbols can be recovered from a small set of other code symbols.In this paper, we establish a relationship between coding schemes for thesingle-server PIR problem and LRCs. In particular, we show the followingresults: (i) PIR schemes designed for retrieving a single message areequivalent to classical LRCs; and (ii) PIR schemes for retrieving multiplemessages are equivalent to cooperative LRCs. These equivalence results allow usto recover upper bounds on the download rate for PIR-SI schemes, and to obtaina novel rate upper bound on cooperative LRCs. We show results for both linearand non-linear codes."
"456","arXiv:1907.00593","https://arxiv.org/abs/1907.00593","Weight Normalization based Quantization for Deep Neural Network  Compression","Wen-Pu Cai, Wu-Jun Li","With the development of deep neural networks, the size of network modelsbecomes larger and larger. Model compression has become an urgent need fordeploying these network models to mobile or embedded devices. Modelquantization is a representative model compression technique. Although a lot ofquantization methods have been proposed, many of them suffer from a highquantization error caused by a long-tail distribution of network weights. Inthis paper, we propose a novel quantization method, called weight normalizationbased quantization (WNQ), for model compression. WNQ adopts weightnormalization to avoid the long-tail distribution of network weights andsubsequently reduces the quantization error. Experiments on CIFAR-100 andImageNet show that WNQ can outperform other baselines to achievestate-of-the-art performance."
"457","arXiv:1907.00590","https://arxiv.org/abs/1907.00590","A Review-Driven Neural Model for Sequential Recommendation","Chenliang Li, Xichuan Niu, Xiangyang Luo, Zhenzhong Chen, Cong Quan","Writing review for a purchased item is a unique channel to express a user'sopinion in E-Commerce. Recently, many deep learning based solutions have beenproposed by exploiting user reviews for rating prediction. In contrast, therehas been few attempt to enlist the semantic signals covered by user reviews forthe task of collaborative filtering. In this paper, we propose a novelreview-driven neural sequential recommendation model (named RNS) by consideringusers' intrinsic preference (long-term) and sequential patterns (short-term).In detail, RNS is devised to encode each user or item with the aspect-awarerepresentations extracted from the reviews. Given a sequence of historicalpurchased items for a user, we devise a novel hierarchical attention overattention mechanism to capture sequential patterns at both union-level andindividual-level. Extensive experiments on three real-world datasets ofdifferent domains demonstrate that RNS obtains significant performanceimprovement over uptodate state-of-the-art sequential recommendation models."
"458","arXiv:1907.00570","https://arxiv.org/abs/1907.00570","Do Transformer Attention Heads Provide Transparency in Abstractive  Summarization?","Joris Baan, Maartje ter Hoeve, Marlies van der Wees, Anne Schuth, Maarten de Rijke","Learning algorithms become more powerful, often at the cost of increasedcomplexity. In response, the demand for algorithms to be transparent isgrowing. In NLP tasks, attention distributions learned by attention-based deeplearning models are used to gain insights in the models' behavior. To whichextent is this perspective valid for all NLP tasks? We investigate whetherdistributions calculated by different attention heads in a transformerarchitecture can be used to improve transparency in the task of abstractivesummarization. To this end, we present both a qualitative and quantitativeanalysis to investigate the behavior of the attention heads. We show that someattention heads indeed specialize towards syntactically and semanticallydistinct input. We propose an approach to evaluate to which extent theTransformer model relies on specifically learned attention distributions. Wealso discuss what this implies for using attention distributions as a means oftransparency."
"459","arXiv:1907.00560","https://arxiv.org/abs/1907.00560","On Symmetry and Initialization for Neural Networks","Ido Nachum, Amir Yehudayoff","This work provides an additional step in the theoretical understanding ofneural networks. We consider neural networks with one hidden layer and showthat when learning symmetric functions, one can choose initial conditions sothat standard SGD training efficiently produces generalization guarantees. Weempirically verify this and show that this does not hold when the initialconditions are chosen at random. The proof of convergence investigates theinteraction between the two layers of the network. Our results highlight theimportance of using symmetry in the design of neural networks."
"460","arXiv:1907.00559","https://arxiv.org/abs/1907.00559","Learning to Approximate Directional Fields Defined over 2D Planes","Maria Taktasheva, Albert Matveev, Alexey Artemov, Evgeny Burnaev","Reconstruction of directional fields is a need in many geometry processingtasks, such as image tracing, extraction of 3D geometric features, and findingprincipal surface directions. A common approach to the construction ofdirectional fields from data relies on complex optimization procedures, whichare usually poorly formalizable, require a considerable computational effort,and do not transfer across applications. In this work, we propose a deeplearning-based approach and study the expressive power and generalizationability."
"461","arXiv:1907.00555","https://arxiv.org/abs/1907.00555","Parametric Verification: An Introduction","Étienne André, Michał Knapik, Didier Lime, Wojciech Penczek, Laure Petrucci","This paper constitutes a short introduction to parametric verification ofconcurrent systems. It originates from two 1-day tutorial sessions held at thePetri nets conferences in Toru\'n (2016) and Zaragoza (2017). The paperpresents not only the basic formal concepts tackled in the video version, butalso an extensive literature to provide the reader with further referencescovering the area.We first introduce motivation behind parametric verification in general, andthen focus on different models and approaches, for verifying several kinds ofsystems. They include Parametric Timed Automata, for modelling real-timesystems, where the timing constraints are not necessarily known a priori.Similarly, Parametric Interval Markov Chains allow for modelling systems whereprobabilities of events occurrences are intervals with parametric bounds.Parametric Petri Nets allow for compact representation of systems, and copewith different types of parameters. Finally, Action Synthesis aims at enablingor disabling actions in a concurrent system to guarantee some of itsproperties. Some tools implementing these approaches were used during hands-onsessions at the tutorial. The corresponding practicals are freely available onthe Web."
"462","arXiv:1907.00553","https://arxiv.org/abs/1907.00553","Model-free Friction Observers for Flexible Joint Robots with Torque  Measurements","Min Jun Kim, Fabian Beck, Christian Ott, Alin Albu-Schaeffer","This paper tackles a friction compensation problem without using a frictionmodel. The unique feature of the proposed friction observer is that the nominalmotor-side signal is fed back into the controller instead of the measuredsignal. By doing so, asymptotic stability and passivity of the controller aremaintained. Another advantage of the proposed observer is that it provides aclear understanding for the stiction compensation which is hard to be capturedin model-free approaches. This allows to design observers that do notovercompensate for the stiction. The proposed scheme is validated throughsimulations and experiments."
"463","arXiv:1907.00549","https://arxiv.org/abs/1907.00549","Spatio-thermal depth correction of RGB-D sensors based on Gaussian  Processes in real-time","Christoph Heindl, Thomas Pönitz, Gernot Stübl, Andreas Pichler, Josef Scharinger","Commodity RGB-D sensors capture color images along with dense pixel-wisedepth information in real-time. Typical RGB-D sensors are provided with afactory calibration and exhibit erratic depth readings due to coarsecalibration values, ageing and thermal influence effects. This limits theirapplicability in computer vision and robotics. We propose a novel method toaccurately calibrate depth considering spatial and thermal influences jointly.Our work is based on Gaussian Process Regression in a four dimensionalCartesian and thermal domain. We propose to leverage modern GPUs for densedepth map correction in real-time. For reproducibility we make our dataset andsource code publicly available."
"464","arXiv:1907.00544","https://arxiv.org/abs/1907.00544","Unsupervised Adversarial Graph Alignment with Graph Embedding","Chaoqi Chen, Weiping Xie, Tingyang Xu, Yu Rong, Wenbing Huang, Xinghao Ding, Yue Huang, Junzhou Huang","Graph alignment, also known as network alignment, is a fundamental task insocial network analysis. Many recent works have relied on partially labeledcross-graph node correspondences, i.e., anchor links. However, due to theprivacy and security issue, the manual labeling of anchor links for diversescenarios may be prohibitive. Aligning two graphs without any anchor links is acrucial and challenging task. In this paper, we propose an UnsupervisedAdversarial Graph Alignment (UAGA) framework to learn a cross-graph alignmentbetween two embedding spaces of different graphs in a fully unsupervisedfashion (\emph{i.e.,} no existing anchor links and no users' personal profileor attribute information is available). The proposed framework learns theembedding spaces of each graph, and then attempts to align the two spaces viaadversarial training, followed by a refinement procedure. We further extend ourUAGA method to incremental UAGA (iUAGA) that iteratively reveals the unobserveduser links based on the pseudo anchor links. This can be used to furtherimprove both the embedding quality and the alignment accuracy. Moreover, theproposed methods will benefit some real-world applications, \emph{e.g.,} linkprediction in social networks. Comprehensive experiments on real-world datademonstrate the effectiveness of our proposed approaches UAGA and iUAGA forunsupervised graph alignment."
"465","arXiv:1907.00542","https://arxiv.org/abs/1907.00542","Cosine similarity-based adversarial process","Hee-Soo Heo, Jee-weon Jung, Hye-jin Shim, IL-Ho Yang, Ha-Jin Yu","An adversarial process between two deep neural networks is a promisingapproach to train a robust model. In this paper, we propose an adversarialprocess using cosine similarity, whereas conventional adversarial processes arebased on inverted categorical cross entropy (CCE). When used for training anidentification model, the adversarial process induces the competition of twodiscriminative models; one for a primary task such as speaker identification orimage recognition, the other one for a subsidiary task such as channelidentification or domain identification. In particular, the adversarial processdegrades the performance of the subsidiary model by eliminating the subsidiaryinformation in the input which, in assumption, may degrade the performance ofthe primary model. The conventional adversarial processes maximize the CCE ofthe subsidiary model to degrade the performance. We have studied a frameworkfor training robust discriminative models by eliminating channel or domaininformation (subsidiary information) by applying such an adversarial process.However, we found through experiments that using the process of maximizing theCCE does not guarantee the performance degradation of the subsidiary model. Inthe proposed adversarial process using cosine similarity, on the contrary, theperformance of the subsidiary model can be degraded more efficiently bysearching feature space orthogonal to the subsidiary model. The experiments onspeaker identification and image recognition show that we found features thatmake the outputs of the subsidiary models independent of the input, and theperformances of the primary models are improved."
"466","arXiv:1907.00540","https://arxiv.org/abs/1907.00540","A Formal Approach for Efficient Navigation Management of Hybrid Electric  Vehicles on Long Trips","Mohammad Ashiqur Rahman, Md Hasan Shahriar, Ehab Al-Shaer, Quanyan Zhu","Plug-in Hybrid Electric Vehicles (PHEVs) are gaining popularity due to theireconomic efficiency as well as their contribution to green management. PHEVsallow the driver to use electric power exclusively for driving and then switchto gasoline as needed. The more gasoline a vehicle uses, the higher cost isrequired for the trip. However, a PHEV cannot last for a long period on storedelectricity without being recharged. Thus, it needs frequent rechargingcompared to traditional gasoline-powered vehicles. Moreover, the batteryrecharging time is usually long, which leads to longer delays on a trip.Therefore, it is necessary to provide a flexible navigation management schemealong with an efficient recharging schedule, which allows the driver to choosean optimal route based on the fuel-cost and time-to-destination constraints. Inthis paper, we present a formal model to solve this PHEV navigation managementproblem. The model is solved to provide a driver with a comprehensive routingplan including the potential recharging and refueling points that satisfy thegiven requirements, particularly the maximum fuel cost and the maximum triptime. In addition, we propose a price-based navigation control technique toachieve better load balance for the traffic system. Evaluation results showthat the proposed formal models can be solved efficiently even with large roadnetworks."
"467","arXiv:1907.00538","https://arxiv.org/abs/1907.00538","Beam Allocation for Millimeter-Wave MIMO Tracking Systems","Deyou Zhang, Ang Li, He Chen, Ning Wei, Ming Ding, Yonghui Li, Branka Vucetic","In this paper, we propose a new beam allocation strategy aiming to maximizethe average successful tracking probability (ASTP) of time-varyingmillimeter-wave MIMO systems. In contrast to most existing works that employone transmitting-receiving (Tx-Rx) beam pair once only in each training period,we investigate a more general framework, where the Tx-Rx beam pairs are allowedto be used repeatedly to improve the received signal powers in specificdirections. In the case of orthogonal Tx-Rx beam pairs, a power-based estimatoris employed to track the time-varying AoA and AoD of the channel, and theresulting training beam pair sequence design problem is formulated as aninteger nonlinear programming (I-NLP) problem. By dividing the feasible regioninto a set of subregions, the formulated I-NLP is decomposed into a series ofconcave sub I-NLPs, which can be solved by recursively invoking a nonlinearbranch-and-bound algorithm. To reduce the computational cost, we relax theinteger constraints of each sub I-NLP and obtain a low-complexity solution viasolving the Karush-Kuhn-Tucker conditions of their relaxed problems. For thecase when the Tx-Rx beam pairs are overlapped in the angular space, we estimatethe updated AoA and AoD via an orthogonal matching pursuit (OMP) algorithm.Moreover, since no explicit expression for the ASTP exists for the OMP-basedestimator, we derive a closed-form lower bound of the ASTP, based on which afavorable beam pair allocation strategy can be obtained. Numerical resultsdemonstrate the superiority of the proposed beam allocation strategy overexisting benchmarks."
"468","arXiv:1907.00537","https://arxiv.org/abs/1907.00537","Parametric Timed Model Checking for Guaranteeing Timed Opacity","Étienne André, Jun Sun","Information leakage can have dramatic consequences on systems security. Amongharmful information leaks, the timing information leakage is the ability for anattacker to deduce internal information depending on the system execution time.We address the following problem: given a timed system, synthesize theexecution times for which one cannot deduce whether the system performed somesecret behavior. We solve this problem in the setting of timed automata (TAs).We first provide a general solution, and then extend the problem to parametricTAs, by synthesizing internal timings making the TA secure. We studydecidability, devise algorithms, and show that our method can also apply toprogram analysis."
"469","arXiv:1907.00534","https://arxiv.org/abs/1907.00534","Large Area 3D Human Pose Detection Via Stereo Reconstruction in  Panoramic Cameras","Christoph Heindl, Thomas Pönitz, Andreas Pichler, Josef Scharinger","We propose a novel 3D human pose detector using two panoramic cameras. Weshow that transforming fisheye perspectives to rectilinear views allows adirect application of two-dimensional deep-learning pose estimation methods,without the explicit need for a costly re-training step to compensate forfisheye image distortions. By utilizing panoramic cameras, our method iscapable of accurately estimating human poses over a large field of view. Thisrenders our method suitable for ergonomic analyses and other pose basedassessments."
"470","arXiv:1907.00400","https://arxiv.org/abs/1907.00400","Prediction is very hard, especially about conversion. Predicting user  purchases from clickstream data in fashion e-commerce","Luca Bigon, Giovanni Cassani, Ciro Greco, Lucas Lacasa, Mattia Pavoni, Andrea Polonioli, Jacopo Tagliabue","Knowing if a user is a buyer vs window shopper solely based on clickstreamdata is of crucial importance for ecommerce platforms seeking to implementreal-time accurate NBA (next best action) policies. However, due to the lowfrequency of conversion events and the noisiness of browsing data, classifyinguser sessions is very challenging. In this paper, we address the clickstreamclassification problem in the fashion industry and present three majorcontributions to the burgeoning field of AI in fashion: first, we collected,normalized and prepared a novel dataset of live shopping sessions from a majorEuropean e-commerce fashion website; second, we use the dataset to test in acontrolled environment strong baselines and SOTA models from the literature;finally, we propose a new discriminative neural model that outperforms neuralarchitectures recently proposed at Rakuten labs."
"471","arXiv:1907.00533","https://arxiv.org/abs/1907.00533","Learning to Link","Maria-Florina Balcan, Travis Dick, Manuel Lang","Clustering is an important part of many modern data analysis pipelines,including network analysis and data retrieval. There are many differentclustering algorithms developed by various communities, and it is often notclear which algorithm will give the best performance on a specific clusteringtask. Similarly, we often have multiple ways to measure distances between datapoints, and the best clustering performance might require a non-trivialcombination of those metrics. In this work, we study data-driven algorithmselection and metric learning for clustering problems, where the goal is tosimultaneously learn the best algorithm and metric for a specific application.The family of clustering algorithms we consider is parameterized linkage basedprocedures that includes single and complete linkage. The family of distancefunctions we learn over are convex combinations of base distance functions. Wedesign efficient learning algorithms which receive samples from anapplication-specific distribution over clustering instances and simultaneouslylearn both a near-optimal distance and clustering algorithm from these classes.We also carry out a comprehensive empirical evaluation of our techniquesshowing that they can lead to significantly improved clustering performance."
"472","arXiv:1907.00531","https://arxiv.org/abs/1907.00531","Mismatched Guesswork","Salman Salamatian, Litian Liu, Ahmad Beirami, Muriel Médard","We study the problem of mismatched guesswork, where we evaluate the number ofsymbols $y \in \mathcal{Y}$ which have higher likelihood than $X \sim \mu$according to a mismatched distribution $\nu$. We discuss the role of thetilted/exponential families of the source distribution $\mu$ and of themismatched distribution $\nu$. We show that the value of guesswork can becharacterized using the tilted family of the mismatched distribution $\nu$,while the probability of guessing is characterized by an exponential familywhich passes through $\mu$. Using this characterization, we demonstrate thatthe mismatched guesswork follows a large deviation principle (LDP), where therate function is described implicitly using information theoretic quantities.We apply these results to one-to-one source coding (without prefix freeconstraint) to obtain the cost of mismatch in terms of average codeword length.We show that the cost of mismatch in one-to-one codes is no larger than that ofthe prefix-free codes, i.e., $D(\mu\| \nu)$. Further, the cost of mismatchvanishes if and only if $\nu$ lies on the tilted family of the truedistribution $\mu$, which is in stark contrast to the prefix-free codes. Theseresults imply that one-to-one codes are inherently more robust to mismatch."
"473","arXiv:1907.00529","https://arxiv.org/abs/1907.00529","Exponential-time quantum algorithms for graph coloring problems","Kazuya Shimizu, Ryuhei Mori","The fastest known classical algorithm deciding the $k$-colorability of$n$-vertex graph requires running time $\Omega(2^n)$ for $k\ge 5$. In thiswork, we present an exponential-space quantum algorithm computing the chromaticnumber with running time $O(1.9140^n)$ using quantum random access memory(QRAM). Our approach is based on Ambainis et al's quantum dynamic programmingwith applications of Grover's search to branching algorithms. We also present apolynomial-space quantum algorithm not using QRAM for the graph $20$-coloringproblem with running time $O(1.9575^n)$. In the polynomial-space quantumalgorithm, we essentially show $(4-\epsilon)^n$-time classical algorithms thatcan be improved quadratically by Grover's search."
"474","arXiv:1907.00528","https://arxiv.org/abs/1907.00528","Cross-view Relation Networks for Mammogram Mass Detection","Jiechao Ma, Sen Liang, Xiang Li, Hongwei Li, Bjoern H Menze, Rongguo Zhang, Wei-Shi Zheng","Mammogram is the most effective imaging modality for the mass lesiondetection of breast cancer at the early stage. The information from the twopaired views (i.e., medio-lateral oblique and cranio-caudal) are highlyrelational and complementary, and this is crucial for doctors' decisions inclinical practice. However, existing mass detection methods do not considerjointly learning effective features from the two relational views. To addressthis issue, this paper proposes a novel mammogram mass detection framework,termed Cross-View Relation Region-based Convolutional Neural Networks(CVR-RCNN). The proposed CVR-RCNN is expected to capture the latent relationinformation between the corresponding mass region of interests (ROIs) from thetwo paired views. Evaluations on a new large-scale private dataset and a publicmammogram dataset show that the proposed CVR-RCNN outperforms existingstate-of-the-art mass detection methods. Meanwhile, our experimental resultssuggest that incorporating the relation information across two views helps totrain a superior detection model, which is a promising avenue for mammogrammass detection."
"475","arXiv:1907.00527","https://arxiv.org/abs/1907.00527","Polar Codes with Memory","Wenyue Zhou, Qiang Liu, Yifei Shen, Xiaofeng Zhou, Chuan Zhang, Yaohua Xu, Liping Li","Polar codes with memory (PCM) are proposed in this paper: a pair ofconsecutive code blocks containing a controlled number of mutual informationbits. The shared mutual information bits of the succeeded block can help thefailed block to recover. The underlying polar codes can employ any decodingscheme such as the successive cancellation (SC) decoding (PCM-SC), the beliefpropagation (BP) decoding (PCM-BP), and the successive cancellation list (SCL)decoding (PCM-SCL). The analysis shows that the packet error rate (PER) of PCMdecreases to the order of PER squared while maintaining the same complexity asthe underlying polar codes. Simulation results indicate that for PCM-SC, thePER is comparable to (less than 0.3 dB) the stand-alone SCL decoding with twolists for the block length $N=256$. The PER of PCM-SCL with $L$ lists can matchthat of the stand-alone SCL decoding with $2L$ lists. Two hardware decoders forPCM are also implemented: the in-serial (IS) decoder and the low-latencyinterleaved (LLI) decoder. For $N=256$, synthesis results show that in theworst case, the latency of the PCM LLI decoder is only $16.1\%$ of the adaptiveSCL decoder with $L=2$, while the throughput is improved by 13 times comparedto it."
"476","arXiv:1907.00511","https://arxiv.org/abs/1907.00511","Automatic Real-time Anomaly Detection for Autonomous Aerial Vehicles","Azarakhsh Keipour, Mohammadreza Mousaei, Sebastian Scherer","The recent increase in the use of aerial vehicles raises concerns about thesafety and reliability of autonomous operations. There is a growing need formethods to monitor the status of these aircraft and report any faults andanomalies to the safety pilot or to the autopilot to deal with the emergencysituation. In this paper, we present a real-time approach using the RecursiveLeast Squares method to detect anomalies in the behavior of an aircraft. Themethod models the relationship between correlated input-output pairs online anduses the model to detect the anomalies. The result is an easy-to-deploy anomalydetection method that does not assume a specific aircraft model and can detectmany types of faults and anomalies in a wide range of autonomous aircraft. Theexperiments on this method show a precision of $88.23\%$, recall of $88.23\%$and $86.36\%$ accuracy for over 22 flight tests. The other contribution isproviding a new fault detection open dataset for autonomous aircraft, whichcontains complete data and the ground truth for 22 fixed-wing flights witheight different types of mid-flight actuator failures to help future faultdetection research for aircraft."
"477","arXiv:1907.00526","https://arxiv.org/abs/1907.00526","FiDi-RL: Incorporating Deep Reinforcement Learning with  Finite-Difference Policy Search for Efficient Learning of Continuous Control","Longxiang Shi, Shijian Li, Longbing Cao, Long Yang, Gang Zheng, Gang Pan","In recent years significant progress has been made in dealing withchallenging problems using reinforcement learning.Despite its great success,reinforcement learning still faces challenge in continuous control tasks.Conventional methods always compute the derivatives of the optimal goal with acostly computation resources, and are inefficient, unstable and lack ofrobust-ness when dealing with such tasks. Alternatively, derivative-basedmethods treat the optimization process as a blackbox and show robustness andstability in learning continuous control tasks, but not data efficient inlearning. The combination of both methods so as to get the best of the both hasraised attention. However, most of the existing combination works adopt complexneural networks (NNs) as the policy for control. The double-edged sword of deepNNs can yield better performance, but also makes it difficult for parametertuning and computation. To this end, in this paper we presents a novel methodcalled FiDi-RL, which incorporates deep RL with Finite-Difference (FiDi) policysearch.FiDi-RL combines Deep Deterministic Policy Gradients (DDPG)with AugmentRandom Search (ARS) and aims at improving the data efficiency of ARS. Theempirical results show that FiDi-RL can improves the performance and stabilityof ARS, and provide competitive results against some existing deepreinforcement learning methods"
"478","arXiv:1907.00524","https://arxiv.org/abs/1907.00524","Approximate $\mathbb{F}_2$-Sketching of Valuation Functions","Grigory Yaroslavtsev, Samson Zhou","We study the problem of constructing a linear sketch of minimum dimensionthat allows approximation of a given real-valued function $f \colon\mathbb{F}_2^n \rightarrow \mathbb R$ with small expected squared error. Wedevelop a general theory of linear sketching for such functions through whichwe analyze their dimension for most commonly studied types of valuationfunctions: additive, budget-additive, coverage, $\alpha$-Lipschitz submodularand matroid rank functions. This gives a characterization of how many bits ofinformation have to be stored about the input $x$ so that one can compute $f$under additive updates to its coordinates.Our results are tight in most cases and we also give extensions to thedistributional version of the problem where the input $x \in \mathbb{F}_2^n$ isgenerated uniformly at random. Using known connections with dynamic streamingalgorithms, both upper and lower bounds on dimension obtained in our workextend to the space complexity of algorithms evaluating $f(x)$ under longsequences of additive updates to the input $x$ presented as a stream. Similarresults hold for simultaneous communication in a distributed setting."
"479","arXiv:1907.00523","https://arxiv.org/abs/1907.00523","Geodesic Centroidal Voronoi Tessellations: Theories, Algorithms and  Applications","Zipeng Ye, Ran Yi, Minjing Yu, Yong-Jin Liu, Ying He","Nowadays, big data of digital media (including images, videos and 3Dgraphical models) are frequently modeled as low-dimensional manifold meshesembedded in a high-dimensional feature space. In this paper, we summarized ourrecent work on geodesic centroidal Voronoi tessellations(GCVTs), which areintrinsic geometric structures on manifold meshes. We show that GCVT can find awidely range of interesting applications in computer vision and graphics, dueto the efficiency of search, location and indexing inherent in these intrinsicgeometric structures. Then we present the challenging issues of how to buildthe combinatorial structures of GCVTs and establish their time and spacecomplexities, including both theoretical and algorithmic results."
"480","arXiv:1907.00520","https://arxiv.org/abs/1907.00520","Teach-Repeat-Replan: A Complete and Robust System for Aggressive Flight  in Complex Environments","Fei Gao, Luqi Wang, Boyu Zhou, Luxin Han, Jie Pan, Shaojie Shen","In this paper, we propose a complete and robust motion planning system forthe aggressive flight of autonomous quadrotors. The proposed method is builtupon on a classical teach-and-repeat framework, which is widely adopted ininfrastructure inspection, aerial transportation, and search-and-rescue. Forthese applications, human's intention is essential to decide the topologicalstructure of the flight trajectory of the drone. However, poor teachingtrajectories and changing environments prevent a simple teach-and-repeat systemfrom being applied flexibly and robustly. In this paper, instead of commandingthe drone to precisely follow a teaching trajectory, we propose a method toautomatically convert a human-piloted trajectory, which can be arbitrarilyjerky, to a topologically equivalent one. The generated trajectory isguaranteed to be smooth, safe, and kinodynamically feasible, with a humanpreferable aggressiveness. Also, to avoid unmapped or dynamic obstacles duringflights, a sliding-windowed local perception and re-planning method areintroduced to our system, to generate safe local trajectories onboard. We nameour system as teach-repeat-replan. It can capture users' intention of a flightmission, convert an arbitrarily jerky teaching path to a smooth repeatingtrajectory, and generate safe local re-plans to avoid unmapped or movingobstacles. The proposed planning system is integrated into a completeautonomous quadrotor with global and local perception and localizationsub-modules. Our system is validated by performing aggressive flights inchallenging indoor/outdoor environments. We release all components in ourquadrotor system as open-source ros-packages."
"481","arXiv:1907.00516","https://arxiv.org/abs/1907.00516","Learning to Blindly Assess Image Quality in the Laboratory and Wild","Weixia Zhang, Kede Ma, Xiaokang Yang","Previous models for blind image quality assessment (BIQA) can only be trained(or fine-tuned) on one subject-rated database due to the difficulty ofcombining multiple databases with different perceptual scales. As a result,models trained in a well-controlled laboratory environment with syntheticdistortions fail to generalize to realistic distortions, whose datadistribution is different. Similarly, models optimized for images captured inthe wild do not account for images simulated in the laboratory. Here wedescribe a simple technique of training BIQA models on multiple databasessimultaneously without additional subjective testing for scale realignment.Specifically, we first create and combine image pairs within individualdatabases, whose ground-truth binary labels are computed from the correspondingmean opinion scores, indicating which of the two images is of higher quality.We then train a deep neural network for BIQA by learning-to-rank massive suchimage pairs. Extensive experiments on six databases demonstrate that our BIQAmethod based on the proposed learning technique works well for both syntheticand realistic distortions, outperforming existing BIQA models with a single setof model parameters. The generalizability of our method is further verified bygroup maximum differentiation (gMAD) competition."
"482","arXiv:1907.00510","https://arxiv.org/abs/1907.00510","Hidden in Plain Sight For Too Long: Using Text Mining Techniques to  Shine a Light on Workplace Sexism and Sexual Harassment","Amir Karami, Suzanne C. Swan, Cynthia Nicole White, Kayla Ford","Objective: The goal of this study is to understand how people experiencesexism and sexual harassment in the workplace by discovering themes in 2,362experiences posted on the Everyday Sexism Project's website everydaysexism.com.Method: This study used both quantitative and qualitative methods. Thequantitative method was a computational framework to collect and analyze alarge number of workplace sexual harassment experiences. The qualitative methodwas the analysis of the topics generated by a text mining method. Results:Twenty-three topics were coded and then grouped into three overarching themesfrom the sex discrimination and sexual harassment literature. The SexDiscrimination theme included experiences in which women were treatedunfavorably due to their sex, such as being passed over for promotion, deniedopportunities, paid less than men, and ignored or talked over in meetings. TheSex Discrimination and Gender harassment theme included stories about sexdiscrimination and gender harassment, such as sexist hostility behaviorsranging from insults and jokes invoking misogynistic stereotypes to bullyingbehavior. The last theme, Unwanted Sexual Attention, contained storiesdescribing sexual comments and behaviors used to degrade women. Unwantedtouching was the highest weighted topic, indicating how common it was forwebsite users to endure being touched, hugged or kissed, groped, and grabbed.Conclusions: This study illustrates how researchers can use automatic processesto go beyond the limits of traditional research methods and investigatenaturally occurring large scale datasets on the internet to achieve a betterunderstanding of everyday workplace sexism experiences."
"483","arXiv:1907.00509","https://arxiv.org/abs/1907.00509","The Semantics of Rank Polymorphism","Justin Slepak, Olin Shivers, Panagiotis Manolios","Iverson's APL and its descendants (such as J, K and FISh) are examples of thefamily of ""rank-polymorphic"" programming languages. The principal controlmechanism of such languages is the general lifting of functions that operate onarrays of rank (or dimension) $r$ to operate on arrays of any higher rank $r' >r$. We present a core, functional language, Remora, that captures thismechanism, and develop both a formal, dynamic semantics for the language, andan accompanying static, rank-polymorphic type system for the language.Critically, the static semantics captures the shape-based lifting mechanism ofthe language. We establish the usual progress and preservation properties forthe type system, showing that it is sound, which means that ""array shape""errors cannot occur at run time in a well-typed program. Our type system usesdependent types, including an existential type abstraction which permitsprograms to operate on arrays whose shape or rank is computed dynamically;however, it is restricted enough to permit static type checking.The rank-polymorphic computational paradigm is unusual in that the types ofarguments affect the dynamic execution of the program -- they are what drivethe rank-polymorphic distribution of a function across arrays of higher rank.To highlight this property, we additionally present a dynamic semantics for apartially erased variant of the fully-typed language and show that acomputation performed with a fully-typed term stays in lock step with thecomputation performed with its partially erased term. The residual types thusprecisely characterise the type information that is needed by the dynamicsemantics, a property useful for the (eventual) construction of efficientcompilers for rank-polymorphic languages."
"484","arXiv:1907.00506","https://arxiv.org/abs/1907.00506","Toward Asymptotically-Optimal Inspection Planning via Efficient  Near-Optimal Graph Search","Mengyu Fu, Alan Kuntz, Oren Salzman, Ron Alterovitz","Inspection planning, the task of planning motions that allow a robot toinspect a set of points of interest, has applications in domains such asindustrial, field, and medical robotics. Inspection planning can becomputationally challenging, as the search space over motion plans that inspectthe points of interest grows exponentially with the number of inspected points.We propose a novel method, Incremental Random Inspection-roadmap Search (IRIS),that computes inspection plans whose length and set of inspected pointsasymptotically converge to those of an optimal inspection plan. IRISincrementally densifies a motion planning roadmap using sampling-basedalgorithms, and performs efficient near-optimal graph search over the resultingroadmap as it is generated. We demonstrate IRIS's efficacy on a simulatedplanar 5DOF manipulator inspection task and on a medical endoscopic inspectiontask for a continuum parallel surgical robot in anatomy segmented from patientCT data. We show that IRIS computes higher-quality inspection paths orders ofmagnitudes faster than a prior state-of-the-art method."
"485","arXiv:1907.00505","https://arxiv.org/abs/1907.00505","Few-Shot Representation Learning for Out-Of-Vocabulary Words","Ziniu Hu, Ting Chen, Kai-Wei Chang, Yizhou Sun","Existing approaches for learning word embeddings often assume there aresufficient occurrences for each word in the corpus, such that therepresentation of words can be accurately estimated from their contexts.However, in real-world scenarios, out-of-vocabulary (a.k.a. OOV) words that donot appear in training corpus emerge frequently. It is challenging to learnaccurate representations of these words with only a few observations. In thispaper, we formulate the learning of OOV embeddings as a few-shot regressionproblem, and address it by training a representation function to predict theoracle embedding vector (defined as embedding trained with abundantobservations) based on limited observations. Specifically, we propose a novelhierarchical attention-based architecture to serve as the neural regressionfunction, with which the context information of a word is encoded andaggregated from K observations. Furthermore, our approach can leverageModel-Agnostic Meta-Learning (MAML) for adapting the learned model to the newcorpus fast and robustly. Experiments show that the proposed approachsignificantly outperforms existing methods in constructing accurate embeddingsfor OOV words, and improves downstream tasks where these embeddings areutilized."
"486","arXiv:1907.00483","https://arxiv.org/abs/1907.00483","Effects of Foraging in Personalized Content-based Image Recommendation","Amit Kumar Jaiswal, Haiming Liu, Ingo Frommholz","A major challenge of recommender systems is to help users locatinginteresting items. Personalized recommender systems have become very popular asthey attempt to predetermine the needs of users and provide them withrecommendations to personalize their navigation. However, few studies haveaddressed the question of what drives the users' attention to specific contentwithin the collection and what influences the selection of interesting items.To this end, we employ the lens of Information Foraging Theory (IFT) to imagerecommendation to demonstrate how the user could utilize visual bookmarks tolocate interesting images. We investigate a personalized content-based imagerecommendation system to understand what affects user attention by reinforcingvisual attention cues based on IFT. We further find that visual bookmarks(cues) lead to a stronger scent of the recommended image collection. Ourevaluation is based on the Pinterest image collection."
"487","arXiv:1907.00504","https://arxiv.org/abs/1907.00504","Joint User Mobility and Traffic Characterization in Temporary Crowded  Events","Adriano Valadar, Eduardo Nuno Almeida, Jorge Mamede","In TCEs (Temporary Crowded Events), for example, music festivals, users arefaced with problems accessing the Internet. TCEs are limited time events with ahigh concentration of people moving within the event enclosure while accessingthe Internet. Unlike other events where the user locations are constant andknown at the start (e.g. stadiums), the traffic generation and the usermovement in TCEs is variable and influenced by the dynamics of the event. Themovement of users can lead to overloads in APs (Access Point) in case they arefixed. In order to minimize this phenomenon, new techniques have been exploredthat resort to the adjustable positioning of APs integrated into UAVs (UnmannedAerial Vehicles). In these scenarios, the dynamic of the location of the APsrequires that tools of prediction of the users movements and, in turn, of thesources of traffic, gain particular expression when being related to thealgorithms of positioning of the referred APs. In order to allow thedevelopment and analysis of new network planning solutions for TCEs, it isnecessary to recreate these scenarios in simulation, which, in turn, requires adetailed characterization of this kind of events. This article aims tocharacterize and model the mobility and traffic generated by users in TCEs.This characterization will enable the development of new statistical models oftraffic generation and user mobility in TCEs."
"488","arXiv:1907.00503","https://arxiv.org/abs/1907.00503","Modeling Tabular data using Conditional GAN","Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan Veeramachaneni","Modeling the probability distribution of rows in tabular data and generatingrealistic synthetic data is a non-trivial task. Tabular data usually contains amix of discrete and continuous columns. Continuous columns may have multiplemodes whereas discrete columns are sometimes imbalanced making the modelingdifficult. Existing statistical and deep neural network models fail to properlymodel this type of data. We design TGAN, which uses a conditional generativeadversarial network to address these challenges. To aid in a fair and thoroughcomparison, we design a benchmark with 7 simulated and 8 real datasets andseveral Bayesian network baselines. TGAN outperforms Bayesian methods on mostof the real datasets whereas other deep learning methods could not."
"489","arXiv:1907.00501","https://arxiv.org/abs/1907.00501","Deep Residual Neural Networks for Audio Spoofing Detection","Moustafa Alzantot, Ziqi Wang, Mani B. Srivastava","The state-of-art models for speech synthesis and voice conversion are capableof generating synthetic speech that is perceptually indistinguishable frombonafide human speech. These methods represent a threat to the automaticspeaker verification (ASV) systems. Additionally, replay attacks where theattacker uses a speaker to replay a previously recorded genuine human speechare also possible. We present our solution for the ASVSpoof2019 competition,which aims to develop countermeasure systems that distinguish between spoofingattacks and genuine speeches. Our model is inspired by the success of residualconvolutional networks in many classification tasks. We build three variants ofa residual convolutional neural network that accept different featurerepresentations (MFCC, Log-magnitude STFT, and CQCC) of input. We compare theperformance achieved by our model variants and the competition baseline models.In the logical access scenario, the fusion of our models has zero t-DCF costand zero equal error rate (EER), as evaluated on the development set. On theevaluation set, our model fusion improves the t-DCF and EER by 25% compared tothe baseline algorithms. Against physical access replay attacks, our modelfusion improves the baseline algorithms t-DCF and EER scores by 71% and 75% onthe evaluation set, respectively."
"490","arXiv:1907.00498","https://arxiv.org/abs/1907.00498","Proof of Witness Presence: Blockchain Consensus for Augmented Democracy  in Smart Cities","Evangelos Pournaras","Smart City data intensive urban environments are becoming highly complex andevolving by the digital transformation. Repositioning the democratic values ofcitizens' choices in these complex ecosystems has turned out to be imperativein an era of social media filter bubbles, fake news and opportunities formanipulating electoral results with such means. This paper introduces a newparadigm of augmented democracy that promises citizens who actively engage in amore informed decision-making integrated in public urban space. The proposedconcept is inspired by a digital revive of the Ancient Agora of Greece, anarena of public discourse, a Polis where citizens assemble to activelydeliberate and collectively decide about public matters. At the core of theproposed paradigm lies the concept of proving witness presence that makesdecision-making subject of providing evidence and testifying for choices madein the physical space. This paper shows how proofs of witness presence can bemade using blockchain consensus. It also shows how complex crowd-sensingdecision-making processes can be designed with the Smart Agora platform and howreal-time collective measurements can be performed in a fully decentralized andprivacy-preserving way. An experimental testnet scenario on sustainable use oftransport means is illustrated. The paramount role of dynamic consensus,self-governance and ethically aligned artificial intelligence in the augmenteddemocracy paradigm is outlined."
"491","arXiv:1907.00494","https://arxiv.org/abs/1907.00494","The University of Sydney's Machine Translation System for WMT19","Liang Ding, Dacheng Tao","This paper describes the University of Sydney's submission of the WMT 2019shared news translation task. We participated in theFinnish$\rightarrow$English direction and got the best BLEU(33.0) score amongall the participants. Our system is based on the self-attentional Transformernetworks, into which we integrated the most recent effective strategies fromacademic research (e.g., BPE, back translation, multi-features data selection,data augmentation, greedy model ensemble, reranking, ConMBR system combination,and post-processing). Furthermore, we propose a novel augmentation method$Cycle Translation$ and a data mixture strategy $Big$/$Small$ parallelconstruction to entirely exploit the synthetic corpus. Extensive experimentsshow that adding the above techniques can make continuous improvements of theBLEU scores, and the best result outperforms the baseline (Transformer ensemblemodel trained with the original parallel corpus) by approximately 5.3 BLEUscore, achieving the state-of-the-art performance."
"492","arXiv:1907.00475","https://arxiv.org/abs/1907.00475","Genus 2 Supersingular Isogeny Oblivious Transfer","Ramsès Fernàndez-València","We present an oblivious transfer scheme that extends the proposal made byBarreto, Oliveira and Benits, based in isogenies supersingular elliptic curves,to the setting of principally polarized supersingular abelian surfaces."
"493","arXiv:1907.00490","https://arxiv.org/abs/1907.00490","ICDAR 2019 Competition on Scene Text Visual Question Answering","Ali Furkan Biten, Rubèn Tito, Andres Mafla, Lluis Gomez, Marçal Rusiñol, Minesh Mathew, C.V. Jawahar, Ernest Valveny, Dimosthenis Karatzas","This paper presents final results of ICDAR 2019 Scene Text Visual QuestionAnswering competition (ST-VQA). ST-VQA introduces an important aspect that isnot addressed by any Visual Question Answering system up to date, namely theincorporation of scene text to answer questions asked about an image. Thecompetition introduces a new dataset comprising 23,038 images annotated with31,791 question/answer pairs where the answer is always grounded on textinstances present in the image. The images are taken from 7 different publiccomputer vision datasets, covering a wide range of scenarios.The competition was structured in three tasks of increasing difficulty, thatrequire reading the text in a scene and understanding it in the context of thescene, to correctly answer a given question. A novel evaluation metric ispresented, which elegantly assesses both key capabilities expected from anoptimal model: text recognition and image understanding.A detailed analysis of results from different participants is showcased,which provides insight into the current capabilities of VQA systems that canread. We firmly believe the dataset proposed in this challenge will be animportant milestone to consider towards a path of more robust and generalmodels that can exploit scene text to achieve holistic image understanding."
"494","arXiv:1907.00489","https://arxiv.org/abs/1907.00489","Improving LSTM Neural Networks for Better Short-Term Wind Power  Predictions","Maximilian Du","This paper introduces an improved method of wind power prediction via weatherforecast-contextualized Long Short- Term Memory Neural Network (LSTM) models.Wind power and weather forecast data were acquired from open-source databasesand combined. However, a generic LSTM model performs poorly on this data, witherratic behavior observed on even low-variance data sections. To address thisissue, LSTM modifications were proposed and tested for accuracy through both aNormalized Mean Absolute Error and the Naive Ratio, which is a score introducedby this paper to quantify unwanted ""naive"" model behavior. Results showed anincrease in model accuracy with the addition of weather forecast data to themodels, as well as major improvements in performance with some modelmodifications, which are attributed to the increased contextualization andstability of the new models. These new and improved models have the potentialto improve power grid stability and expedite renewable power integration."
"495","arXiv:1907.00488","https://arxiv.org/abs/1907.00488","Topic Modeling the Reading and Writing Behavior of Information Foragers","Jaimie Murdock","The general problem of ""information foraging"" in an environment about whichagents have incomplete information has been explored in many fields, includingcognitive psychology, neuroscience, economics, finance, ecology, and computerscience. In all of these areas, the searcher aims to enhance future performanceby surveying enough of existing knowledge to orient themselves in theinformation space. Individuals can be viewed as conducting a cognitive searchin which they must balance exploration of ideas that are novel to them againstexploitation of knowledge in domains in which they are already expert.In this dissertation, I present several case studies that demonstrate howreading and writing behaviors interact to construct personal knowledge bases.These studies use LDA topic modeling to represent the information environmentof the texts each author read and wrote. Three studies revolve around CharlesDarwin. Darwin left detailed records of every book he read for 23 years, fromdisembarking from the H.M.S. Beagle to just after publication of The Origin ofSpecies. Additionally, he left copies of his drafts before publication. Icharacterize his reading behavior, then show how that reading behaviorinteracted with the drafts and subsequent revisions of The Origin of Species,and expand the dataset to include later readings and writings. Then, through astudy of Thomas Jefferson's correspondence, I expand the study to non-bookdata. Finally, through an examination of neuroscience citation data, I movefrom individual behavior to collective behavior in constructing an informationenvironment. Together, these studies reveal ""the interplay between individualand collective phenomena where innovation takes place"" (Tria et al. 2014)."
"496","arXiv:1907.00485","https://arxiv.org/abs/1907.00485","Robust and Resource Efficient Identification of Two Hidden Layer Neural  Networks","Massimo Fornasier, Timo Klock, Michael Rauchensteiner","We address the structure identification and the uniform approximation of twofully nonlinear layer neural networks of the type $f(x)=1^T h(B^T g(A^T x))$ on$\mathbb R^d$ from a small number of query samples. We approach the problem bysampling actively finite difference approximations to Hessians of the network.Gathering several approximate Hessians allows reliably to approximate thematrix subspace $\mathcal W$ spanned by symmetric tensors $a_1 \otimes a_1,\dots,a_{m_0}\otimes a_{m_0}$ formed by weights of the first layer togetherwith the entangled symmetric tensors $v_1 \otimes v_1 ,\dots,v_{m_1}\otimesv_{m_1}$, formed by suitable combinations of the weights of the first andsecond layer as $v_\ell=A G_0 b_\ell/\|A G_0 b_\ell\|_2$, $\ell \in [m_1]$, fora diagonal matrix $G_0$ depending on the activation functions of the firstlayer. The identification of the 1-rank symmetric tensors within $\mathcal W$is then performed by the solution of a robust nonlinear program. We provideguarantees of stable recovery under a posteriori verifiable conditions. Wefurther address the correct attribution of approximate weights to the first orsecond layer. By using a suitably adapted gradient descent iteration, it ispossible then to estimate, up to intrinsic symmetries, the shifts of theactivations functions of the first layer and compute exactly the matrix $G_0$.Our method of identification of the weights of the network is fullyconstructive, with quantifiable sample complexity, and therefore contributes todwindle the black-box nature of the network training phase. We corroborate ourtheoretical results by extensive numerical experiments."
"497","arXiv:1907.00484","https://arxiv.org/abs/1907.00484","Bayesian Generalized Network Design","Yuval Emek, Shay Kutten, Ron Lavi, Yangguang Shi","We study network coordination problems, as captured by the setting ofgeneralized network design (Emek et al., STOC 2018), in the face of uncertaintyresulting from partial information that the network users hold regarding theactions of their peers. This uncertainty is formalized using Alon et al.'sBayesian ignorance framework (TCS 2012). While the approach of Alon et al. ispurely combinatorial, the current paper takes into account computationalconsiderations: Our main technical contribution is the development of(strongly) polynomial time algorithms for local decision making in the face ofBayesian uncertainty."
"498","arXiv:1907.00482","https://arxiv.org/abs/1907.00482","Base Station Antenna Selection for Low-Resolution ADC Systems","Jinseok Choi, Junmo Sung, Narayan Prasad, Xiao-Feng Qi, Brian L. Evans, Alan Gatherer","This paper investigates antenna selection at a base station with largeantenna arrays and low-resolution analog-to-digital converters. For downlinktransmit antenna selection for narrowband channels, we show (1) a selectioncriterion that maximizes sum rate with zero-forcing precoding equivalent tothat of a perfect quantization system; (2) maximum sum rate increases withnumber of selected antennas; (3) derivation of the sum rate loss function fromusing a subset of antennas; and (4) unlike high-resolution converter systems,sum rate loss reaches a maximum at a point of total transmit power anddecreases beyond that point to converge to zero. For widebandorthogonal-frequency-division-multiplexing (OFDM) systems, our results holdwhen entire subcarriers share a common subset of antennas. For uplink receiveantenna selection for narrowband channels, we (1) generalize a greedy antennaselection criterion to capture tradeoffs between channel gain and quantizationerror; (2) propose a quantization-aware fast antenna selection algorithm usingthe criterion; and (3) derive a lower bound on sum rate achieved by theproposed algorithm based on submodular functions. For wideband OFDM systems, weextend our algorithm and derive a lower bound on its sum rate. Simulationresults validate theoretical analyses and show increases in sum rate overconventional algorithms."
"499","arXiv:1907.00481","https://arxiv.org/abs/1907.00481","Mincut pooling in Graph Neural Networks","Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi","The advance of node pooling operations in a Graph Neural Network (GNN) haslagged behind the feverish design of new graph convolution techniques, andpooling remains an important and challenging endeavor for the design of deeparchitectures. In this paper, we propose a pooling operation for GNNs thatimplements a differentiable unsupervised loss based on the mincut optimizationobjective. First, we validate the effectiveness of the proposed loss functionby clustering nodes in citation networks and through visualization examples,such as image segmentation. Then, we show how the proposed pooling layer can beused to build a deep GNN architecture for graph classification."
"500","arXiv:1907.00480","https://arxiv.org/abs/1907.00480","Predicting video saliency using crowdsourced mouse-tracking data","Vitaliy Lyudvichenko, Dmitriy Vatolin","This paper presents a new way of getting high-quality saliency maps forvideo, using a cheaper alternative to eye-tracking data. We designed amouse-contingent video viewing system which simulates the viewers' peripheralvision based on the position of the mouse cursor. The system enables the use ofmouse-tracking data recorded from an ordinary computer mouse as an alternativeto real gaze fixations recorded by a more expensive eye-tracker. We developed acrowdsourcing system that enables the collection of such mouse-tracking data atlarge scale. Using the collected mouse-tracking data we showed that it canserve as an approximation of eye-tracking data. Moreover, trying to increasethe efficiency of collected mouse-tracking data we proposed a novel deep neuralnetwork algorithm that improves the quality of mouse-tracking saliency maps."
"501","arXiv:1907.00479","https://arxiv.org/abs/1907.00479","(""Oops! Had the silly thing in reverse"")---Optical injection attacks in  through LED status indicators","Joe Loughry","It is possible to attack a computer remotely through the front panel LEDs.Following on previous results that showed information leakage at opticalwavelengths, now it seems practicable to inject information into a system aswell. It is shown to be definitely feasible under realistic conditions (byinfosec standards) of target system compromise; experimental results suggest itfurther may be possible, through a slightly different mechanism, even underhigh security conditions that put extremely difficult constraints on theattacker. The problem is of recent origin; it could not have occurred before aconfluence of unrelated technological developments made it possible.Arduino-type microcontrollers are involved; this is an Internet of Things (IoT)vulnerability. Unlike some previous findings, the vulnerability here ismoderate---at present---because it takes the infosec form of a classical covertchannel. However, the architecture of several popular families ofmicrocontrollers suggests that a Rowhammer-like directed energy optical attackthat requires no malware might be possible. Phase I experiments yieldedsurprising and encouraging results; a covert channel is definitely practicablewithout exotic hardware, bandwidth approaching a Mbit/s, and the majority ofdiscrete LEDs tested were found to be reversible on GPIO pins. Phase IIexperiments, not yet funded, will try to open the door remotely."
"502","arXiv:1907.00478","https://arxiv.org/abs/1907.00478","Indoor positioning system using WLAN channel estimates as fingerprints  for mobile devices","Erick Schmidt, David Akopian","With the growing integration of location based services (LBS) such as GPS inmobile devices, indoor position systems (IPS) have become an important role forresearch. There are several IPS methods such as AOA, TOA, TDOA, which usetrilateration for indoor location estimation but are generally based online-of-sight. Other methods rely on classification such as fingerprintingwhich uses WLAN indoor signals. This paper re-examines the classical WLANfingerprinting accuracy which uses received signal strength (RSS) measurementsby introducing channel estimates for improvements in the classification ofindoor locations. The purpose of this paper is to improve existingclassification algorithms used in fingerprinting by introducing channelestimates when there are a low number of APs available. The channel impulseresponse, or in this case the channel estimation from the receiver, shouldcharacterize a complex indoor area which usually has multipath, thus providinga unique signature for each location which proves useful for better patternrecognition. In this experiment, channel estimates are extracted from aSoftware-Defined Radio (SDR) environment, thus exploiting the benefits of SDRfrom a NI-USRP model and LabVIEW software. Measurements are taken from a knownbuilding, and several scenarios with one and two access points (APs) are usedin this experiment. Also, three granularities in distance between locations areanalyzed. A Support Vector Machine (SVM) is used as the algorithm for patternrecognition of different locations based on the samples taken from RSS andchannel estimation coefficients."
"503","arXiv:1907.00477","https://arxiv.org/abs/1907.00477","Analyzing Utility of Visual Context in Multimodal Speech Recognition  Under Noisy Conditions","Tejas Srinivasan, Ramon Sanabria, Florian Metze","Multimodal learning allows us to leverage information from multiple sources(visual, acoustic and text), similar to our experience of the real world.However, it is currently unclear to what extent auxiliary modalities improveperformance over unimodal models, and under what circumstances the auxiliarymodalities are useful. We examine the utility of the auxiliary visual contextin Multimodal Automatic Speech Recognition in adversarial settings, where wedeprive the models from partial audio signal during inference time. Ourexperiments show that while MMASR models show significant gains overtraditional speech-to-text architectures (upto 4.2% WER improvements), they donot incorporate visual information when the audio signal has been corrupted.This shows that current methods of integrating the visual modality do notimprove model robustness to noise, and we need better visually groundedadaptation techniques."
"504","arXiv:1907.00468","https://arxiv.org/abs/1907.00468","A Fast-rate WLAN Measurement Tool for Improved Miss-rate in Indoor  Navigation","Erick Schmidt, David Akopian","Recently, location-based services (LBS) have steered attention to indoorpositioning systems (IPS). WLAN-based IPSs relying on received signal strength(RSS) measurements such as fingerprinting are gaining popularity due to provenhigh accuracy of their results. Typically, sets of RSS measurements at selectedlocations from several WLAN access points (APs) are used to calibrate thesystem. Retrieval of such measurements from WLAN cards are commonly at one-Hzrate. Such measurement collection is needed for offline radio-map surveyingstage which aligns fingerprints to locations, and for online navigation stage,when collected measurements are associated with the radio-map for usernavigation. As WLAN network is not originally designed for positioning, an RSSmeasurement miss could have a high impact on the fingerprinting system.Additionally, measurement fluctuations require laborious signal processing, andsurveying process can be very time consuming. This paper proposes a fast-ratemeasurement collection method that addresses previously mentioned problems byachieving a higher probability of RSS measurement collection during a givenone-second window. This translates to more data for statistical processing andfaster surveying. The fast-rate collection approach is analyzed against theconventional measurement rate in a proposed testing methodology that mimicsreal-life scenarios related to IPS surveying and online navigation."
"505","arXiv:1907.00467","https://arxiv.org/abs/1907.00467","Typed lambda-calculi and superclasses of regular functions","Lê Thành Dũng Nguyên","We propose to use Church encodings in typed lambda-calculi as the basis foran automata-theoretic counterpart of implicit computational complexity, in thesame way that monadic second-order logic provides a counterpart to descriptivecomplexity. Specifically, we look at transductions i.e. string-to-string (ortree-to-tree) functions - in particular those with superlinear growth, such aspolyregular functions, HDT0L transductions and S\'enizergues's ""k-computablemappings"".Our first results towards this aim consist showing the inclusion of sometransduction classes in some classes defined by lambda-calculi. In particular,this sheds light on a basic open question on the expressivity of the simplytyped lambda-calculus. We also encode regular functions (and, by changing thetype of programs considered, we get a larger subclass of polyregular functions)in the elementary affine lambda-calculus, a variant of linear logic originallydesigned for implicit computational complexity."
"506","arXiv:1907.00464","https://arxiv.org/abs/1907.00464","Merge and Label: A novel neural network architecture for nested NER","Joseph Fisher, Andreas Vlachos","Named entity recognition (NER) is one of the best studied tasks in naturallanguage processing. However, most approaches are not capable of handlingnested structures which are common in many applications. In this paper weintroduce a novel neural network architecture that first merges tokens and/orentities into entities forming nested structures, and then labels each of themindependently. Unlike previous work, our merge and label approach predictsreal-valued instead of discrete segmentation structures, which allow it tocombine word and nested entity embeddings while maintaining differentiability.%which smoothly groups entities into single vectors across multiple levels. Weevaluate our approach using the ACE 2005 Corpus, where it achievesstate-of-the-art F1 of 74.6, further improved with contextual embeddings (BERT)to 82.4, an overall improvement of close to 8 F1 points over previousapproaches trained on the same data. Additionally we compare it againstBiLSTM-CRFs, the dominant approach for flat NER structures, demonstrating thatits ability to predict nested structures does not impact performance in simplercases."
"507","arXiv:1907.00462","https://arxiv.org/abs/1907.00462","Inter and Intra Document Attention for Depression Risk Assessment","Diego Maupomé, Marc Queudot, Marie-Jean Meurs","We take interest in the early assessment of risk for depression in socialmedia users. We focus on the eRisk 2018 dataset, which represents users as asequence of their written online contributions. We implement four RNN-basedsystems to classify the users. We explore several aggregations methods tocombine predictions on individual posts. Our best model reads through allwritings of a user in parallel but uses an attention mechanism to prioritizethe most important ones at each timestep."
"508","arXiv:1907.00459","https://arxiv.org/abs/1907.00459","N-Person Discrete-Time Dynamic Games of Asymmetric Information","Linan Huang, Quanyan Zhu","This paper considers a class of N-person discrete-time dynamic games with anasymmetric information structure. Each player has private information revealedonly to himself, which is modeled as a random variable called the type. Eachplayer aims to find an optimal feedback control policy to reach the desiredstate while minimizing the control cost without exact knowledge of the systemdynamics. Players can form a belief on the unknowns based on the observation ofthe state trajectory and update it via the Bayesian rule to learn the typevalue of other players. To deal with the uncertainty caused by the privateinformation, each player forms his control policy under the expectation of thetype belief, which forms the perfect Bayesian Nash equilibrium (PBNE). Thestrong coupling of the type estimation and the control policy establishes noseparation principle in our non-classical information structure. In particular,we investigate the linear-quadratic setting, and we obtain generalized Riccatiequations and an affine state-feedback PBNE policy. Moreover, we show that thePBNE policy is unique if it exists and is strongly time consistent. Finally, wenumerically illustrate the proposed framework with a case study."
"509","arXiv:1907.00457","https://arxiv.org/abs/1907.00457","Contextual Phonetic Pretraining for End-to-end Utterance-level Language  and Speaker Recognition","Shaoshi Ling, Julian Salazar, Katrin Kirchhoff","Pretrained contextual word representations in NLP have greatly improvedperformance on various downstream tasks. For speech, we propose contextualframe representations that capture phonetic information at the acoustic framelevel and can be used for utterance-level language, speaker, and speechrecognition. These representations come from the frame-wise intermediaterepresentations of an end-to-end, self-attentive ASR model (SAN-CTC) on spokenutterances. We first train the model on the Fisher English corpus withcontext-independent phoneme labels, then use its representations at inferencetime as features for task-specific models on the NIST LRE07 closed-set languagerecognition task and a Fisher speaker recognition task, giving significantimprovements over the state-of-the-art on both (e.g., language EER of 4.68% on3sec utterances, 23% relative reduction in speaker EER). Results remaincompetitive when using a novel dilated convolutional model for languagerecognition, or when ASR pretraining is done with character labels only."
"510","arXiv:1907.00456","https://arxiv.org/abs/1907.00456","Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human  Preferences in Dialog","Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson, Agata Lapedriza, Noah Jones, Shixiang Gu, Rosalind Picard","Most deep reinforcement learning (RL) systems are not able to learneffectively from off-policy data, especially if they cannot explore online inthe environment. These are critical shortcomings for applying RL to real-worldproblems where collecting data is expensive, and models must be tested offlinebefore being deployed to interact with the environment -- e.g. systems thatlearn from human interaction. Thus, we develop a novel class of off-policybatch RL algorithms, which are able to effectively learn offline, withoutexploring, from a fixed batch of human interaction data. We leverage modelspre-trained on data as a strong prior, and use KL-control to penalizedivergence from this prior during RL training. We also use dropout-baseduncertainty estimates to lower bound the target Q-values as a more efficientalternative to Double Q-Learning. The algorithms are tested on the problem ofopen-domain dialog generation -- a challenging reinforcement learning problemwith a 20,000-dimensional action space. Using our Way Off-Policy algorithm, wecan extract multiple different reward functions post-hoc from collected humaninteraction data, and learn effectively from all of these. We test thereal-world generalization of these systems by deploying them live to conversewith humans in an open-domain setting, and demonstrate that our algorithmachieves significant improvements over prior methods in off-policy batch RL."
"511","arXiv:1907.00455","https://arxiv.org/abs/1907.00455","Multiplicative Models for Recurrent Language Modeling","Diego Maupomé, Marie-Jean Meurs","Recently, there has been interest in multiplicative recurrent neural networksfor language modeling. Indeed, simple Recurrent Neural Networks (RNNs)encounter difficulties recovering from past mistakes when generating sequencesdue to high correlation between hidden states. These challenges can bemitigated by integrating second-order terms in the hidden-state update. Onesuch model, multiplicative Long Short-Term Memory (mLSTM) is particularlyinteresting in its original formulation because of the sharing of itssecond-order term, referred to as the intermediate state. We explore thesearchitectural improvements by introducing new models and testing them oncharacter-level language modeling tasks. This allows us to establish therelevance of shared parametrization in recurrent language modeling."
"512","arXiv:1907.00452","https://arxiv.org/abs/1907.00452","Detecting Spiky Corruption in Markov Decision Processes","Jason Mancuso, Tomasz Kisielewski, David Lindner, Alok Singh","Current reinforcement learning methods fail if the reward function isimperfect, i.e. if the agent observes reward different from what it actuallyreceives. We study this problem within the formalism of Corrupt Reward MarkovDecision Processes (CRMDPs). We show that if the reward corruption in a CRMDPis sufficiently ""spiky"", the environment is solvable. We fully characterize theregret bound of a Spiky CRMDP, and introduce an algorithm that is able todetect its corrupt states. We show that this algorithm can be used to learn theoptimal policy with any common reinforcement learning algorithm. Finally, weinvestigate our algorithm in a pair of simple gridworld environments, findingthat our algorithm can detect the corrupt states and learn the optimal policydespite the corruption."
"513","arXiv:1907.00450","https://arxiv.org/abs/1907.00450","Discrete Event Simulation of Driver's Routing Behavior Rule at a Road  Intersection","Ben Benzaman, Erfan Pakdamanian","Several factors influence traffic congestion and overall traffic dynamics.Simulation modeling has been utilized to understand the traffic performanceparameters during traffic congestions. This paper focuses on driver behavior ofroute selection by differentiating three distinguishable decisions, which areshortest distance routing, shortest time routing and less crowded road routing.This research generated 864 different scenarios to capture various trafficdynamics under collective driving behavior of route selection. Factors such asvehicle arrival rate, behaviors at system boundary and traffic light phasingwere considered. The simulation results revealed that shortest time routingscenario offered the best solution considering all forms of interactions amongthe factors. Overall, this routing behavior reduces traffic wait time and totaltime (by 69.5% and 65.72%) compared to shortest distance routing."
"514","arXiv:1907.00448","https://arxiv.org/abs/1907.00448","Self-Supervised Dialogue Learning","Jiawei Wu, Xin Wang, William Yang Wang","The sequential order of utterances is often meaningful in coherent dialogues,and the order changes of utterances could lead to low-quality and incoherentconversations. We consider the order information as a crucial supervised signalfor dialogue learning, which, however, has been neglected by many previousdialogue systems. Therefore, in this paper, we introduce a self-supervisedlearning task, inconsistent order detection, to explicitly capture the flow ofconversation in dialogues. Given a sampled utterance pair triple, the task isto predict whether it is ordered or misordered. Then we propose asampling-based self-supervised network SSN to perform the prediction withsampled triple references from previous dialogue history. Furthermore, wedesign a joint learning framework where SSN can guide the dialogue systemstowards more coherent and relevant dialogue learning through adversarialtraining. We demonstrate that the proposed methods can be applied to bothopen-domain and task-oriented dialogue scenarios, and achieve the newstate-of-the-art performance on the OpenSubtitiles and Movie-Ticket Bookingdatasets."
"515","arXiv:1907.00443","https://arxiv.org/abs/1907.00443","Multilingual Bottleneck Features for Query by Example Spoken Term  Detection","Dhananjay Ram, Lesly Miculicich, Hervé Bourlard","State of the art solutions to query by example spoken term detection(QbE-STD) usually rely on bottleneck feature representation of the query andaudio document to perform dynamic time warping (DTW) based template matching.Here, we present a study on QbE-STD performance using several monolingual aswell as multilingual bottleneck features extracted from feed forward networks.Then, we propose to employ residual networks (ResNet) to estimate thebottleneck features and show significant improvements over the correspondingfeed forward network based features. The neural networks are trained onGlobalPhone corpus and QbE-STD experiments are performed on a very challengingQUESST 2014 database."
"516","arXiv:1907.00440","https://arxiv.org/abs/1907.00440","The Prager-Synge theorem in reconstruction based a posteriori error  estimation","Fleurianne Bertrand, Daniele Boffi","In this paper we review the hypercircle method of Prager and Synge. Thistheory inspired several studies and induced an active research in the area of aposteriori error analysis. In particular, we review the Braess--Sch\""oberlerror estimator in the context of the Poisson problem. We discuss adaptivefinite element schemes based on two variants of the estimator and we prove theconvergence and optimality of the resulting algorithms."
"517","arXiv:1907.00437","https://arxiv.org/abs/1907.00437","INN: Inflated Neural Networks for IPMN Diagnosis","Rodney LaLonde, Irene Tanner, Katerina Nikiforaki, Georgios Z. Papadakis, Pujan Kandel, Candice W. Bolan, Michael B. Wallace, Ulas Bagci","Intraductal papillary mucinous neoplasm (IPMN) is a precursor to pancreaticductal adenocarcinoma. While over half of patients are diagnosed withpancreatic cancer at a distant stage, patients who are diagnosed early enjoy amuch higher 5-year survival rate of $34\%$ compared to $3\%$ in the former;hence, early diagnosis is key. Unique challenges in the medical imaging domainsuch as extremely limited annotated data sets and typically large 3D volumetricdata have made it difficult for deep learning to secure a strong foothold. Inthis work, we construct two novel ""inflated"" deep network architectures,$\textit{InceptINN}$ and $\textit{DenseINN}$, for the task of diagnosing IPMNfrom multisequence (T1 and T2) MRI. These networks inflate their 2D layers to3D and bootstrap weights from their 2D counterparts (Inceptionv3 andDenseNet121 respectively) trained on ImageNet to the new 3D kernels. We alsoextend the inflation process by further expanding the pre-trained kernels tohandle any number of input modalities and different fusion strategies. This isone of the first studies to train an end-to-end deep network on multisequenceMRI for IPMN diagnosis, and shows that our proposed novel inflated networkarchitectures are able to handle the extremely limited training data (139 MRIscans), while providing an absolute improvement of $8.76\%$ in accuracy fordiagnosing IPMN over the current state-of-the-art. Code is publicly availableat https://github.com/lalonderodney/INN-Inflated-Neural-Nets."
"518","arXiv:1907.00435","https://arxiv.org/abs/1907.00435","YouTube Chatter: Understanding Online Comments Discourse on  Misinformative and Political YouTube Videos","Aarash Heydari, Janny Zhang, Shaan Appel, Xinyi Wu, Gireeja Ranade","We conduct a preliminary analysis of comments on political YouTube contentcontaining misinformation in comparison to comments on trustworthy orapolitical videos, labelling the bias and factual ratings of our channelsaccording to Media Bias Fact Check where applicable. One of our mostinteresting discoveries is that especially-polarized or misinformativepolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,and Questionable Source) generate 7.5x more comments per view and 10.42x morereplies per view than apolitical or Pro-Science channels; in particular,Conspiracy-Pseudoscience and Questionable Sources generate 8.3x more commentsper view and 11.0x more replies per view than apolitical and Pro-Sciencechannels. We also compared average thread lengths, average comment lengths, andprofanity rates across channels, and present simple machine learningclassifiers for predicting the bias category of a video based on thesestatistics."
"519","arXiv:1907.00434","https://arxiv.org/abs/1907.00434","Network-accelerated Distributed Machine Learning Using MLFabric","Raajay Viswanathan, Aditya Akella","Existing distributed machine learning (DML) systems focus on improving thecomputational efficiency of distributed learning, whereas communication aspectshave received less attention. Many DML systems treat the network as a blackbox.Thus, DML algorithms' performance is impeded by network bottlenecks, and DMLsystems end up sacrificing important algorithmic and system-level benefits. Wepresent MLfabric, a communication library that manages all network transfers ina DML system, and holistically determines the communication pattern of a DMLalgorithm at any point in time. This allows MLfabric to carefully ordertransfers (i.e., gradient updates) to improve convergence, opportunisticallyaggregate updates in-network to improve efficiency, and proactively replicatesome of them to support new notions of fault tolerance. We empirically findthat MLfabric achieves up to 3X speed-up in training large deep learning modelsin realistic dynamic cluster settings."
"520","arXiv:1907.00430","https://arxiv.org/abs/1907.00430","Requisite Variety in Ethical Utility Functions for AI Value Alignment","Nadisha-Marie Aliman, Leon Kester","Being a complex subject of major importance in AI Safety research, valuealignment has been studied from various perspectives in the last years.However, no final consensus on the design of ethical utility functionsfacilitating AI value alignment has been achieved yet. Given the urgency toidentify systematic solutions, we postulate that it might be useful to startwith the simple fact that for the utility function of an AI not to violatehuman ethical intuitions, it trivially has to be a model of these intuitionsand reflect their variety $ - $ whereby the most accurate models pertaining tohuman entities being biological organisms equipped with a brain constructingconcepts like moral judgements, are scientific models. Thus, in order to betterassess the variety of human morality, we perform a transdisciplinary analysisapplying a security mindset to the issue and summarizing variety-relevantbackground knowledge from neuroscience and psychology. We complement thisinformation by linking it to augmented utilitarianism as a suitable ethicalframework. Based on that, we propose first practical guidelines for the designof approximate ethical goal functions that might better capture the variety ofhuman moral judgements. Finally, we conclude and address future possiblechallenges."
"521","arXiv:1907.00429","https://arxiv.org/abs/1907.00429","Machine Learning for Intelligent Authentication in 5G-and-Beyond  Wireless Networks","He Fang, Xianbin Wang, Stefano Tomasin","The fifth generation (5G) and beyond wireless networks are critical tosupport diverse vertical applications by connecting heterogeneous devices andmachines, which directly increase vulnerability for various spoofing attacks.Conventional cryptographic and physical layer authentication techniques arefacing some challenges in complex dynamic wireless environments, includingsignificant security overhead, low reliability, as well as difficulty inpre-designing authentication model, providing continuous protections, andlearning time-varying attributes. In this article, we envision newauthentication approaches based on machine learning techniques byopportunistically leveraging physical layer attributes, and introduceintelligence to authentication for more efficient security provisioning.Machine learning paradigms for intelligent authentication design are presented,namely for parametric/non-parametric and supervised/unsupervised/reinforcementlearning algorithms. In a nutshell, the machine learning-based intelligentauthentication approaches utilize specific features in the multi-dimensionaldomain for achieving cost-effective, more reliable, model-free, continuous andsituation-aware device validation under unknown network conditions andunpredictable dynamics."
"522","arXiv:1907.00428","https://arxiv.org/abs/1907.00428","Connecting edge-colouring","Jørgen Bang-Jensen, Thomas Bellitto, Anders Yeo","This paper studies the problem of connecting edge-colouring. Given anundirected connected graph, our aim is to colour its edges with as few coloursas possible so that there exists a properly coloured walk between every pair ofvertices of the graph i.e. a walk that does not use consecutively two edges ofthe same colour. We establish that the problem can be solved in polynomial timein the size of the graph and we provide a characterization of the graphs thatcan be properly connected with $k$ colours for every possible value of $k$."
"523","arXiv:1907.00422","https://arxiv.org/abs/1907.00422","Dedicated Lane for Connected and Automated Vehicle: How Much Does A  Homogeneous Traffic Flow Contribute?","Zijia Zhong, Joyoung Lee","Dedicated lanes for connected and automated vehicles (CAVs) can not onlyprovide the technological accommodation, but also the desired market incentivefor road user to adapt CAVs. Thus far, the majority of the impact assessment ofCAV focused on the network-wide benefits. In this paper, we investigate thechange of the traffic flow characteristic with two configurations of dedicatedCAV lane across levels of market penetration. The traffic flow characteristicsare quantified from the perspectives of headway distribution, communicationdensity, and speed-flow diagram. The results highlight the contributions of theCAV lane. First, CAV lanes significantly improves the speed-flowcharacteristics by extending the stable region of the speed-flow curve andyielding a greater optimum flow. The highest value of optimum flow is 3400vehicle per lane per hour at 90% MPR with one CAV lane. Furthermore, theconcentration of CAVs at a lane results a narrower headway distribution (withsmaller standard deviation), even with partial market penetration. Moreover,the CAV lane creates a more consistent CAV density which maintains thecommunication density level at a predictable level, hence decreasing theprobability of packet drop."
"524","arXiv:1907.00421","https://arxiv.org/abs/1907.00421","A Sound Algorithm for Asynchronous Session Subtyping (extended version)","Mario Bravetti, Marco Carbone, Julien Lange, Nobuko Yoshida, Gianluigi Zavattaro","Session types, types for structuring communication between endpoints indistributed systems, are recently being integrated into mainstream programminglanguages. In practice, a very important notion for dealing with such types isthat of subtyping, since it allows for typing larger classes of system, where aprogram has not precisely the expected behavior but a similar one.Unfortunately, recent work has shown that subtyping for session types in anasynchronous setting is undecidable. To cope with this negative result, theonly approaches we are aware of either restrict the syntax of session types orlimit communication (by considering forms of bounded asynchrony). Bothapproaches are too restrictive in practice, hence we proceed differently bypresenting an algorithm for checking subtyping which is sound, but not complete(in some cases it terminates without returning a decisive verdict). Thealgorithm is based on a tree representation of the coinductive definition ofasynchronous subtyping; this tree could be infinite, and the algorithm checksfor the presence of finite witnesses of infinite successful subtrees.Furthermore, we provide a tool that implements our algorithm and we apply it tomany examples that cannot be managed with the previous approaches."
"525","arXiv:1907.00420","https://arxiv.org/abs/1907.00420","Multi-Label Product Categorization Using Multi-Modal Fusion Models","Pasawee Wirojwatanakul, Artit Wangperawong","In this study, we investigated multi-modal approaches using images,descriptions, and title to categorize e-commerce products on Amazon.com.Specifically, we examined late fusion models, where the modalities are fused atthe decision level. Products were each assigned multiple labels, and thehierarchy in the labels were flattened and filtered. For our individualbaseline models, we modified a CNN architecture to classify the description andtitle, and then modified Keras' ResNet-50 to classify the images, achieving F1scores of 77.0%, 82.7%, and 61.0%, respectively. In comparison, our tri-modallate fusion model can classify products more accurately than single modalmodels can, improving the F1 score to 88.2%. Each modality complemented theshortcomings of the other modalities, demonstrating that increasing the numberof modalities can be an effective method for improving the accuracy ofmulti-label classification problems."
"526","arXiv:1907.00409","https://arxiv.org/abs/1907.00409","Evaluating Language Model Finetuning Techniques for Low-resource  Languages","Jan Christian Blaise Cruz, Charibeth Cheng","Unlike mainstream languages (such as English and French), low-resourcelanguages often suffer from a lack of expert-annotated corpora and benchmarkresources that make it hard to apply state-of-the-art techniques directly. Inthis paper, we alleviate this scarcity problem for the low-resourced Filipinolanguage in two ways. First, we introduce a new benchmark language modelingdataset in Filipino which we call WikiText-TL-39. Second, we show that languagemodel finetuning techniques such as BERT and ULMFiT can be used to consistentlytrain robust classifiers in low-resource settings, experiencing at most a0.0782 increase in validation error when the number of training examples isdecreased from 10K to 1K while finetuning using a privately-held sentimentdataset."
"527","arXiv:1907.00408","https://arxiv.org/abs/1907.00408","GarmNet: Improving Global with Local Perception for Robotic Laundry  Folding","Daniel Fernandes Gomes, Shan Luo, Luis F. Teixeira","Developing autonomous assistants to help with domestic tasks is a vital topicin robotics research. Among these tasks, garment folding is one of them that isstill far from being achieved mainly due to the large number of possibleconfigurations that a crumpled piece of clothing may exhibit. Research has beendone on either estimating the pose of the garment as a whole or detecting thelandmarks for grasping separately. However, such works constrain the capabilityof the robots to perceive the states of the garment by limiting therepresentations for one single task. In this paper, we propose a novelend-to-end deep learning model named GarmNet that is able to simultaneouslylocalize the garment and detect landmarks for grasping. The localization of thegarment represents the global information for recognising the category of thegarment, whereas the detection of landmarks can facilitate subsequent graspingactions. We train and evaluate our proposed GarmNet model using the CloPeMaGarment dataset that contains 3,330 images of different garment types indifferent poses. The experiments show that the inclusion of landmark detection(GarmNet-B) can largely improve the garment localization, with an error rate of24.7% lower. Solutions as ours are important for robotics applications, asthese offer scalable to many classes, memory and processing efficientsolutions."
"528","arXiv:1907.00406","https://arxiv.org/abs/1907.00406","Higher-order time-stepping schemes for fluid-structure interaction  problems","Daniele Boffi, Lucia Gastaldi, Sebastian Wolf","We consider a recently introduced formulation for fluid-structure interactionproblems which makes use of a distributed Lagrange multiplier in the spirit ofthe fictitious domain method. In this paper we focus on time integrationmethods of second order based on backward differentiation formulae and on theCrank-Nicolson method. We show the stability properties of the resultingmethod; numerical tests confirm the theoretical results."
"529","arXiv:1907.00397","https://arxiv.org/abs/1907.00397","Variational Quantum Circuits and Deep Reinforcement Learning","Samuel Yen-Chi Chen, Hsi-Sheng Goan","Recently, machine learning has prevailed in many academia and industrialapplications. At the same time, quantum computing, once seen as not realizable,has been brought to markets by several tech giants. However, these machines arenot fault-tolerant and can not execute very deep circuits. Therefore, it isurgent to design suitable algorithms and applications implementable on thesemachines. In this work, we demonstrate a novel approach which appliesvariational quantum circuits to deep reinforcement learning. With the proposedmethod, we can implement famous deep reinforcement learning algorithms such asexperience replay and target network with variational quantum circuits. In thisframework, with appropriate information encoding scheme, the possible quantumadvantage is the number of circuit parameters with $poly(\log{} N)$ compared to$poly(N)$ in conventional neural network where $N$ is the dimension of inputvectors. Such an approach can be deployed on near-term noisy intermediate-scalequantum machines."
"530","arXiv:1907.00393","https://arxiv.org/abs/1907.00393","On the Sample Complexity of HGR Maximal Correlation Functions","Shao-Lun Huang, Xiangxiang Xu","The Hirschfeld-Gebelein-R\'{e}nyi (HGR) maximal correlation and thecorresponding functions have been shown useful in many machine learningscenarios. In this paper, we study the sample complexity of estimating the HGRmaximal correlation functions by the alternative conditional expectation (ACE)algorithm from a sequence of training data in the asymptotic regime.Specifically, we develop a mathematical framework to characterize the learningerrors between the maximal correlation functions computed from the truedistribution, and the functions estimated from the ACE algorithm. For bothsupervised and semi-supervised learning scenarios, we establish the analyticalexpressions for the error exponents of the learning errors, which indicate thenumber of training samples required for estimating the HGR maximal correlationfunctions by the ACE algorithm. Moreover, with our theoretical results, weinvestigate the sampling strategy for different types of samples insemi-supervised learning with a total sampling budget constraint, and anoptimal sampling strategy is developed to maximize the error exponent of thelearning error. Finally, the numerical simulations are presented to support ourtheoretical results."
"531","arXiv:1907.00391","https://arxiv.org/abs/1907.00391","E2E Delay Guarantee for the Tactile Internet via joint NFV and Radio  Resource Allocation","Narges Gholipoor, Hamid Saeedi, Nader Mokari, Eduard Jorswieck","The Tactile Internet (TI) is one of the next generation wireless networkservices with end to end (E2E) delay as low as 1~ms. Since this ultra low E2Edelay cannot be met in the current 4G network architecture, it is necessary toinvestigate this service in the next generation wireless network by consideringnew technologies such as network function virtualization (NFV). On the otherhand, given the importance of E2E delay in the TI service, it is crucial toconsider the delay of all parts of the network, including the radio access partand the NFV core part. In this paper, for the first time, we investigate thejoint radio resource allocation (R-RA) and NFV resource allocation (NFV-RA) ina heterogeneous network where queuing delays, transmission delays, and delaysresulting from virtual network function (VNF) execution are jointly considered.For this setup, we formulate a new resource allocation (RA) problem to minimizethe total cost function subject to guaranteeing E2E delay of each user. Sincethe proposed optimization problem is highly non-convex, we exploit alternativesearch method (ASM), successive convex approximation (SCA), and heuristicalgorithms to solve it. Simulation results reveal that in the proposed schemecan significantly reduce the network costs compared to the case where the twoproblems are optimized separately."
"532","arXiv:1907.00390","https://arxiv.org/abs/1907.00390","A Novel Bi-directional Interrelated Model for Joint Intent Detection and  Slot Filling","Haihong E, Peiqing Niu, Zhongfu Chen, Meina Song","A spoken language understanding (SLU) system includes two main tasks, slotfilling (SF) and intent detection (ID). The joint model for the two tasks isbecoming a tendency in SLU. But the bi-directional interrelated connectionsbetween the intent and slots are not established in the existing joint models.In this paper, we propose a novel bi-directional interrelated model for jointintent detection and slot filling. We introduce an SF-ID network to establishdirect connections for the two tasks to help them promote each other mutually.Besides, we design an entirely new iteration mechanism inside the SF-ID networkto enhance the bi-directional interrelated connections. The experimentalresults show that the relative improvement in the sentence-level semantic frameaccuracy of our model is 3.79% and 5.42% on ATIS and Snips datasets,respectively, compared to the state-of-the-art model."
"533","arXiv:1907.00388","https://arxiv.org/abs/1907.00388","Reinforcement Learning for Robotic Time-optimal Path Tracking Using  Prior Knowledge","Jiadong Xiao, Lin Li, Yanbiao Zou, Tie Zhang","Time-optimal path tracking, as a significant tool for industrial robots, hasattracted the attention of numerous researchers. In most time-optimal pathtracking problems, the actuator torque constraints are assumed to beconservative, which ignores the motor characteristic; i.e., the actuator torqueconstraints are velocity-dependent, and the relationship between torque andvelocity is piecewise linear. However, considering that the motorcharacteristics increase the solving difficulty, in this study, an improvedQ-learning algorithm for robotic time-optimal path tracking using priorknowledge is proposed. After considering the limitations of the Q-learningalgorithm, an improved action-value function is proposed to improve theconvergence rate. The proposed algorithms use the idea of reward and penalty,rewarding the actions that satisfy constraint conditions and penalizing theactions that break constraint conditions, to finally obtain a time-optimaltrajectory that satisfies the constraint conditions. The effectiveness of thealgorithms is verified by experiments."
"534","arXiv:1907.00386","https://arxiv.org/abs/1907.00386","Study of Rate-Splitting Techniques with Block Diagonalization for  Multiuser MIMO Systems","A. Flores, R. C. de Lamare","In this work, we investigate Block Diagonalization (BD) techniques formultiuser multiple-antenna systems using rate-splitting (RS) multiple access.In RS multiple access the messages of the users are split into a common partand a private part in order to mitigate multiuser interference. We present thesystem model for a RS multiple access system operating in a broadcast channelscenario where the receivers are equipped with multiple antennas. We alsodevelop linear precoders based on BD for the RS multiple access systems alongwith combining techniques, such as the min-max criterion and the maximum ratiocombining criterion, to enhance the common rate. Closed-form expressions todescribe the sum rate performance of the proposed scheme are also derived. Theperformance of the system is evaluated via simulations considering imperfectchannel state information at the transmitter. The results show that theproposed schemes outperform conventional linear precoding methods."
"535","arXiv:1907.00382","https://arxiv.org/abs/1907.00382","Adversarially Trained Deep Neural Semantic Hashing Scheme for Subjective  Search in Fashion Inventory","Saket Singh, Debdoot Sheet, Mithun Dasgupta","The simple approach of retrieving a closest match of a query image from onein the gallery, compares an image pair using sum of absolute difference inpixel or feature space. The process is computationally expensive, ill-posed toillumination, background composition, pose variation, as well as inefficient tobe deployed on gallery sets with more than 1000 elements. Hashing is a fasteralternative which involves representing images in reduced dimensional simplefeature spaces. Encoding images into binary hash codes enables similaritycomparison in an image-pair using the Hamming distance measure. The challenge,however, lies in encoding the images using a semantic hashing scheme that letssubjective neighbors lie within the tolerable Hamming radius. This workpresents a solution employing adversarial learning of a deep neural semantichashing network for fashion inventory retrieval. It consists of a featureextracting convolutional neural network (CNN) learned to (i) minimize error inclassifying type of clothing, (ii) minimize hamming distance between semanticneighbors and maximize distance between semantically dissimilar images, (iii)maximally scramble a discriminator's ability to identify the corresponding hashcode-image pair when processing a semantically similar query-gallery imagepair. Experimental validation for fashion inventory search yields a meanaverage precision (mAP) of 90.65% in finding the closest match as compared to53.26% obtained by the prior art of deep Cauchy hashing for hamming spaceretrieval."
"536","arXiv:1907.00378","https://arxiv.org/abs/1907.00378","Nearest-Neighbour-Induced Isolation Similarity and Its Impact on  Density-Based Clustering","Xiaoyu Qin, Kai Ming Ting, Ye Zhu, Vincent CS Lee","A recent proposal of data dependent similarity called IsolationKernel/Similarity has enabled SVM to produce better classification accuracy. Weidentify shortcomings of using a tree method to implement Isolation Similarity;and propose a nearest neighbour method instead. We formally prove thecharacteristic of Isolation Similarity with the use of the proposed method. Theimpact of Isolation Similarity on density-based clustering is studied here. Weshow for the first time that the clustering performance of the classicdensity-based clustering algorithm DBSCAN can be significantly uplifted tosurpass that of the recent density-peak clustering algorithm DP. This isachieved by simply replacing the distance measure with the proposednearest-neighbour-induced Isolation Similarity in DBSCAN, leaving the rest ofthe procedure unchanged. A new type of clusters called mass-connected clustersis formally defined. We show that DBSCAN, which detects density-connectedclusters, becomes one which detects mass-connected clusters, when the distancemeasure is replaced with the proposed similarity. We also provide the conditionunder which mass-connected clusters can be detected, while density-connectedclusters cannot."
"537","arXiv:1907.00377","https://arxiv.org/abs/1907.00377","FVA: Modeling Perceived Friendliness of Virtual Agents Using Movement  Characteristics","Tanmay Randhavane, Aniket Bera, Kyra Kapsaskis, Kurt Gray, Dinesh Manocha","We present a new approach for improving the friendliness and warmth of avirtual agent in an AR environment by generating appropriate movementcharacteristics. Our algorithm is based on a novel data-driven friendlinessmodel that is computed using a user-study and psychological characteristics. Weuse our model to control the movements corresponding to the gaits, gestures,and gazing of friendly virtual agents (FVAs) as they interact with the user'savatar and other agents in the environment. We have integrated FVA agents withan AR environment using with a Microsoft HoloLens. Our algorithm can generateplausible movements at interactive rates to increase the social presence. Wealso investigate the perception of a user in an AR setting and observe that anFVA has a statistically significant improvement in terms of the perceivedfriendliness and social presence of a user compared to an agent without thefriendliness modeling. We observe an increment of 5.71% in the mean responsesto a friendliness measure and an improvement of 4.03% in the mean responses toa social presence measure."
"538","arXiv:1907.00376","https://arxiv.org/abs/1907.00376","On the Fault Proneness of SonarQube Technical Debt Violations: A  comparison of eight Machine Learning Techniques","Valentina Lenarduzzi, Francesco Lomio, Davide Taibi, Heikki Huttunen","Background. The popularity of tools for analyzing Technical Debt, andparticularly that of SonarQube, is increasing rapidly. SonarQube proposes a setof coding rules, which represent something wrong in the code that will soon bereflected in a fault or will increase maintenance effort. However, while themanagement of some companies is encouraging developers not to violate theserules in the first place and to produce code below a certain technical debtthreshold, developers are skeptical of their importance. Objective. In order tounderstand which SonarQube violations are actually fault-prone and to analyzethe accuracy of the fault-prediction model, we designed and conducted anempirical study on 21 well-known mature open-source projects. Method. Weapplied the SZZ algorithm to label the fault-inducing commits. We compared theclassification power of eight Machine Learning models (Logistic Regression,Decision Tree, Random Forest, Extremely Randomized Trees, AdaBoost, GradientBoosting, XGBoost) to obtain a set of violations that are correlated withfault-inducing commits. Finally, we calculated the percentage of violationsintroduced in the fault-inducing commit and removed in the fault-fixing commit,so as to reduce the risk of spurious correlations. Result. Among the 202violations defined for Java by SonarQube, only 26 have a relatively lowfault-proneness. Moreover, violations classified as ''bugs'' by SonarQubehardly never become a failure. Consequently, the accuracy of thefault-prediction power proposed by SonarQube is extremely low. Conclusion. Therules applied by SonarQube for calculating technical debt should be thoroughlyinvestigated and their harmfulness needs to be further confirmed. Therefore,companies should carefully consider which rules they really need to apply,especially if their goal is to reduce fault-proneness."
"539","arXiv:1907.00374","https://arxiv.org/abs/1907.00374","Fooling a Real Car with Adversarial Traffic Signs","Nir Morgulis, Alexander Kreines, Shachar Mendelowitz, Yuval Weisglass","The attacks on the neural-network-based classifiers using adversarial imageshave gained a lot of attention recently. An adversary can purposely generate animage that is indistinguishable from a innocent image for a human being but isincorrectly classified by the neural networks. The adversarial images do notneed to be tuned to a particular architecture of the classifier - an image thatfools one network can fool another one with a certain success rate.Thepublished works mostly concentrate on the use of modified image files forattacks against the classifiers trained on the model databases. Although thereexists a general understanding that such attacks can be carried in the realworld as well, the works considering the real-world attacks are scarce.Moreover, to the best of our knowledge, there have been no reports on theattacks against real production-grade image classification systems.In our workwe present a robust pipeline for reproducible production of adversarial trafficsigns that can fool a wide range of classifiers, both open-source andproduction-grade in the real world. The efficiency of the attacks was checkedboth with the neural-network-based classifiers and legacy computer visionsystems. Most of the attacks have been performed in the black-box mode, e.g.the adversarial signs produced for a particular classifier were used to attacka variety of other classifiers. The efficiency was confirmed in drive-byexperiments with a production-grade traffic sign recognition systems of a realcar."
"540","arXiv:1907.00366","https://arxiv.org/abs/1907.00366","An Enhanced Electrocardiogram Biometric Authentication System Using  Machine Learning","Ebrahim Al Alkeem, Song-Kyoo Kim, Chan Yeob Yeun, M. Jamal Zemerly, Kin Poon, Paul D. Yoo","Traditional authentication systems use alphanumeric or graphical passwords,or token-based techniques that require ""something you know and something youhave"". The disadvantages of these systems include the risks of forgetfulness,loss, and theft. To address these shortcomings, biometric authentication israpidly replacing traditional authentication methods and is becoming aneveryday part of life. The electrocardiogram (ECG) is one of the most recenttraits considered for biometric purposes, and three typical use cases have beendescribed: security checks, hospitals and wearable devices. Here we describe anECG-based authentication system suitable for security checks and hospitalenvironments. The proposed authentication system will help investigatorsstudying ECG-based biometric authentication techniques to define datasetboundaries and to acquire high-quality training data. We evaluated theperformance of the proposed system using a confusion matrix and also byapplying the Amang ECG (amgecg) toolbox in MATLAB to investigate two parametersthat directly affect the accuracy of authentication: the ECG slicing time(sliding window) and sampling time. Using this approach, we found that accuracywas optimized by using a sliding window of 0.4 s and a sampling time of 37 s."
"541","arXiv:1907.00365","https://arxiv.org/abs/1907.00365","Spatial Coded Modulation","Junshan Luo, Shilian Wang, Fanggang Wang","In this paper, we propose a spatial coded modulation (SCM) scheme, whichimproves the accuracy of the active antenna detection by coding over thetransmit antennas. Specifically, the antenna activation pattern in the SCMcorresponds to a codeword in a properly designed codebook with a larger minimumHamming distance than its counterpart conventional spatial modulation. As theminimum Hamming distance increases, the reliability of the active antennadetection is directly enhanced, which in turn improves the demodulation of themodulated symbols and yields a better system reliability. In addition to thereliability, the proposed SCM scheme also achieves a higher capacity with theidentical antenna configuration compared to the conventional spatial modulationtechnique. Moreover, the proposed SCM scheme strikes a balance between spectralefficiency and reliability by trading off the minimum Hamming distance with thenumber of available codewords. The optimal maximum likelihood detector is firstformulated. Then, a low-complexity suboptimal detector is proposed to reducethe computational complexity, which has a two-step detection. Theoreticalderivations of the channel capacity and the bit error rate are presented invarious channel scenarios, i.e., Rayleigh, Rician, Nakagami-m, imperfectchannel state information, and spatial correlation. Further derivation onperformance bounding is also provided to reveal the insight of the benefit ofincreasing the minimum Hamming distance. Numerical results validate theanalysis and demonstrate that the proposed SCM outperforms the conventionalspatial modulation techniques in both channel capacity and system reliability."
"542","arXiv:1907.00359","https://arxiv.org/abs/1907.00359","Rough concepts","Willem Conradie, Sabine Frittella, Krishna Manoorkar, Sajad Nazari, Alessandra Palmigiano, Apostolos Tzimoulis, Nachoem M. Wijnberg","The present paper proposes a novel way to unify Rough Set Theory and FormalConcept Analysis. Our method stems from results and insights developed in thealgebraic theory of modal logic, and is based on the idea that Pawlak'soriginal approximation spaces can be seen as special instances of enrichedformal contexts, i.e. relational structures based on formal contexts fromFormal Concept Analysis."
"543","arXiv:1907.00354","https://arxiv.org/abs/1907.00354","Difficulty-aware Meta-Learning for Rare Disease Diagnosis","Xiaomeng Li, Lequan Yu, Chi-Wing Fu, Pheng-Ann Heng","Rare diseases have extremely low-data regimes, unlike common diseases withlarge amount of available labeled data. Hence, to train a neural network toclassify rare diseases with a few per-class data samples is very challenging,and so far, catches very little attention. In this paper, we present adifficulty-aware meta-learning method to address rare disease classificationsand demonstrate its capability to classify dermoscopy images. Our key approachis to first train and construct a meta-learning model from data of commondiseases, then adapt the model to perform rare disease classification.Toachieve this, we develop the difficulty-aware meta-learning method thatdynamically monitors the importance of learning tasks during themeta-optimization stage. To evaluate our method, we use the recent ISIC 2018skin lesion classification dataset, and show that with only five samples perclass, our model can quickly adapt to classify unseen classes by a high AUC of83.3%. Also, we evaluated several rare disease classification results in thepublic Dermofit Image Library to demonstrate the potential of our method forreal clinical practice."
"544","arXiv:1907.00350","https://arxiv.org/abs/1907.00350","Random Vector Functional Link Neural Network based Ensemble Deep  Learning","Rakesh Katuwal, P.N. Suganthan, M. Tanveer","In this paper, we propose a deep learning framework based on randomizedneural network. In particular, inspired by the principles of Random VectorFunctional Link (RVFL) network, we present a deep RVFL network (dRVFL) withstacked layers. The parameters of the hidden layers of the dRVFL are randomlygenerated within a suitable range and kept fixed while the output weights arecomputed using the closed form solution as in a standard RVFL network. We alsopropose an ensemble deep network (edRVFL) that can be regarded as a marriage ofensemble learning with deep learning. Unlike traditional ensembling approachesthat require training several models independently from scratch, edRVFL isobtained by training a single dRVFL network once. Both dRVFL and edRVFLframeworks are generic and can be used with any RVFL variant. To illustratethis, we integrate the deep learning networks with a recently proposedsparse-pretrained RVFL (SP-RVFL). Extensive experiments on benchmark datasetsfrom diverse domains show the superior performance of our proposed deep RVFLnetworks."
"545","arXiv:1907.00349","https://arxiv.org/abs/1907.00349","A multiscale reduced basis method for Schrödinger equation with  multiscale and random potentials","Jingrun Chen, Dingjiong Ma, Zhiwen Zhang","The semiclassical Schr\""{o}dinger equation with multiscale and randompotentials often appears when studying electron dynamics in heterogeneousquantum systems. As time evolves, the wavefunction develops high-frequencyoscillations in both the physical space and the random space, which posessevere challenges for numerical methods. In this paper, we propose a multiscalereduced basis method, where we construct multiscale reduced basis functionsusing an optimization method and the proper orthogonal decomposition method inthe physical space and employ the quasi-Monte Carlo method in the random space.Our method is verified to be efficient: the spatial gridsize is onlyproportional to the semiclassical parameter and the number of samples in therandom space is inversely proportional to the same parameter. Severaltheoretical aspects of the proposed method, including how to determine thenumber of samples in the construction of multiscale reduced basis andconvergence analysis, are studied with numerical justification. In addition, weinvestigate the Anderson localization phenomena for Schr\""{o}dinger equationwith correlated random potentials in both 1D and 2D."
"546","arXiv:1907.00348","https://arxiv.org/abs/1907.00348","Learning to Find Correlated Features by Maximizing Information Flow in  Convolutional Neural Networks","Wei Shen, Fei Li, Rujie Liu","Training convolutional neural networks for image classification tasks usuallycauses information loss. Although most of the time the information lost isredundant with respect to the target task, there are still cases wherediscriminative information is also discarded. For example, if the samples thatbelong to the same category have multiple correlated features, the model mayonly learn a subset of the features and ignore the rest. This may not be aproblem unless the classification in the test set highly depends on the ignoredfeatures. We argue that the discard of the correlated discriminativeinformation is partially caused by the fact that the minimization of theclassification loss doesn't ensure to learn the overall discriminativeinformation but only the most discriminative information. To address thisproblem, we propose an information flow maximization (IFM) loss as aregularization term to find the discriminative correlated features. With lessinformation loss the classifier can make predictions based on more informativefeatures. We validate our method on the shiftedMNIST dataset and show theeffectiveness of IFM loss in learning representative and discriminativefeatures."
"547","arXiv:1907.00344","https://arxiv.org/abs/1907.00344","Development of a novel matrix-based methodology for system engineering:  A case study","Hossein Sabzian, Seyyed Mostafa Seyyed Hashemi, Ehsan Kamrani","Developing a structured method for analyzing various aspects of a systemrequires a novel methodology. This study is aimed at developing such asmethodology through combining two major matrix methods, namely, DesignStructure Matrix (DSM) and Interface Structure Matrix (ISM). Through thispaper, a business process modeling method is applied to turn a real workproject to a process model. Then that process model is written in two variousmatrix forms of DSM and ISM. These two matrices are analyzed by two types ofalgorithm for extracting activity levels and sub-processes. In the end, a MixedMatrix Model (MMM) is built upon these activity levels and sub-processes, whichcan be used as a framework for the engineering of real-world systems."
"548","arXiv:1907.00339","https://arxiv.org/abs/1907.00339","Design and Implementation of an Automatic Synchronizing and Protection  Relay through Power-Hardware-in-the-Loop (PHIL) Simulation","Mishal Mahmood, Mariam Azam, Khair-un-Nisa Fatima, Muhammad Sarwar, Muhammad Abubakar, Babar Hussain","This paper focuses on the design and implementation of an automaticsynchronizing and protection relay to automate the synchronization process of aDistributed Energy Resource (DER) to the Main Grid. The proposed design utilizea cost-effective data acquisition using arduino in combination with LabVIEWsoftware to implement the multi-purpose synchronizing relay. The proposedsynchronizing relay is capable of synchronizing a Distributed Generator (DG) tothe power grid from black-start and fulfills the requirements imposed by theutility. The synchronizing relay is implemented through voltage and frequencycontrol of an actual lab-scale synchronous generator. In the synchronizationprocess, frequency synchronization is done using speed control of the steppermotor as prime mover and voltage synchronization is accomplished usingExcitation Control module through Power-Hardware-in-the-Loop (PHIL) simulation.In grid-connected mode, active and reactive power controls and protectionschemes for the synchronous generator have also been implemented. The proposedmulti-function relay has been deployed and tested on a lab-scale test bed tovalidate the proposed design and functionality."
"549","arXiv:1907.00338","https://arxiv.org/abs/1907.00338","Large-scale, real-time visual-inertial localization revisited","Simon Lynen, Bernhard Zeisl, Dror Aiger, Michael Bosse, Joel Hesch, Marc Pollefeys, Roland Siegwart, Torsten Sattler","The overarching goals in image-based localization are scale, robustness andspeed. In recent years, approaches based on local features and sparse 3Dpoint-cloud models have both dominated the benchmarks and seen successfulrealworld deployment. They enable applications ranging from robot navigation,autonomous driving, virtual and augmented reality to device geo-localization.Recently end-to-end learned localization approaches have been proposed whichshow promising results on small scale datasets. However the positioningaccuracy, scalability, latency and compute & storage requirements of theseapproaches remain open challenges. We aim to deploy localization atglobal-scale where one thus relies on methods using local features and sparse3D models. Our approach spans from offline model building to real-timeclient-side pose fusion. The system compresses appearance and geometry of thescene for efficient model storage and lookup leading to scalability beyond whatwhat has been previously demonstrated. It allows for low-latency localizationqueries and efficient fusion run in real-time on mobile platforms by combiningserver-side localization with real-time visual-inertial-based camera posetracking. In order to further improve efficiency we leverage a combination ofpriors, nearest neighbor search, geometric match culling and a cascaded posecandidate refinement step. This combination outperforms previous approacheswhen working with large scale models and allows deployment at unprecedentedscale. We demonstrate the effectiveness of our approach on a proof-of-conceptsystem localizing 2.5 million images against models from four cities indifferent regions on the world achieving query latencies in the 200ms range."
"550","arXiv:1907.00332","https://arxiv.org/abs/1907.00332","Secure Mobile Technologies for Proactive Critical Infrastructure  Situational Awareness","Gabriel Salles-Loustau, Vidyasagar Sadhu, Dario Pompili, Saman Zonouz, Vincent Sritapan","Trustworthy operation of our national critical infrastructures, such as theelectricity grid, against adversarial parties and accidental failures requiresconstant and secure monitoring capabilities. In this paper, Eyephone ispresented to leverage secure smartphone sensing and data acquisitioncapabilities and enable pervasive sensing of the national criticalinfrastructures. The reported information by the smartphone users will notifythe control center operators about particular accidental or malicious remotecritical infrastructure incidents. The reporting will be proactive regardingpotentially upcoming failures given the system's current risky situation, e.g.,a tree close to fall on a power grid transmission line. The information willinclude various modalities such as images, video, audio, time and location.Eyephone will use system-wide information flow analysis and policy enforcementto prevent user privacy violations during the incident reportings. A workingproof-of-concept prototype of Eyephone is implemented. Our results show thatEyephone allows secure and effective use of smartphones for real-timesituational awareness of our national critical infrastructures."
"551","arXiv:1907.00330","https://arxiv.org/abs/1907.00330","Visual Space Optimization for Zero-shot Learning","Xinsheng Wang, Shanmin Pang, Jihua Zhu, Zhongyu Li, Zhiqiang Tian, Yaochen Li","Zero-shot learning, which aims to recognize new categories that are notincluded in the training set, has gained popularity owing to its potentialability in the real-word applications. Zero-shot learning models rely onlearning an embedding space, where both semantic descriptions of classes andvisual features of instances can be embedded for nearest neighbor search.Recently, most of the existing works consider the visual space formulated bydeep visual features as an ideal choice of the embedding space. However, thediscrete distribution of instances in the visual space makes the data structureunremarkable. We argue that optimizing the visual space is crucial as it allowssemantic vectors to be embedded into the visual space more effectively. In thiswork, we propose two strategies to accomplish this purpose. One is the visualprototype based method, which learns a visual prototype for each visual class,so that, in the visual space, a class can be represented by a prototype featureinstead of a series of discrete visual features. The other is to optimize thevisual feature structure in an intermediate embedding space, and in this methodwe successfully devise a multilayer perceptron framework based algorithm thatis able to learn the common intermediate embedding space and meanwhile to makethe visual data structure more distinctive. Through extensive experimentalevaluation on four benchmark datasets, we demonstrate that optimizing visualspace is beneficial for zero-shot learning. Besides, the proposed prototypebased method achieves the new state-of-the-art performance."
"552","arXiv:1907.00327","https://arxiv.org/abs/1907.00327","Collaboration of AI Agents via Cooperative Multi-Agent Deep  Reinforcement Learning","Niranjan Balachandar, Justin Dieter, Govardana Sachithanandam Ramachandran","There are many AI tasks involving multiple interacting agents where agentsshould learn to cooperate and collaborate to effectively perform the task. Herewe develop and evaluate various multi-agent protocols to train agents tocollaborate with teammates in grid soccer. We train and evaluate ourmulti-agent methods against a team operating with a smart hand-coded policy. Asa baseline, we train agents concurrently and independently, with nocommunication. Our collaborative protocols were parameter sharing, coordinatedlearning with communication, and counterfactual policy gradients. Against thehand-coded team, the team trained with parameter sharing and the team trainedwith coordinated learning performed the best, scoring on 89.5% and 94.5% ofepisodes respectively when playing against the hand-coded team. Against theparameter sharing team, with adversarial training the coordinated learning teamscored on 75% of the episodes, indicating it is the most adaptable of ourmethods. The insights gained from our work can be applied to other domainswhere multi-agent collaboration could be beneficial."
"553","arXiv:1907.00326","https://arxiv.org/abs/1907.00326","Observing Dialogue in Therapy: Categorizing and Forecasting Behavioral  Codes","Jie Cao, Michael Tanana, Zac E. Imel, Eric Poitras, David C. Atkins, Vivek Srikumar","Automatically analyzing dialogue can help understand and guide behavior indomains such as counseling, where interactions are largely mediated byconversation. In this paper, we study modeling behavioral codes used to asses apsychotherapy treatment style called Motivational Interviewing (MI), which iseffective for addressing substance abuse and related problems. Specifically, weaddress the problem of providing real-time guidance to therapists with adialogue observer that (1) categorizes therapist and client MI behavioral codesand, (2) forecasts codes for upcoming utterances to help guide the conversationand potentially alert the therapist. For both tasks, we define neural networkmodels that build upon recent successes in dialogue modeling. Our experimentsdemonstrate that our models can outperform several baselines for both tasks. Wealso report the results of a careful analysis that reveals the impact of thevarious network design tradeoffs for modeling therapy dialogue."
"554","arXiv:1907.00325","https://arxiv.org/abs/1907.00325","Estimating Information-Theoretic Quantities with Random Forests","Richard Guo, Cencheng Shen, Joshua Vogelstein","Information-theoretic quantities, such as mutual information and conditionalentropy, are useful statistics for measuring the dependence between two randomvariables. However, estimating these quantities in a non-parametric fashion isdifficult, especially when the variables are high-dimensional, a mixture ofcontinuous and discrete values, or both. In this paper, we propose a decisionforest method, Conditional Forests (CF), to estimate these quantities. Bycombining quantile regression forests with honest sampling, and introducing afinite sample correction, CF improves finite sample bias in a range ofsettings. We demonstrate through simulations that CF achieves smaller bias andvariance in both low- and high-dimensional settings for estimating posteriors,conditional entropy, and mutual information. We then use CF to estimate theamount of information between neuron class and other ceulluar feautres."
"555","arXiv:1907.00321","https://arxiv.org/abs/1907.00321","Mechanisms of Artistic Creativity in Deep Learning Neural Networks","Lonce Wyse","The generative capabilities of deep learning neural networks (DNNs) have beenattracting increasing attention for both the remarkable artifacts they produce,but also because of the vast conceptual difference between how they areprogrammed and what they do. DNNs are 'black boxes' where high-level behavioris not explicitly programmed, but emerges from the complex interactions ofthousands or millions of simple computational elements. Their behavior is oftendescribed in anthropomorphic terms that can be misleading, seem magical, orstoke fears of an imminent singularity in which machines become 'more' thanhuman. In this paper, we examine 5 distinct behavioral characteristicsassociated with creativity, and provide an example of a mechanisms fromgenerative deep learning architectures that give rise to each thesecharacteristics. All 5 emerge from machinery built for purposes other than thecreative characteristics they exhibit, mostly classification. These mechanismsof creative generative capabilities thus demonstrate a deep kinship tocomputational perceptual processes. By understanding how these differentbehaviors arise, we hope to on one hand take the magic out of anthropomorphicdescriptions, but on the other, to build a deeper appreciation of machinicforms of creativity on their own terms that will allow us to nurture theirfurther development."
"556","arXiv:1907.00276","https://arxiv.org/abs/1907.00276","Stereo relative pose from line and point feature triplets","Alexander Vakhitov, Victor Lempitsky, Yinqiang Zheng","Stereo relative pose problem lies at the core of stereo visual odometrysystems that are used in many applications. In this work, we present twominimal solvers for the stereo relative pose. We specifically consider the casewhen a minimal set consists of three point or line features and each of themhas three known projections on two stereo cameras. We validate the importanceof this formulation for practical purposes in our experiments with motionestimation. We then present a complete classification of minimal cases withthree point or line correspondences each having three projections, and presenttwo new solvers that can handle all such cases. We demonstrate a considerableeffect from the integration of the new solvers into a visual SLAM system."
"557","arXiv:1907.00318","https://arxiv.org/abs/1907.00318","Multiple Landmark Detection using Multi-Agent Reinforcement Learning","Athanasios Vlontzos, Amir Alansary, Konstantinos Kamnitsas, Daniel Rueckert, Bernhard Kainz","The detection of anatomical landmarks is a vital step for medical imageanalysis and applications for diagnosis, interpretation and guidance. Manualannotation of landmarks is a tedious process that requires domain-specificexpertise and introduces inter-observer variability. This paper proposes a newdetection approach for multiple landmarks based on multi-agent reinforcementlearning. Our hypothesis is that the position of all anatomical landmarks isinterdependent and non-random within the human anatomy, thus finding onelandmark can help to deduce the location of others. Using a Deep Q-Network(DQN) architecture we construct an environment and agent with implicitinter-communication such that we can accommodate K agents acting and learningsimultaneously, while they attempt to detect K different landmarks. Duringtraining the agents collaborate by sharing their accumulated knowledge for acollective gain. We compare our approach with state-of-the-art architecturesand achieve significantly better accuracy by reducing the detection error by50%, while requiring fewer computational resources and time to train comparedto the naive approach of training K agents separately."
"558","arXiv:1907.00317","https://arxiv.org/abs/1907.00317","Waiting is not easy but worth it: the online TSP on the line revisited","Pei-Chuan Chen, Erik D. Demaine, Chung-Shou Liao, Hao-Ting Wei","We consider the online traveling salesman problem on the real line (OLTSPL)in which a salesman begins at the origin, traveling at no faster than unitspeed along the real line, and wants to serve a sequence of requests, arrivingonline over time on the real line and return to the origin as quickly aspossible. The problem has been widely investigated for more than two decades,but was just optimally solved by a deterministic algorithm with a competitiveratio of $(9+\sqrt{17})/8$, reported in~[Bjelde A. et al., in Proc. SODA 2017,pp.994--1005].In this study we present lower bounds and upper bounds for randomizedalgorithms in the OLTSPL. Precisely, we show, for the first time, that a simplerandomized \emph{zealous} algorithm can improve the optimal deterministicalgorithm. Here an algorithm is called zealous if waiting strategies are notallowed to use for the salesman as long as there are unserved requests.Moreover, we incorporate a natural waiting scheme into the randomizedalgorithm, which can even achieve the lower bound we propose for any randomizedalgorithms, and thus it is optimal. We also consider randomized algorithmsagainst a \emph{fair} adversary, i.e. an adversary with restricted power thatrequires the salesman to move within the convex hull of the origin and therequests released so far. The randomized non-zealous algorithm can outperformthe optimal deterministic algorithm against the fair adversary as well."
"559","arXiv:1907.00313","https://arxiv.org/abs/1907.00313","Reinforcement Learning with Fairness Constraints for Resource  Distribution in Human-Robot Teams","Houston Claure, Yifang Chen, Jignesh Modi, Malte Jung, Stefanos Nikolaidis","Much work in robotics and operations research has focused on optimal resourcedistribution, where an agent dynamically decides how to sequentially distributeresources among different candidates. However, most work ignores the notion offairness in candidate selection. In the case where a robot distributesresources to human team members, favoring heavily the highest performingteammate can have negative effects in team dynamics and system acceptance. Weintroduce a multi-armed bandit algorithm with fairness constraints, where arobot distributes resources to human teammates of different skill levels. Inthis problem, the robot does not know the skill level of each human teammate,but learns it by observing their performance over time. We define fairness as aconstraint on the minimum rate that each human teammate is selected throughoutthe task. We provide theoretical guarantees on performance and perform alarge-scale user study, where we adjust the level of fairness in our algorithm.Results show that fairness in resource distribution has a significant effect onusers' trust in the system."
"560","arXiv:1907.00309","https://arxiv.org/abs/1907.00309","Isomorphism problems for tensors, groups, and cubic forms: completeness  and reductions","Joshua A. Grochow, Youming Qiao","In this paper we consider the problems of testing isomorphism of tensors,$p$-groups, cubic forms, algebras, and more, which arise from a variety ofareas, including machine learning, group theory, and cryptography. Theseproblems can all be cast as orbit problems on multi-way arrays under differentgroup actions. Our first two main results are:1. All the aforementioned isomorphism problems are equivalent underpolynomial-time reductions, in conjunction with the recent results ofFutorny-Grochow-Sergeichuk (Lin. Alg. Appl., 2019).2. Isomorphism of $d$-tensors reduces to isomorphism of 3-tensors, for any $d\geq 3$.Our results suggest that these isomorphism problems form a rich and robustequivalence class, which we call Tensor Isomorphism-complete, or TI-complete.We then leverage the techniques used in the above results to prove twofirst-of-their-kind results for Group Isomorphism (GpI):3. We give a reduction from GpI for $p$-groups of exponent $p$ and smallclass ($c < p$) to GpI for $p$-groups of exponent $p$ and class 2. The latterare widely believed to be the hardest cases of GpI, but as far as we know, thisis the first reduction from any more general class of groups to this class.4. We give a search-to-decision reduction for isomorphism of $p$-groups ofexponent $p$ and class 2 in time $|G|^{O(\log \log |G|)}$. Whilesearch-to-decision reductions for Graph Isomorphism (GI) have been known formore than 40 years, as far as we know this is the first non-trivialsearch-to-decision reduction in the context of GpI.Our main technique for (1), (3), and (4) is a linear-algebraic analogue ofthe classical graph coloring gadget, which was used to obtain thesearch-to-decision reduction for GI. This gadget construction may be ofindependent interest and utility. The technique for (2) gives a method forencoding an arbitrary tensor into an algebra."
"561","arXiv:1907.00304","https://arxiv.org/abs/1907.00304","From Parameter Estimation to Dispersion of Nonstationary Gauss-Markov  Processes","Peida Tian, Victoria Kostina","This paper provides a precise error analysis for the maximum likelihoodestimate $\hat{a}(\pmb{u})$ of the parameter $a$ given samples $\pmb{u} = (u_1,\ldots, u_n)^\top$ drawn from a nonstationary Gauss-Markov process $U_i = aU_{i-1} + Z_i,~i\geq 1$, where $a> 1$, $U_0 = 0$, and $Z_i$'s are independentGaussian random variables with zero mean and variance $\sigma^2$. We show atight nonasymptotic exponentially decaying bound on the tail probability of theestimation error. Unlike previous works, our bound is tight already for asample size of the order of hundreds. We apply the new estimation bound to findthe dispersion for lossy compression of nonstationary Gauss-Markov sources. Weshow that the dispersion is given by the same integral formula derived in ourprevious work~\cite{dispersionJournal} for the (asymptotically) stationaryGauss-Markov sources, i.e., $|a| < 1$. New ideas in the nonstationary caseinclude a deeper understanding of the scaling of the maximum eigenvalue of thecovariance matrix of the source sequence, and new techniques in the derivationof our estimation error bound."
"562","arXiv:1907.00244","https://arxiv.org/abs/1907.00244","An Empirical Evaluation of Two General Game Systems: Ludii and RBG","Éric Piette, Matthew Stephenson, Dennis J. N. J. Soemers, Cameron Browne","Although General Game Playing (GGP) systems can facilitate useful research inArtificial Intelligence (AI) for game-playing, they are often computationallyinefficient and somewhat specialised to a specific class of games. However,since the start of this year, two General Game Systems have emerged thatprovide efficient alternatives to the academic state of the art -- the GameDescription Language (GDL). In order of publication, these are the RegularBoardgames language (RBG), and the Ludii system. This paper offers anexperimental evaluation of Ludii. Here, we focus mainly on a comparison betweenthe two new systems in terms of two key properties for any GGP system:simplicity/clarity (e.g. human-readability), and efficiency."
"563","arXiv:1907.00303","https://arxiv.org/abs/1907.00303","A nodal integration scheme for meshfree Galerkin methods using the  virtual element decomposition","R. Silva-Valenzuela, A. Ortiz-Bernardin, N. Sukumar, E. Artioli, N. Hitschfeld-Kahler","In this paper, we present a novel nodal integration scheme for meshfreeGalerkin methods that draws on the mathematical framework of the virtualelement method. We adopt the linear maximum-entropy basis functions fordiscretization of the field variables, although the proposed scheme isapplicable to any linear meshfree approximant. In our approach, the weak formintegrals are nodally integrated using nodal representative cells that carrythe nodal displacements and state variables such as strains and stresses. Thenodal integration is performed using the virtual element decomposition, whereinthe bilinear form is decomposed into a consistency part and a stability partthat ensure consistency and stability of the method. The performance of theproposed nodal integration scheme is assessed through various examples inlinear elastostatics and linear elastodynamics. We demonstrate that theproposed nodally integrated meshfree method is accurate, converges optimally,and is more efficient than a standard cell-based Gauss integrated meshfreemethod."
"564","arXiv:1907.00302","https://arxiv.org/abs/1907.00302","Bonded Mining: Difficulty Adjustment by Miner Commitment","George Bissias, Brian N. Levine, David Thibodeau","Proof-of-work blockchains must implement a difficulty adjustment algorithm(DAA) in order to maintain a consistent inter-arrival time between blocks.Conventional DAAs are essentially feedback controllers, and as such, they areinherently reactive. This leaves them susceptible to manipulation and oftencauses them to either under- or over-correct. We present Bonded Mining, aproactive DAA that works by collecting hash rate commitments secured by bondfrom miners. The difficulty is set directly from the commitments and the bondis used to penalize miners who deviate from their commitment. We devise astatistical test that is capable of detecting hash rate deviations by utilizingonly on-blockchain data. The test is sensitive enough to detect a variety ofdeviations from commitments, while almost never misclassifying honest miners.We demonstrate in simulation that, under reasonable assumptions, Bonded Miningis more effective at maintaining a target block time than the Bitcoin Cash DAA,one of the newest and most dynamic DAAs currently deployed."
"565","arXiv:1907.00301","https://arxiv.org/abs/1907.00301","Strategic Learning Approach for Deploying UAV-provided Wireless Services","Xinping Xu, Lingjie Duan, Minming Li","Unmanned Aerial Vehicle (UAV) have emerged as a promising technique torapidly provide wireless services to a group of mobile users simultaneously.The paper aims to address a challenging issue that each user is selfish and maymisreport his location or preference for changing the optimal UAV location tobe close to himself. Using algorithmic game theory, we study how to determinethe final location of a UAV in the 3D space, by ensuring all selfish users'truthfulness in reporting their locations for learning purpose. To minimize thesocial service cost in this UAV placement game, we design strategyproofmechanisms with the approximation ratios, when comparing to the social optimum.We also study the obnoxious UAV placement game to maximally keep their socialutility, where each incumbent user may misreport his location to keep the UAVaway from him. Moreover, we present the dual-preference UAV placement game byconsidering the coexistence of the two groups of users above, where users canmisreport both their locations and preference types (favorable or obnoxious)towards the UAV. Finally, we extend the three games above to include multipleUAVs and design strategyproof mechanisms with provable approximation ratios."
"566","arXiv:1907.00298","https://arxiv.org/abs/1907.00298","Deciding Memory Safety for Forest Datastructures","Umang Mathur, Adithya Murali, Paul Krogmeier, P. Madhusudan, Mahesh Viswanathan","Memory safety is the problem of determining if a heap manipulating programthat allocates/frees memory locations and manipulates heap pointers, does notdereference a memory location that is not allocated. Memory safety errors areserious security vulnerabilities that can be exploited systematically to attacksystems. In this paper we consider the problem of checking if a program, whoseinitial allocated heap forms a forest structure (i.e., a disjoint set of treesand lists), is memory safe. While the problem of checking memory safety ofprograms whose initial heap is a forest structure is undecidable, we identify aclass of caching programs for which the problem of checking memory safety isdecidable. Our experimental evaluation demonstrates that common libraryroutines that manipulate forest data-structures using a single pass are almostalways caching. We show that our decision procedure for such programs iseffective in both proving memory safety and in identifying memory safetyvulnerabilities."
"567","arXiv:1907.00297","https://arxiv.org/abs/1907.00297","A weighted finite difference method for subdiffusive Black Scholes Model","Grzegorz Krzyżanowski, Marcin Magdziarz, Łukasz Płociniczak","In this paper we focus on the subdiffusive Black Scholes model. The main partof our work consists of the finite difference method as a numerical approach tothe option pricing in the considered model. We derive the governing fractionaldifferential equation and the related weighted numerical scheme being ageneralization of the classical Crank-Nicolson scheme. The proposed method has$2-\alpha$ order of accuracy with respect to time where $\alpha\in(0,1)$ is thesubdiffusion parameter, and $2$ with respect to space. Further, we provide thestability and convergence analysis. Finally, we present some numerical results."
"568","arXiv:1907.00294","https://arxiv.org/abs/1907.00294","Generative Mask Pyramid Network forCT/CBCT Metal Artifact Reduction with  Joint Projection-Sinogram Correction","Haofu Liao, Wei-An Lin, Zhimin Huo, Levon Vogelsang, William J. Sehnert, S. Kevin Zhou, Jiebo Luo","A conventional approach to computed tomography (CT) or cone beam CT (CBCT)metal artifact reduction is to replace the X-ray projection data within themetal trace with synthesized data. However, existing projection or sinogramcompletion methods cannot always produce anatomically consistent information tofill the metal trace, and thus, when the metallic implant is large, significantsecondary artifacts are often introduced. In this work, we propose to replacemetal artifact affected regions with anatomically consistent content throughjoint projection-sinogram correction as well as adversarial learning. To handlethe metallic implants of diverse shapes and large sizes, we also propose anovel mask pyramid network that enforces the mask information across thenetwork's encoding layers and a mask fusion loss that reduces early saturationof adversarial training. Our experimental results show that the proposedprojection-sinogram correction designs are effective and our method recoversinformation from the metal traces better than the state-of-the-art methods."
"569","arXiv:1907.00285","https://arxiv.org/abs/1907.00285","X-CHANGR: Changing Memristive Crossbar Mapping for Mitigating  Line-Resistance Induced Accuracy Degradation in Deep Neural Networks","Amogh Agrawal, Chankyu Lee, Kaushik Roy","There is widespread interest in emerging technologies, especially resistivecrossbars for accelerating Deep Neural Networks (DNNs). Resistive crossbarsoffer a highly-parallel and efficient matrix-vector-multiplication (MVM)operation. MVM being the most dominant operation in DNNs makes crossbarsideally suited. However, various sources of device and circuit non-idealitieslead to errors in the MVM output, thereby reducing DNN accuracy. Towards thatend, we propose crossbar re-mapping strategies to mitigate line-resistanceinduced accuracy degradation in DNNs, without having to re-train the learnedweights, unlike most prior works. Line-resistances degrade the voltage levelsalong the crossbar columns, thereby inducing more errors at the columns awayfrom the drivers. We rank the DNN weights and kernels based on a sensitivityanalysis, and re-arrange the columns such that the most sensitive kernels aremapped closer to the drivers, thereby minimizing the impact of errors on theoverall accuracy. We propose two algorithms $-$ static remapping strategy (SRS)and dynamic remapping strategy (DRS), to optimize the crossbar re-arrangementof a pre-trained DNN. We demonstrate the benefits of our approach on a standardVGG16 network trained using CIFAR10 dataset. Our results show that SRS and DRSlimit the accuracy degradation to 2.9\% and 2.1\%, respectively, compared to a5.6\% drop from an as it is mapping of weights and kernels to crossbars. Webelieve this work brings an additional aspect for optimization, which can beused in tandem with existing mitigation techniques, such as in-situcompensation, technology aware training and re-training approaches, to enhancesystem performance."
"570","arXiv:1907.00283","https://arxiv.org/abs/1907.00283","SLAM Endoscopy enhanced by adversarial depth prediction","Richard J. Chen, Taylor L. Bobrow, Thomas Athey, Faisal Mahmood, Nicholas J. Durr","Medical endoscopy remains a challenging application for simultaneouslocalization and mapping (SLAM) due to the sparsity of image features and sizeconstraints that prevent direct depth-sensing. We present a SLAM approach thatincorporates depth predictions made by an adversarially-trained convolutionalneural network (CNN) applied to monocular endoscopy images. The depth networkis trained with synthetic images of a simple colon model, and then fine-tunedwith domain-randomized, photorealistic images rendered from computed tomographymeasurements of human colons. Each image is paired with an error-free depth mapfor supervised adversarial learning. Monocular RGB images are then fused withcorresponding depth predictions, enabling dense reconstruction and mosaicing asan endoscope is advanced through the gastrointestinal tract. Our preliminaryresults demonstrate that incorporating monocular depth estimation into a SLAMarchitecture can enable dense reconstruction of endoscopic scenes."
"571","arXiv:1907.00282","https://arxiv.org/abs/1907.00282","ROS 2 for RoboCup","Marcus M. Scheunemann, Sander G. van Dijk","There has always been much motivation for sharing code and solutions amongteams in the RoboCup community. Yet the transfer of code between teams wasusually complicated due to a huge variety of used frameworks and theirdifferences in processing sensory information. The RoboCup@Home league hastackled this by transitioning to ROS as a common framework. In contrast, otherleagues, such as those using humanoid robots, are reluctant to use ROS, as inthose leagues real-time processing and low-computational complexity is crucial.However, ROS 2 now offers built-in support for real-time processing andpromises to be suitable for embedded systems and multi-robot systems. It alsooffers the possibility to compose a set of nodes needed to run a robot into asingle process. This, as we will show, reduces communication overhead andallows to have one single binary, which is pertinent to competitions such asthe 3D-Simulation League. Although ROS 2 has not yet been announced to beproduction ready, we started the process to develop ROS 2 packages for using itwith humanoid robots (real and simulated). This paper presents the developedmodules, our contributions to ROS 2 core and RoboCup related packages, and mostimportantly it provides benchmarks that indicate that ROS 2 is a promisingcandidate for a common framework used among leagues."
"572","arXiv:1907.00281","https://arxiv.org/abs/1907.00281","Improving 3D U-Net for Brain Tumor Segmentation by Utilizing Lesion  Prior","Po-Yu Kao, Jefferson W. Chen, B.S. Manjunath","We propose a novel, simple and effective method to integrate lesion prior anda 3D U-Net for improving brain tumor segmentation. First, we utilize theground-truth brain tumor lesions from a group of patients to generate theheatmaps of different types of lesions. These heatmaps are used to create thevolume-of-interest (VOI) map which contains prior information about brain tumorlesions. The VOI map is then integrated with the multimodal MR images and inputto a 3D U-Net for segmentation. The proposed method is evaluated on a publicbenchmark dataset, and the experimental results show that the proposed featurefusion method achieves an improvement over the baseline methods. In addition,our proposed method also achieves a competitive performance compared tostate-of-the-art methods."
"573","arXiv:1907.00278","https://arxiv.org/abs/1907.00278","Most abundant isotope peaks and efficient selection on $Y=X_1+X_2+\cdots  + X_m$","Patrick Kreitzberg, Kyle Lucke, Oliver Serang","The isotope masses and relative abundances for each element are fundamentalchemical knowledge. Computing the isotope masses of a compound and theirrelative abundances is an important and difficult analytical chemistry problem.We demonstrate that this problem is equivalent to sorting$Y=X_1+X_2+\cdots+X_m$. We introduce a novel, practically efficient method forcomputing the top values in $Y$. then demonstrate the applicability of thismethod by computing the most abundant isotope masses (and their abundances)from compounds of nontrivial size."
"574","arXiv:1907.00277","https://arxiv.org/abs/1907.00277","Active Learning of Probabilistic Movement Primitives","Adam Conkey, Tucker Hermans","A Probabilistic Movement Primitive (ProMP) defines a distribution overtrajectories with an associated feedback policy. ProMPs are typicallyinitialized from human demonstrations and achieve task generalization throughprobabilistic operations. However, there is currently no principled guidance inthe literature to determine how many demonstrations a teacher should provideand what constitutes a ""good'"" demonstration for promoting generalization. Inthis paper, we present an active learning approach to learning a library ofProMPs capable of task generalization over a given space. We utilizeuncertainty sampling techniques to generate a task instance for which a teachershould provide a demonstration. The provided demonstration is incorporated intoan existing ProMP if possible, or a new ProMP is created from the demonstrationif it is determined that it is too dissimilar from existing demonstrations. Weprovide a qualitative comparison between common active learning metrics;motivated by this comparison we present a novel uncertainty sampling approachnamed ""Greatest Mahalanobis Distance.'' We perform grasping experiments on areal KUKA robot and show our novel active learning measure achieves better taskgeneralization with fewer demonstrations than a random sampling over the space."
"575","arXiv:1907.00275","https://arxiv.org/abs/1907.00275","Efficient Regularized Piecewise-Linear Regression Trees","Leonidas Lefakis, Oleksandr Zadorozhnyi, Gilles Blanchard","We present a detailed analysis of the class of regression decision treealgorithms which employ a regulized piecewise-linear node-splitting criterionand have regularized linear models at the leaves. From a theoretic standpoint,based on Rademacher complexity framework, we present new high-probability upperbounds for the generalization error for the proposed classes of regularizedregression decision tree algorithms, including LASSO-type, and $\ell_{2}$regularization for linear models at the leaves. Theoretical result are furtherextended by considering a general type of variable selection procedure.Furthermore, in our work we demonstrate that the class of piecewise-linearregression trees is not only numerically stable but can be made tractable viaan algorithmic implementation, presented herein, as well as with the help ofmodern GPU technology. Empirically, we present results on multiple datasetswhich highlight the strengths and potential pitfalls, of the proposed treealgorithms compared to baselines which grow trees based on piecewise constantmodels."
"576","arXiv:1907.00274","https://arxiv.org/abs/1907.00274","NetTailor: Tuning the Architecture, Not Just the Weights","Pedro Morgado, Nuno Vasconcelos","Real-world applications of object recognition often require the solution ofmultiple tasks in a single platform. Under the standard paradigm of networkfine-tuning, an entirely new CNN is learned per task, and the final networksize is independent of task complexity. This is wasteful, since simple tasksrequire smaller networks than more complex tasks, and limits the number oftasks that can be solved simultaneously. To address these problems, we proposea transfer learning procedure, denoted NetTailor, in which layers of apre-trained CNN are used as universal blocks that can be combined with smalltask-specific layers to generate new networks. Besides minimizingclassification error, the new network is trained to mimic the internalactivations of a strong unconstrained CNN, and minimize its complexity by thecombination of 1) a soft-attention mechanism over blocks and 2) complexityregularization constraints. In this way, NetTailor can adapt the networkarchitecture, not just its weights, to the target task. Experiments show thatnetworks adapted to simple tasks, such as character or traffic signrecognition, become significantly smaller than those adapted to hard tasks,such as fine-grained recognition. More importantly, due to the modular natureof the procedure, this reduction in network complexity is achieved withoutcompromise of either parameter sharing across tasks, or classificationaccuracy."
"577","arXiv:1907.00273","https://arxiv.org/abs/1907.00273","DuDoNet: Dual Domain Network for CT Metal Artifact Reduction","Wei-An Lin, Haofu Liao, Cheng Peng, Xiaohang Sun, Jingdan Zhang, Jiebo Luo, Rama Chellappa, Shaohua Kevin Zhou","Computed tomography (CT) is an imaging modality widely used for medicaldiagnosis and treatment. CT images are often corrupted by undesirable artifactswhen metallic implants are carried by patients, which creates the problem ofmetal artifact reduction (MAR). Existing methods for reducing the artifacts dueto metallic implants are inadequate for two main reasons. First, metalartifacts are structured and non-local so that simple image domain enhancementapproaches would not suffice. Second, the MAR approaches which attempt toreduce metal artifacts in the X-ray projection (sinogram) domain inevitablylead to severe secondary artifact due to sinogram inconsistency. To overcomethese difficulties, we propose an end-to-end trainable Dual Domain Network(DuDoNet) to simultaneously restore sinogram consistency and enhance CT images.The linkage between the sigogram and image domains is a novel Radon inversionlayer that allows the gradients to back-propagate from the image domain to thesinogram domain during training. Extensive experiments show that our methodachieves significant improvements over other single domain MAR approaches. Tothe best of our knowledge, it is the first end-to-end dual-domain network forMAR."
"578","arXiv:1907.00272","https://arxiv.org/abs/1907.00272","Intersection Graphs of Non-crossing Paths","Steven Chaplick","We study graph classes modeled by families of non-crossing (NC) connectedsets. Two classic graph classes in this context are disk graphs and properinterval graphs. We focus on the cases when the sets are paths and the host isa tree. Forbidden induced subgraph characterizations and linear time certifyingrecognition algorithms are given for intersection graphs of NC paths of a tree(and related subclasses).For intersection graphs of NC paths of a tree, the dominating set problem isshown to be solvable in linear time. Also, each such graph is shown to have aHamiltonian cycle if and only if it is 2-connected, and to have a Hamiltonianpath if and only if its block-cutpoint tree is a path."
"579","arXiv:1907.00271","https://arxiv.org/abs/1907.00271","HTS: A Hardware Task Scheduler for Heterogeneous Systems","Kartik Hegde, Abhishek Srivastava, Rohit Agrawal","As the Moore's scaling era comes to an end, application specific hardwareaccelerators appear as an attractive way to improve the performance and powerefficiency of our computing systems. A massively heterogeneous system with alarge number of hardware accelerators along with multiple general purpose CPUsis a promising direction, but pose several challenges in terms of the run-timescheduling of tasks on the accelerators and design granularity of accelerators.This paper addresses these challenges by developing an example heterogeneoussystem to enable multiple applications to share the available accelerators. Wepropose to design accelerators at a lower abstraction to enable applications tobe broken down into tasks that can be mapped on several accelerators. Weobserve that several real-life workloads can be broken down into commonprimitives that are shared across many workloads. Finally, we propose anddesign a hardware task scheduler inspired by the hardware schedulers inout-of-order superscalar processors to efficiently utilize the accelerators inthe system by scheduling tasks in out-of-order and even speculatively. Weevaluate the proposed system on both real-life and synthetic benchmarks basedon Digital Signal Processing~(DSP) applications. Compared to executing thebenchmark on a system with sequential scheduling, proposed scheduler achievesup to 12x improvement in performance."
"580","arXiv:1907.00270","https://arxiv.org/abs/1907.00270","An aggregate learning approach for interpretable semi-supervised  population prediction and disaggregation using ancillary data","Guillaume Derval, Frédéric Docquier, Pierre Schaus","Census data provide detailed information about population characteristics ata coarse resolution. Nevertheless, fine-grained, high-resolution mappings ofpopulation counts are increasingly needed to characterize population dynamicsand to assess the consequences of climate shocks, natural disasters,investments in infrastructure, development policies, etc. Dissagregating thesecensus is a complex machine learning, and multiple solutions have been proposedin past research. We propose in this paper to view the problem in the contextof the aggregate learning paradigm, where the output value for all trainingpoints is not known, but where it is only known for aggregates of the points(i.e. in this context, for regions of pixels where a census is available). Wedemonstrate with a very simple and interpretable model that this method is onpar, and even outperforms on some metrics, the state-of-the-art, despite itssimplicity."
"581","arXiv:1907.00269","https://arxiv.org/abs/1907.00269","On Training Flexible Robots using Deep Reinforcement Learning","Zach Dwiel, Madhavun Candadai, Mariano Phielipp","The use of robotics in controlled environments has flourished over the lastseveral decades and training robots to perform tasks using control strategiesdeveloped from dynamical models of their hardware have proven very effective.However, in many real-world settings, the uncertainties of the environment, thesafety requirements and generalized capabilities that are expected of robotsmake rigid industrial robots unsuitable. This created great research interestinto developing control strategies for flexible robot hardware for whichbuilding dynamical models are challenging. In this paper, inspired by thesuccess of deep reinforcement learning (DRL) in other areas, we systematicallystudy the efficacy of policy search methods using DRL in training flexiblerobots. Our results indicate that DRL is successfully able to learn efficientand robust policies for complex tasks at various degrees of flexibility. Wealso note that DRL using Deep Deterministic Policy Gradients can be sensitiveto the choice of sensors and adding more informative sensors does notnecessarily make the task easier to learn."
"582","arXiv:1907.00267","https://arxiv.org/abs/1907.00267","Learning to Generate Synthetic 3D Training Data through Hybrid Gradient","Dawei Yang, Jia Deng","Synthetic images rendered by graphics engines are a promising source fortraining deep networks. However, it is challenging to ensure that they can helptrain a network to perform well on real images, because a graphics-basedgeneration pipeline requires numerous design decisions such as the selection of3D shapes and the placement of the camera. In this work, we propose a newmethod that optimizes the generation of 3D training data based on what we call""hybrid gradient"". We parametrize the design decisions as a real vector, andcombine the approximate gradient and the analytical gradient to obtain thehybrid gradient of the network performance with respect to this vector. Weevaluate our approach on the task of estimating surface normals from a singleimage. Experiments on standard benchmarks show that our approach can outperformthe prior state of the art on optimizing the generation of 3D training data,particularly in terms of computational efficiency."
"583","arXiv:1907.00262","https://arxiv.org/abs/1907.00262","Dissecting Pruned Neural Networks","Jonathan Frankle, David Bau","Pruning is a standard technique for removing unnecessary structure from aneural network to reduce its storage footprint, computational demands, orenergy consumption. Pruning can reduce the parameter-counts of manystate-of-the-art neural networks by an order of magnitude without compromisingaccuracy, meaning these networks contain a vast amount of unnecessarystructure. In this paper, we study the relationship between pruning andinterpretability. Namely, we consider the effect of removing unnecessarystructure on the number of hidden units that learn disentangled representationsof human-recognizable concepts as identified by network dissection. We aim toevaluate how the interpretability of pruned neural networks changes as they arecompressed. We find that pruning has no detrimental effect on this measure ofinterpretability until so few parameters remain that accuracy beings to drop.Resnet-50 models trained on ImageNet maintain the same number of interpretableconcepts and units until more than 90% of parameters have been pruned."
"584","arXiv:1907.00259","https://arxiv.org/abs/1907.00259","Infrastructure-Agnostic Hypertext","Jakob Voß","This paper presents a novel and formal interpretation of the original visionof hypertext: infrastructure-agnostic hypertext is independent from specificstandards such as data formats and network protocols. Its model is illustratedwith examples and references to existing technologies that allow forimplementation and integration in current information infrastructures such asthe Internet."
"585","arXiv:1907.00253","https://arxiv.org/abs/1907.00253","Asynchronous Behavior Trees with Memory aimed at Aerial Vehicles with  Redundancy in Flight Controller","Evgenii Safronov, Michael Vilzmann, Dzmitry Tsetserukou, Konstantin Kondak","Complex aircraft systems are becoming a target for automation. For successfuloperation, they require both efficient and readable mission execution system.Flight control computer (FCC) units, as well as all important subsystems, areoften duplicated. Discrete nature of mission execution systems does not allowsmall differences in data flow among redundant FCCs which are acceptable forcontinuous control algorithms. Therefore, mission state consistency has to bespecifically maintained. We present a novel mission execution system whichincludes FCC state synchronization. To achieve this result we developed a newconcept of Asynchronous Behavior Tree with Memory and proposed a statesynchronization algorithm. The implemented system was tested and proven to workin a real-time simulation of High Altitude Pseudo Satellite (HAPS) mission."
"586","arXiv:1907.00250","https://arxiv.org/abs/1907.00250","Multi-objective multi-generation Gaussian process optimizer for design  optimization","Xiaobiao Huang","We present a multi-objective optimization algorithm that uses Gaussianprocess (GP) regression-based models to generate or select trial solutions in amulti-generation iterative procedure. In each generation, a surrogate model isconstructed for each objective function with the sample data. The models areused to evaluate solutions and to select the ones with a high potential beforethey are evaluated on the actual system. Since the trial solutions selected bythe GP models tend to have better performance than other methods that only relyon random operations, the new algorithm has much better efficiency in exploringthe parameter space. Simulations with multiple test cases show that the newalgorithm has a substantially higher convergence speed that the NSGA-II and PSOalgorithms."
"587","arXiv:1907.00246","https://arxiv.org/abs/1907.00246","Ludii as a Competition Platform","Matthew Stephenson, Éric Piette, Dennis J. N. J. Soemers, Cameron Browne","Ludii is a general game system being developed as part of the ERC-fundedDigital Ludeme Project (DLP). While its primary aim is to model, play, andanalyse the full range of traditional strategy games, Ludii also has thepotential to support a wide range of AI research topics and competitions. Thispaper describes some of the future competitions and challenges that we intendto run using the Ludii system, highlighting some of its most important aspectsthat can potentially lead to many algorithm improvements and new avenues ofresearch. We compare and contrast our proposed competition motivations, goalsand frameworks against those of existing general game playing competitions,addressing the strengths and weaknesses of each platform."
"588","arXiv:1907.00245","https://arxiv.org/abs/1907.00245","Ludii and XCSP: Playing and Solving Logic Puzzles","Cédric Piette, Éric Piette, Matthew Stephenson, Dennis J. N. J. Soemers, Cameron Browne","Many of the famous single-player games, commonly called puzzles, can be shownto be NP-Complete. Indeed, this class of complexity contains hundreds ofpuzzles, since people particularly appreciate completing an intractable puzzle,such as Sudoku, but also enjoy the ability to check their solution easily onceit's done. For this reason, using constraint programming is naturally suited tosolve them. In this paper, we focus on logic puzzles described in the Ludiigeneral game system and we propose using the XCSP formalism in order to solvethem with any CSP solver."
"589","arXiv:1907.00242","https://arxiv.org/abs/1907.00242","Joint Functional Splitting and Content Placement for Green Hybrid CRAN","Ajay Sriram, Meysam Masoudi, Abdulrahman Alabbasi, Cicek Cavdar","A hybrid cloud radio access network (H-CRAN) architecture has been proposedto alleviate the midhaul capacity limitation in C-RAN. In this architecture,functional splitting is utilized to distribute the processing functions betweena central cloud and edge clouds. The flexibility of selecting specific splitpoint enables the H-CRAN designer to reduce midhaul bandwidth, or reducelatency, or save energy, or distribute the computation task depending onequipment availability. Meanwhile, techniques for caching are proposed toreduce content delivery latency and the required bandwidth. However, cachingimposes new constraints on functional splitting. In this study, consideringH-CRAN, a constraint programming problem is formulated to minimize the overallpower consumption by selecting the optimal functional split point and contentplacement, taking into account the content access delay constraint. We alsoinvestigate the trade-off between the overall power consumption and occupiedmidhaul bandwidth in the network. Our results demonstrate that functionalsplitting together with enabling caching at edge clouds reduces not onlycontent access delays but also fronthaul bandwidth consumption but at theexpense of higher power consumption."
"590","arXiv:1907.00240","https://arxiv.org/abs/1907.00240","An Overview of the Ludii General Game System","Matthew Stephenson, Éric Piette, Dennis J. N. J. Soemers, Cameron Browne","The Digital Ludeme Project (DLP) aims to reconstruct and analyse over 1000traditional strategy games using modern techniques. One of the key aspects ofthis project is the development of Ludii, a general game system that will beable to model and play the complete range of games required by this project.Such an undertaking will create a wide range of possibilities for new AIchallenges. In this paper we describe many of the features of Ludii that can beused. This includes designing and modifying games using the Ludii gamedescription language, creating agents capable of playing these games, andseveral advantages the system has over prior general game software."
"591","arXiv:1907.00239","https://arxiv.org/abs/1907.00239","QCSP monsters and the demise of the Chen Conjecture","Dmitriy Zhuk, Barnaby Martin","We give a surprising classification for the computational complexity ofQuantified Constraint Satisfaction Problems, QCSP$(\Gamma)$, where $\Gamma$ isa finite language over $3$ elements which contains all constants. Inparticular, such problems are either in P, NP-complete, co-NP-complete orPspace-complete. Our classification refutes the hitherto widely-believed ChenConjecture.Additionally, we show that already on 4-element domain there exists aconstraint language $\Gamma$ such that QCSP$(\Gamma)$ is DP-complete (fromBoolean Hierarchy), and on 10-element domain there exists a constraint languagegiving a complexity class different from all the above classes.Meanwhile, we prove the Chen Conjecture for finite conservative languages$\Gamma$. If the polymorphism clone of $\Gamma$ has the polynomially generatedpowers (PGP) property then QCSP$(\Gamma)$ is in NP. Otherwise, the polymorphismclone of $\Gamma$ has the exponentially generated powers (EGP) property andQCSP$(\Gamma)$ is Pspace-complete."
"592","arXiv:1907.00236","https://arxiv.org/abs/1907.00236","Streaming Quantiles Algorithms with Small Space and Update Time","Nikita Ivkin, Edo Liberty, Kevin Lang, Zohar Karnin, Vladimir Braverman","Approximating quantiles and distributions over streaming data has beenstudied for roughly two decades now. Recently, Karnin, Lang, and Libertyproposed the first asymptotically optimal algorithm for doing so. Thismanuscript complements their theoretical result by providing a practicalvariants of their algorithm with improved constants. For a given sketch size,our techniques provably reduce the upper bound on the sketch error by a factorof two. These improvements are verified experimentally. Our modified quantilesketch improves the latency as well by reducing the worst case update time from$O(1/\varepsilon)$ down to $O(\log (1/\varepsilon))$. We also suggest twoalgorithms for weighted item streams which offer improved asymptotic updatetimes compared to na\""ive extensions. Finally, we provide a specialized datastructure for these sketches which reduces both their memory footprints andupdate times."
"593","arXiv:1907.00235","https://arxiv.org/abs/1907.00235","Enhancing the Locality and Breaking the Memory Bottleneck of Transformer  on Time Series Forecasting","Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, Xifeng Yan","Time series forecasting is an important problem across many domains,including predictions of solar plant energy output, electricity consumption,and traffic jam situation. In this paper, we propose to tackle such forecastingproblem with Transformer. Although impressed by its performance in ourpreliminary study, we found its two major weaknesses: (1) locality-agnostics:the point-wise dot-product self attention in canonical Transformer architectureis insensitive to local context, which can make the model prone to anomalies intime series; (2) memory bottleneck: space complexity of canonical Transformergrows quadratically with sequence length $L$, making modeling long time seriesinfeasible. In order to solve these two issues, we first propose convolutionalself attention by producing queries and keys with causal convolution so thatlocal context can be better incorporated into attention mechanism. Then, wepropose LogSparse Transformer with only $O(L(\log L)^{2})$ memory cost,improving the time series forecasting in finer granularity under constrainedmemory budget. Our experiments on both synthetic data and real-world datasetsshow that it compares favorably to the state-of-the-art."
"594","arXiv:1907.00233","https://arxiv.org/abs/1907.00233","Evaluating Local Geometric Feature Representations for 3D Rigid Data  Matching","Jiaqi Yang, Siwen Quan, Peng Wang, Yanning Zhang","Local geometric descriptors remain an essential component for 3D rigid datamatching and fusion. The devise of a rotational invariant local geometricdescriptor usually consists of two steps: local reference frame (LRF)construction and feature representation. Existing evaluation efforts havemainly been paid on the LRF or the overall descriptor, yet the quantitativecomparison of feature representations remains unexplored. This paper fills thisgap by comprehensively evaluating nine state-of-the-art local geometric featurerepresentations. Our evaluation is on the ground that ground-truth LRFs areleveraged such that the ranking of tested feature representations are moreconvincing as opposed to existing studies. The experiments are deployed on sixstandard datasets with various application scenarios (shape retrieval, pointcloud registration, and object recognition) and data modalities (LiDAR, Kinect,and Space Time) as well as perturbations including Gaussian noise, shot noise,data decimation, clutter, occlusion, and limited overlap. The evaluated termscover the major concerns for a feature representation, e.g., distinctiveness,robustness, compactness, and efficiency. The outcomes present interestingfindings that may shed new light on this community and provide complementaryperspectives to existing evaluations on the topic of local geometric featuredescription. A summary of evaluated methods regarding their peculiarities isalso presented to guide real-world applications and new descriptor crafting."
"595","arXiv:1907.00231","https://arxiv.org/abs/1907.00231","Towards Forward Secure Internet Traffic","Eman Salem Alashwali, Pawel Szalachowski, Andrew Martin","Forward Secrecy (FS) is a security property in key-exchange algorithms whichguarantees that a compromise in the secrecy of a long-term private-key does notcompromise the secrecy of past session keys. With a growing awareness oflong-term mass surveillance programs by governments and others, FS has becomewidely regarded as a highly desirable property. This is particularly true inthe TLS protocol, which is used to secure Internet communication. In thispaper, we investigate FS in pre-TLS 1.3 protocols, which do not mandate FS, butstill widely used today. We conduct an empirical analysis of over 10 millionTLS servers from three different datasets using a novel heuristic approach.Using a modern TLS client handshake algorithms, our results show 5.37% of topdomains, 7.51% of random domains, and 26.16% of random IPs do not select FSkey-exchange algorithms. Surprisingly, 39.20% of the top domains, 24.40% of therandom domains, and 14.46% of the random IPs that do not select FS, do supportFS. In light of this analysis, we discuss possible paths toward forward secureInternet traffic. As an improvement of the current state, we propose a newclient-side mechanism that we call ""Best Effort Forward Secrecy"" (BEFS), and anextension of it that we call ""Best Effort Forward Secrecy and AuthenticatedEncryption"" (BESAFE), which aims to guide (force) misconfigured servers to FSusing a best effort approach. Finally, within our analysis, we introduce anovel adversarial model that we call ""discriminatory"" adversary, which isapplicable to the TLS protocol."
"596","arXiv:1907.00227","https://arxiv.org/abs/1907.00227","On Asymmetric Unification for the Theory of XOR with a Homomorphism","Christopher Lynch, Andrew M. Marshall, Catherine Meadows, Paliath Narendran, Veena Ravishankar","Asymmetric unification, or unification with irreducibility constraints, is anewly developed paradigm that arose out of the automated analysis ofcryptographic protocols. However, there are still relatively few asymmetricunification algorithms. In this paper we address this lack by exploring theapplication of automata-based unification methods. We examine the theory of xorwith a homomorphism, ACUNh, from the point of view of asymmetric unification,and develop a new automata-based decision procedure. Then, we adapt a recentlydeveloped asymmetric combination procedure to produce a general asymmetric-ACUNh decision procedure. Finally, we present a new approach for obtaining asolution-generating asymmetric-ACUNh unification automaton. We also compare ourapproach to the most commonly used form of asymmetric unification availabletoday, variant unification."
"597","arXiv:1907.00221","https://arxiv.org/abs/1907.00221","Causal Inference Under Interference And Network Uncertainty","Rohit Bhattacharya, Daniel Malinsky, Ilya Shpitser","Classical causal and statistical inference methods typically assume theobserved data consists of independent realizations. However, in manyapplications this assumption is inappropriate due to a network of dependencesbetween units in the data. Methods for estimating causal effects have beendeveloped in the setting where the structure of dependence between units isknown exactly, but in practice there is often substantial uncertainty about theprecise network structure. This is true, for example, in trial data drawn fromvulnerable communities where social ties are difficult to query directly. Inthis paper we combine techniques from the structure learning and interferenceliteratures in causal inference, proposing a general method for estimatingcausal effects under data dependence when the structure of this dependence isnot known a priori. We demonstrate the utility of our method on syntheticdatasets which exhibit network dependence."
"598","arXiv:1907.00220","https://arxiv.org/abs/1907.00220","Distributed Global Output-Feedback Control for a Class of Euler-Lagrange  Systems","Qingkai Yang, Hao Fang, Jie Chen, Zhong-Ping Jiang, Ming Cao","This published paper investigates the distributed tracking control problemfor a class of Euler-Lagrange multi-agent systems when the agents can onlymeasure the positions. In this case, the lack of the separation principle andthe strong nonlinearity in unmeasurable states pose severe technical challengesto global output-feedback control design. To overcome these difficulties, aglobal nonsingular coordinate transformation matrix in the upper triangularform is firstly proposed such that the nonlinear dynamic model can be partiallylinearized with respect to the unmeasurable states. And, a new type of velocityobservers is designed to estimate the unmeasurable velocities for each system.Then, based on the outputs of the velocity observers, we propose distributedcontrol laws that enable the coordinated tracking control system to achieveuniform global exponential stability (UGES). Both theoretical analysis andnumerical simulations are presented to validate the effectiveness of theproposed control scheme. Followed by the original paper, a typo and a mistakeis corrected."
"599","arXiv:1907.00218","https://arxiv.org/abs/1907.00218","Latent Variable Sentiment Grammar","Liwen Zhang, Kewei Tu, Yue Zhang","Neural models have been investigated for sentiment classification overconstituent trees. They learn phrase composition automatically by encoding treestructures but do not explicitly model sentiment composition, which requires toencode sentiment class labels. To this end, we investigate two formalisms withdeep sentiment representations that capture sentiment subtype expressions bylatent variables and Gaussian mixture vectors, respectively. Experiments onStanford Sentiment Treebank (SST) show the effectiveness of sentiment grammarover vanilla neural encoders. Using ELMo embeddings, our method gives the bestresults on this benchmark."
"600","arXiv:1907.00217","https://arxiv.org/abs/1907.00217","Predicting Social Perception from Faces: A Deep Learning Approach","U. Messer, S. Fausser","Warmth and competence represent the fundamental traits in social judgmentthat determine emotional reactions and behavioral intentions towards socialtargets. This research investigates whether an algorithm can learn visualrepresentations of social categorization and accurately predict humanperceivers' impressions of warmth and competence in face images. In addition,this research unravels which areas of a face are important for theclassification of warmth and competence. We use Deep Convolutional NeuralNetworks to extract features from face images and the Gradient-weighted ClassActivation Mapping (Grad CAM) method to understand the importance of faceregions for the classification. Given a single face image the trained algorithmcould correctly predict warmth impressions with an accuracy of about 90% andcompetence impressions with an accuracy of about 80%. The findings haveimplications for the automated processing of faces and the design of artificialcharacters."
"601","arXiv:1907.00216","https://arxiv.org/abs/1907.00216","Quadrilateral Mesh Generation II : Meromorphic Quartic Differentials and  Abel-Jacobi Condition","Na Lei, Xiaopeng Zheng, Zhongxuan Luo, Feng Luo, Xianfeng Gu","This work discovers the equivalence relation between quadrilateral meshes andmeromorphic quartic. Each quad-mesh induces a conformal structure of thesurface, and a meromorphic differential, where the configuration of singularvertices correspond to the configurations the poles and zeros (divisor) of themeroromorphic differential. Due to Riemann surface theory, the configuration ofsingularities of a quad-mesh satisfies the Abel-Jacobi condition. Inversely, ifa satisfies the Abel-Jacobi condition, then there exists a meromorphic quarticdifferential whose equals to the given one. Furthermore, if the meromorphicquadric differential is with finite, then it also induces a a quad-mesh, thepoles and zeros of the meromorphic differential to the singular vertices of thequad-mesh. Besides the theoretic proofs, the computational algorithm forverification of Abel-Jacobi condition is explained in details. Furthermore,constructive algorithm of meromorphic quartic differential on zero surfaces isproposed, which is based on the global algebraic representation of meromorphic.Our experimental results demonstrate the efficiency and efficacy of thealgorithm. This opens up a direction for quad-mesh generation using algebraicgeometric approach."
"602","arXiv:1907.00215","https://arxiv.org/abs/1907.00215","Non-destructive three-dimensional measurement of hand vein based on  self-supervised network","Xiaoyu Chen, Qixin Wang, Jinzhou Ge, Yi Zhang, Jing Han","At present, supervised stereo methods based on deep neural network haveachieved impressive results. However, in some scenarios, accuratethree-dimensional labels are inaccessible for supervised training. In thispaper, a self-supervised network is proposed for binocular disparity matching(SDMNet), which computes dense disparity maps from stereo image pairs withoutdisparity labels: In the self-supervised training, we match the stereo imagesdensely to approximate the disparity maps and use them to warp the left andright images to estimate the right and left images; we build the loss functionbetween estimated images and original images for self-supervised training,which adopts perceptual loss to help improve the quality of disparity maps inboth detail and structure. Then, we use SDMNet to obtain disparities of handvein. SDMNet has achieved excellent results on KITTI 2012, KITTI 2015,simulated vein dataset and real vein dataset, outperforming manystate-of-the-art supervised matching methods."
"603","arXiv:1907.00214","https://arxiv.org/abs/1907.00214","Learning Where to Look While Tracking Instruments in Robot-assisted  Surgery","Mobarakol Islam, Yueyuan Li, Hongliang Ren","Directing of the task-specific attention while tracking instrument in surgeryholds great potential in robot-assisted intervention. For this purpose, wepropose an end-to-end trainable multitask learning (MTL) model for real-timesurgical instrument segmentation and attention prediction. Our model isdesigned with a weight-shared encoder and two task-oriented decoders andoptimized for the joint tasks. We introduce batch-Wasserstein (bW) loss andconstruct a soft attention module to refine the distinctive visual region forefficient saliency learning. For multitask optimization, it is alwayschallenging to obtain convergence of both tasks in the same epoch. We deal withthis problem by adopting `poly' loss weight and two phases of training. Wefurther propose a novel way to generate task-aware saliency map and scanpath ofthe instruments on MICCAI robotic instrument segmentation dataset. Compared tothe state of the art segmentation and saliency models, our model outperformsmost of the evaluation metrics."
"604","arXiv:1907.00211","https://arxiv.org/abs/1907.00211","Robust Linear Discriminant Analysis Using Ratio Minimization of  L1,2-Norms","Feiping Nie, Hua Wang, Zheng Wang, Heng Huang","As one of the most popular linear subspace learning methods, the LinearDiscriminant Analysis (LDA) method has been widely studied in machine learningcommunity and applied to many scientific applications. Traditional LDAminimizes the ratio of squared L2-norms, which is sensitive to outliers. Inrecent research, many L1-norm based robust Principle Component Analysis methodswere proposed to improve the robustness to outliers. However, due to thedifficulty of L1-norm ratio optimization, so far there is no existing work toutilize sparsity-inducing norms for LDA objective. In this paper, we propose anovel robust linear discriminant analysis method based on the L1,2-norm ratiominimization. Minimizing the L1,2-norm ratio is a much more challenging problemthan the traditional methods, and there is no existing optimization algorithmto solve such non-smooth terms ratio problem. We derive a new efficientalgorithm to solve this challenging problem, and provide a theoretical analysison the convergence of our algorithm. The proposed algorithm is easy toimplement, and converges fast in practice. Extensive experiments on bothsynthetic data and nine real benchmark data sets show the effectiveness of theproposed robust LDA method."
"605","arXiv:1907.00209","https://arxiv.org/abs/1907.00209","High Sensitivity Snapshot Spectrometer Based on Deep Network Unmixing","XiaoYu Chen, Xu Wang, Lianfa Bai, Jing Han, Zhuang Zhao","In this paper, we present a convolution neural network based method torecover the light intensity distribution from the overlapped dispersive spectrainstead of adding an extra light path to capture it directly for the firsttime. Then, we construct a single-path sub-Hadamard snapshot spectrometer basedon our previous dual-path snapshot spectrometer. In the proposed single-pathspectrometer, we use the reconstructed light intensity as the original lightintensity and recover high signal-to-noise ratio spectra successfully. Comparedwith dual-path snapshot spectrometer, the network based single-pathspectrometer has a more compact structure and maintains snapshot and highsensitivity. Abundant simulated and experimental results have demonstrated thatthe proposed method can obtain a better reconstructed signal-to-noise ratiospectrum than the dual-path sub-Hadamard spectrometer because of its higherlight throughput."
"606","arXiv:1907.00208","https://arxiv.org/abs/1907.00208","Deep Gamblers: Learning to Abstain with Portfolio Theory","Liu Ziyin, Zhikang Wang, Paul Pu Liang, Ruslan Salakhutdinov, Louis-Philippe Morency, Masahito Ueda","We deal with the \textit{selective classification} problem(supervised-learning problem with a rejection option), where we want to achievethe best performance at a certain level of coverage of the data. We transformthe original $m$-class classification problem to $(m+1)$-class where the$(m+1)$-th class represents the model abstaining from making a prediction dueto uncertainty. Inspired by portfolio theory, we propose a loss function forthe selective classification problem based on the doubling rate of gambling. Weshow that minimizing this loss function has a natural interpretation asmaximizing the return of a \textit{horse race}, where a player aims to balancebetween betting on an outcome (making a prediction) when confident andreserving one's winnings (abstaining) when not confident. This loss functionallows us to train neural networks and characterize the uncertainty ofprediction in an end-to-end fashion. In comparison with previous methods, ourmethod requires almost no modification to the model inference algorithm orneural architecture. Experimentally, we show that our method can identify bothuncertain and outlier data points, and achieves strong results on SVHN andCIFAR10 at various coverages of the data."
"607","arXiv:1907.00205","https://arxiv.org/abs/1907.00205","The Ramanujan Machine: Automatically Generated Conjectures on  Fundamental Constants","Gal Raayoni, George Pisha, Yahel Manor, Uri Mendlovic, Doron Haviv, Yaron Hadad, Ido Kaminer","Fundamental mathematical constants like $e$ and $\pi$ are ubiquitous indiverse fields of science, from abstract mathematics and geometry to physics,biology and chemistry. Nevertheless, for centuries new mathematical formulasrelating fundamental constants have been scarce and usually discoveredsporadically. In this paper we propose a novel and systematic approach thatleverages algorithms for deriving new mathematical formulas for fundamentalconstants and help reveal their underlying structure. Our algorithms finddozens of well-known as well as previously unknown continued fractionrepresentations of $\pi$, $e$, and the Riemann zeta function values. Two newconjectures produced by our algorithm, along with many others, are:\begin{equation*}e = 3 + \frac{-1}{4+\frac{-2}{5+\frac{-3}{6+\frac{-4}{7+\ldots}}}}\quad\quad,\quad\quad \frac{4}{\pi-2} = 3+\frac{1\cdot3}{5+\frac{2\cdot4}{7+\frac{3\cdot 5}{9+\frac{4\cdot 6}{11+\ldots}}}} \end{equation*} We presenttwo algorithms that proved useful in finding new results: a variant of theMeet-In-The-Middle (MITM) algorithm and a Gradient Descent (GD) tailored to therecurrent structure of continued fractions. Both algorithms are based onmatching numerical values and thus find new conjecture formulas withoutproviding proofs and without requiring prior knowledge on any mathematicalstructure. This approach is especially attractive for fundamental constants forwhich no mathematical structure is known, as it reverses the conventionalapproach of sequential logic in formal proofs. Instead, our work presents a newconceptual approach for research: computer algorithms utilizing numerical datato unveil new internal structures and conjectures, thus playing the role ofmathematical intuition of great mathematicians of the past, providing leads tonew mathematical research."
"608","arXiv:1907.00203","https://arxiv.org/abs/1907.00203","Upper Bounding GED via Transformations to LSAPE Based on Rings and  Machine Learning","David B. Blumenthal, Sébastien Bougleux, Johann Gamper, Luc Brun","The graph edit distance (GED) is a flexible distance measure which is widelyused for inexact graph matching. Since its exact computation is NP-hard,heuristics are used in practice. A popular approach is to obtain upper boundsfor GED via transformations to the linear sum assignment problem witherror-correction (LSAPE). Typically, local structures and distances betweenthem are employed for carrying out this transformation, but recently alsomachine learning techniques have been used. In this paper, we formally define aunifying framework LSAPE-GED for transformations from GED to LSAPE. Weintroduce rings as a new kind of local structures that are able to capture alot of information encoded in the input graphs at a low computational cost.Furthermore, we propose two new ring based heuristics RING and RING-ML, whichinstantiate LSAPE-GED using the traditional and the machine learning basedapproach for transforming GED to LSAPE, respectively. Extensive experimentsshow that using rings for upper bounding GED significantly improves the stateof the art on datasets where most information resides in the graphs'topologies."
"609","arXiv:1907.00199","https://arxiv.org/abs/1907.00199","Incidents Are Meant for Learning, Not Repeating: Sharing Knowledge About  Security Incidents in Cyber-Physical Systems","Faeq Alrimawi, Liliana Pasquale, Deepak Mehta, Nobukazu Yoshioka, Bashar Nuseibeh","Cyber-physical systems (CPSs) are part of most critical infrastructures suchas industrial automation and transportation systems. Thus, security incidentstargeting CPSs can have disruptive consequences to assets and people. As priorincidents tend to re-occur, sharing knowledge about these incidents can helporganizations be more prepared to prevent, mitigate or investigate futureincidents. This paper proposes a novel approach to enable representation andsharing of knowledge about CPS incidents across different organizations. Tosupport sharing, we represent incident knowledge (incident patterns) capturingincident characteristics that can manifest again, such as incident activitiesor vulnerabilities exploited by offenders. Incident patterns are a moreabstract representation of specific incident instances and, thus, are generalenough to be applicable to various systems - different than the one in whichthe incident occurred. They can also avoid disclosing potentially sensitiveinformation about an organization's assets and resources. We provide anautomated technique to extract an incident pattern from a specific incidentinstance. To understand how an incident pattern can manifest again in othercyber-physical systems, we also provide an automated technique to instantiateincident patterns to specific systems. We demonstrate the feasibility of ourapproach in the application domain of smart buildings. We evaluate correctness,scalability, and performance using two substantive scenarios inspired byreal-world systems and incidents."
"610","arXiv:1907.00198","https://arxiv.org/abs/1907.00198","Hybrid Collision Avoidance for ASVs Compliant with COLREGs Rules 8 and  13-17","Bjørn-Olav H. Eriksen, Glenn Bitar, Morten Breivik, Anastasios M. Lekkas","This paper presents a three-layered hybrid collision avoidance (COLAV) systemfor autonomous surface vehicle, compliant with rules 8 and 13-17 of theInternational Regulations for Preventing Collisions at Sea (COLREGs). The COLAVsystem consists of a high-level planner producing an energy-optimizedtrajectory, a model predictive control based mid-level COLAV algorithmconsidering moving obstacles and the COLREGs, and the branching-course modelpredictive control algorithm for short-term COLAV handling emergency situationsin accordance with the COLREGs. Previously developed algorithms by the authorsare used for the high-level planner and short-term COLAV, while we in thispaper further develop the mid-level algorithm to make it comply with COLREGsrules 13-17. This includes developing a state machine for classifying obstaclevessels using a combination of the geometrical situation, the distance and timeto the closest point of approach (CPA) and a new CPA-like measure. Theperformance of the hybrid COLAV system is tested through numerical simulationsfor three scenarios representing a range of different challenges, includingmulti-obstacle situations with multiple simultaneously active COLREGs rules,and also obstacles ignoring the COLREGs. The COLAV system avoids collision inall the scenarios, and follows the energy-optimized trajectory when theobstacles do not interfere with it."
"611","arXiv:1907.00194","https://arxiv.org/abs/1907.00194","Open-MPI over MOSIX: paralleled computing in a clustered world","Adam Lev-Libfeld, Alex Margolin, Amnon Barak","Recent increased interest in Cloud computing emphasizes the need to find anadequate solution to the load-balancing problem in parallel computing --efficiently running several jobs concurrently on a cluster of shared computers(nodes). One approach to solve this problem is by preemptive process migration-- the transfer of running processes between nodes. A possible drawback of thisapproach is the increased overhead between heavily communicating processes.This project presents a solution to this last problem by incorporating theprocess migration capability of MOSIX into Open-MPI and by reducing theresulting communication overhead. Specifically, we developed a module fordirect communication (DiCOM) between migrated Open-MPI processes, to overcomethe increased communication latency of TCP/IP between such processes. Theoutcome is reduced run-time by improved resource allocation."
"612","arXiv:1907.00193","https://arxiv.org/abs/1907.00193","frame attention networks for facial expression recognition in videos","Debin Meng, Xiaojiang Peng, Kai Wang, Yu Qiao","The video-based facial expression recognition aims to classify a given videointo several basic emotions. How to integrate facial features of individualframes is crucial for this task. In this paper, we propose the Frame AttentionNetworks (FAN), to automatically highlight some discriminative frames in anend-to-end framework. The network takes a video with a variable number of faceimages as its input and produces a fixed-dimension representation. The wholenetwork is composed of two modules. The feature embedding module is a deepConvolutional Neural Network (CNN) which embeds face images into featurevectors. The frame attention module learns multiple attention weights which areused to adaptively aggregate the feature vectors to form a singlediscriminative video representation. We conduct extensive experiments on CK+and AFEW8.0 datasets. Our proposed FAN shows superior performance compared toother CNN based methods and achieves state-of-the-art performance on CK+."
"613","arXiv:1907.00190","https://arxiv.org/abs/1907.00190","Distributed Design of Robust Kalman Filters over Corrupted Channels","Xingkang He, Karl Henrik Johansson, Haitao Fang","The robust state estimation problem is on how to design robust filters forestimating an unknown state of uncertain systems. This paper considers thisproblem for multi-agent systems with multiplicative noise and degradedmeasurements over corrupted channels. Employing a covariance intersectionfusion method, we propose a distributed robust Kalman filter with stochasticgains, which enables a sequence of upper bounds of conditional mean squareerror given channel noise to be calculated online. Considering the limitationof step-wise optimization, for better performance, we propose a switchingfusion scheme based on a sliding window method, which provides an online designof covariance intersection weights by solving a semi-definite programmingproblem. Compared to the filter fusing latest estimates, the one based on theswitching fusion method has a smaller upper bound of the conditional meansquare error. We present a robust collective observability condition, whichdegenerates to the traditional collective observability condition fortime-varying stochastic systems if there is no measurement degradation ormultiplicative noise. Under this condition and strong connectivity, we provethat the mean square errors of two filters are both uniformly upper bounded bya constant matrix over a finite transient time, which depends on the systemobservability and the network size. Different to existing results, somerequirements including stability for the systems and observability of thesub-systems are not needed for our results. Finally, a numerical simulation isprovided to validate the theoretical results."
"614","arXiv:1907.00184","https://arxiv.org/abs/1907.00184","Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery  in Low-resource Settings","Marcely Zanon Boito, Aline Villavicencio, Laurent Besacier","Since Bahdanau et al. [1] first introduced attention for neural machinetranslation, most sequence-to-sequence models made use of attention mechanisms[2, 3, 4]. While they produce soft-alignment matrices that could be interpretedas alignment between target and source languages, we lack metrics to quantifytheir quality, being unclear which approach produces the best alignments. Thispaper presents an empirical evaluation of 3 main sequence-to-sequence models(CNN, RNN and Transformer-based) for word discovery from unsegmented phonemesequences. This task consists in aligning word sequences in a source languagewith phoneme sequences in a target language, inferring from it wordsegmentation on the target side [5]. Evaluating word segmentation quality canbe seen as an extrinsic evaluation of the soft-alignment matrices producedduring training. Our experiments in a low-resource scenario on Mboshi andEnglish languages (both aligned to French) show that RNNs surprisinglyoutperform CNNs and Transformer for this task. Our results are confirmed by anintrinsic evaluation of alignment quality through the use of Average NormalizedEntropy (ANE). Lastly, we improve our best word discovery model by using analignment entropy confidence measure that accumulates ANE over all theoccurrences of a given alignment pair in the collection."
"615","arXiv:1907.00182","https://arxiv.org/abs/1907.00182","Continual Learning for Robotics","Timothée Lesort, Vincenzo Lomonaco, Andrei Stoian, Davide Maltoni, David Filliat, Natalia Díaz-Rodríguez","Continual learning (CL) is a particular machine learning paradigm where thedata distribution and learning objective changes through time, or where all thetraining data and objective criteria are never available at once. The evolutionof the learning process is modeled by a sequence of learning experiences wherethe goal is to be able to learn new skills all along the sequence withoutforgetting what has been previously learned. Continual learning also aims atthe same time at optimizing the memory, the computation power and the speedduring the learning process.An important challenge for machine learning is not necessarily findingsolutions that work in the real world but rather finding stable algorithms thatcan learn in real world. Hence, the ideal approach would be tackling the realworld in a embodied platform: an autonomous agent. Continual learning wouldthen be effective in an autonomous agent or robot, which would learnautonomously through time about the external world, and incrementally develop aset of complex skills and knowledge.Robotic agents have to learn to adapt and interact with their environmentusing a continuous stream of observations. Some recent approaches aim attackling continual learning for robotics, but most recent papers on continuallearning only experiment approaches in simulation or with static datasets.Unfortunately, the evaluation of those algorithms does not provide insights onwhether their solutions may help continual learning in the context of robotics.This paper aims at reviewing the existing state of the art of continuallearning, summarizing existing benchmarks and metrics, and proposing aframework for presenting and evaluating both robotics and non roboticsapproaches in a way that makes transfer between both fields easier."
"616","arXiv:1907.00181","https://arxiv.org/abs/1907.00181","Fake News Detection using Stance Classification: A Survey","Anders Edelbo Lillie, Emil Refsgaard Middelboe","This paper surveys and presents recent academic work carried out within thefield of stance classification and fake news detection. Echo chambers and themodel organism problem are examples that pose challenges to acquire data withhigh quality, due to opinions being polarised in microblogs. Nevertheless it isshown that several machine learning approaches achieve promising results inclassifying stance. Some use crowd stance for fake news detection, such as theapproach in [Dungs et al., 2018] using Hidden Markov Models. Furthermorefeature engineering have significant importance in several approaches, which isshown in [Aker et al., 2017]. This paper additionally includes a proposal of asystem implementation based on the presented survey."
"617","arXiv:1907.00174","https://arxiv.org/abs/1907.00174","The Engineering of Software-Defined Quantum Key Distribution Networks","Alejandro Aguado, Victor Lopez, Diego Lopez, Momtchil Peev, Andreas Poppe, Antonio Pastor, Jesus Folgueira, Vicente Martiin","Quantum computers will change the cryptographic panorama. A technology oncebelieved to lay far away into the future is increasingly closer to real worldapplications. Quantum computers will break the algorithms used in our publickey infrastructure and in our key exchange protocols, forcing a completeretooling of the cryptography as we know it. Quantum Key distribution is aphysical layer technology immune to quantum or classical computational threats.However, it requires a physical substrate, and optical fiber has been the usualchoice. Most of the time used just as a point to point link for the exclusivetransport of the delicate quantum signals. Its integration in a real-worldshared network has not been attempted so far. Here we show how the newprogrammable software network architectures, together with specially designedquantum systems can be used to produce a network that integrates classical andquantum communications, including management, in a single, production-levelinfrastructure. The network can also incorporate new quantum-safe algorithmsand use the existing security protocols, thus bridging the gap between today'snetwork security and the quantum-safe network of the future. This can be donein an evolutionary way, without zero-day migrations and the correspondingupfront costs. We also present how the technologies have been deployed inpractice using a production network."
"618","arXiv:1907.00173","https://arxiv.org/abs/1907.00173","Fast Accurate Beam and Channel Tracking for Two-dimensional Phased  Antenna Array","Yu Liu, Jiahui Li, Xiujun Zhang, Shidong Zhou","The sparsity and the severe attenuation of millimeter-wave (mmWave) channelimply that highly directional communication is needed. The narrow beam causedby large array requires accurate alignment, which can be achieved by beamtraining with large exploration overhead in static scenarios. However, thistraining expense is prohibitive when serving fast-moving users. In this paper,we focus on accurate two-dimensional (2D) beam and channel tracking problem inmmWave mobile communication. The minimum exploration overhead of 2D beam andchannel tracking is given in theory first. Then the channel is divided intothree cases: Quasi-static Case, Dynamic Case I and Dynamic Case II according todifferent time-varying models. We further develop three tracking algorithmscorresponding to these three cases. The proposed algorithms have severalsalient features: (1) fading channel supportive: they can simultaneously trackthe channel gain and 2D beam direction in fading channel environments; (2) lowexploration overhead: they achieve the minimum exploration requirement forjoint beam and channel tracking; (3) fast tracking speed and high trackingaccuracy: in Quasi-static Case and Dynamic Case I, the tracking error is provedto converge to the minimum Cram\'{e}r-Rao lower bound (CRLB). In Dynamic CaseII, our tracking algorithm outperforms existing tracking algorithms with lowertracking error and faster tracking speed in simulation."
"619","arXiv:1907.00172","https://arxiv.org/abs/1907.00172","Model Checking a C++ Software Framework, a Case Study","John Lång, I.S.W.B. Prasetya","This paper presents a case study on applying two model checkers, SPIN andDIVINE, to verify key properties of a C++ software framework, known as ADAPRO,originally developed at CERN. SPIN was used for verifying properties on thedesign level. DIVINE was used for verifying simple test applications thatinteracted with the implementation. Both model checkers were found to havetheir own respective sets of pros and cons, but the overall experience waspositive. Because both model checkers were used in a complementary manner, theyprovided valuable new insights into the framework, which would arguably havebeen hard to gain by traditional testing and analysis tools only. Translatingthe C++ source code into the modeling language of the SPIN model checker helpedto find flaws in the original design. With DIVINE, defects were found in partsof the code base that had already been subject to hundreds of hours of unittests, integration tests, and acceptance tests. Most importantly, modelchecking was found to be easy to integrate into the workflow of the softwareproject and bring added value, not only as verification, but also validationmethodology. Therefore, using model checking for developing library-level codeseems realistic and worth the effort."
"620","arXiv:1907.00168","https://arxiv.org/abs/1907.00168","The CUED's Grammatical Error Correction Systems for BEA-2019","Felix Stahlberg, Bill Byrne","We describe two entries from the Cambridge University Engineering Departmentto the BEA 2019 Shared Task on grammatical error correction. Our submission tothe low-resource track is based on prior work on using finite state transducerstogether with strong neural language models. Our system for the restrictedtrack is a purely neural system consisting of neural language models and neuralmachine translation models trained with back-translation and a combination ofcheckpoint averaging and fine-tuning -- without the help of any additionaltools like spell checkers. The latter system has been used inside a separatesystem combination entry in cooperation with the Cambridge University ComputerLab."
"621","arXiv:1907.00167","https://arxiv.org/abs/1907.00167","A linearly implicit structure-preserving scheme for the Camassa-Holm  equation based on multiple scalar auxiliary variables approach","Chaolong Jiang, Yuezheng Gong, Wenjun Cai, Yushun Wang","In this paper, we present a linearly implicit energy-preserving scheme forthe Camassa-Holm equation by using the multiple scalar auxiliary variablesapproach, which is first developed to construct efficient and robust energystable schemes for gradient systems. The Camassa-Holm equation is firstreformulated into an equivalent system by utilizing the multiple scalarauxiliary variables approach, which inherits a modified energy. Then, thesystem is discretized in space aided by the standard Fourier pseudo-spectralmethod and a semi-discrete system is obtained, which is proven to preserve asemi-discrete modified energy. Subsequently, the linearized Crank-Nicolsonmethod is applied for the resulting semi-discrete system to arrive at a fullydiscrete scheme. The main feature of the new scheme is to form a linear systemwith a constant coefficient matrix at each time step and produce numericalsolutions along which the modified energy is precisely conserved, as is thecase with the analytical solution. Several numerical results are addressed toconfirm accuracy and efficiency of the proposed scheme."
"622","arXiv:1907.00033","https://arxiv.org/abs/1907.00033","Algorithms for weighted independent transversals and strong colouring","Alessandra Graf, David G. Harris, Penny Haxell","An independent transversal (IT) in a graph with a given vertex partition isan independent set consisting of one vertex in each partition class. Severalsufficient conditions are known for the existence of an IT in a given graphwith a given vertex partition, which have been used over the years to solvemany combinatorial problems. Some of these IT existence theorems havealgorithmic proofs, but there remains a gap between the best bounds given bynonconstructive results, and those obtainable by efficient algorithms.Recently, Graf and Haxell (2018) described a new (deterministic) algorithmthat asymptotically closes this gap, but there are limitations on itsapplicability. In this paper we develop a randomized version of this algorithmthat is much more widely applicable, and demonstrate its use by givingefficient algorithms for two problems concerning the strong chromatic number ofgraphs."
"623","arXiv:1907.00164","https://arxiv.org/abs/1907.00164","Privacy Risks of Explaining Machine Learning Models","Reza Shokri, Martin Strobel, Yair Zick","Can we trust black-box machine learning with its decisions? Can we trustalgorithms to train machine learning models on sensitive data? Transparency andprivacy are two fundamental elements of trust for adopting machine learning. Inthis paper, we investigate the relation between interpretability and privacy.In particular we analyze if an adversary can exploit transparent machinelearning to infer sensitive information about its training set. To this end, weperform membership inference as well as reconstruction attacks on two popularclasses of algorithms for explaining machine learning models: feature-based andrecord-based influence measures. We empirically show that an attacker, thatonly observes the feature-based explanations, has the same power as the stateof the art membership inference attacks on model predictions. We alsodemonstrate that record-based explanations can be effectively exploited toreconstruct significant parts of the training set. Finally, our resultsindicate that minorities and special cases are more vulnerable to these type ofattacks than majority groups."
"624","arXiv:1907.00157","https://arxiv.org/abs/1907.00157","Progressive Fashion Attribute Extraction","Sandeep Singh Adhikari, Sukhneer Singh, Anoop Rajagopal, Aruna Rajan","Extracting fashion attributes from images of people wearing clothing/fashionaccessories is a very hard multi-class classification problem. Most often, evencatalogues of fashion do not have all the fine-grained attributes tagged due toprohibitive cost of annotation. Using images of fashion articles, runningmulti-class attribute extraction with a single model for all kinds ofattributes (neck design detailing, sleeves detailing, etc) requires classifiersthat are robust to missing and ambiguously labelled data. In this work, wepropose a progressive training approach for such multi-class classification,where weights learnt from an attribute are fine tuned for another attribute ofthe same fashion article (say, dresses). We branch networks for each attributesfrom a base network progressively during training. While it may have manylabels, an image doesn't need to have all possible labels for fashion articlespresent in it. We also compare our approach to multi-label classification, anddemonstrate improvements over overall classification accuracies using ourapproach."
"625","arXiv:1907.00151","https://arxiv.org/abs/1907.00151","GPT-based Generation for Classical Chinese Poetry","Yi Liao, Yasheng Wang, Qun Liu, Xin Jiang","We present a simple yet effective method for generating high qualityclassical Chinese poetry with Generative Pre-trained Language Model (GPT). Themethod adopts a simple GPT model, without using any human crafted rules orfeatures, or designing any additional neural components. While the proposedmodel learns to generate various forms of classical Chinese poems, includingJueju, L\""{u}shi, various Cipai and Couples, the generated poems are of veryhigh quality. We also propose and implement a method to fine-tune the model togenerate acrostic poetry. To the best of our knowledge, this is the first toemploy GPT in developing a poetry generation system. We will release an onlinedemonstration system in the near future to show the generation capability ofthe proposed method for classical Chinese poetry."
"626","arXiv:1907.00148","https://arxiv.org/abs/1907.00148","Improved ICH classification using task-dependent learning","Amir Bar, Michal Mauda, Yoni Turner, Michal Safadi, Eldad Elnekave","Head CT is one of the most commonly performed imaging studied in theEmergency Department setting and Intracranial hemorrhage (ICH) is among themost critical and timesensitive findings to be detected on Head CT. We presentBloodNet, a deep learning architecture designed for optimal triaging of HeadCTs, with the goal of decreasing the time from CT acquisition to accurate ICHdetection. The BloodNet architecture incorporates dependency between theotherwise independent tasks of segmentation and classification, achievingimproved classification results. AUCs of 0.9493 and 0.9566 are reported on heldout positive-enriched and randomly sampled sets comprised of over 1400 studiesacquired from over 10 different hospitals. These results are comparable topreviously reported results with smaller number of tagged studies."
"627","arXiv:1907.00146","https://arxiv.org/abs/1907.00146","DataPop: Knowledge Base Population using Distributed Voice Enabled  Devices","Elena Montes, Monique Shotande, Daniel Helm, Christan Grant","Data scientists are constantly creating methods to efficiently and accuratelypopulate big data sets for use in large-scale applications. Many recent effortsutilize crowd-sourcing and textual interfaces. In this paper, we propose a newmethod of curating data; namely, creating a multi-device Amazon Alexa Skill inthe form of a research trivia game. Users experience a synchronized gamingexperience with other Amazon Echo users, competing against one another whilefilling in gaps of a connected knowledge base. This allows for fullexploitation of the speed improvement offered by voice interface technology ina game-based format."
"628","arXiv:1907.00143","https://arxiv.org/abs/1907.00143","Análise Estática de Código-Fonte","Joenio Marques da Costa","This article presents a theoretical summary of the source code staticanalysis, its definition, uses and applications, how static analysis isperformed, their intermediate representation formats, models and most commonanalysis techniques, ends up presenting a set of free and freely availabledownloadable static analysis tools, academic software tools developed byscientists during their research work (The paper is written in BrazillianPortuguese)."
"629","arXiv:1907.00141","https://arxiv.org/abs/1907.00141","Approximate Inference in Structured Instances with Noisy Categorical  Observations","Alireza Heidari, Ihab F. Ilyas, Theodoros Rekatsinas","We study the problem of recovering the latent ground truth labeling of astructured instance with categorical random variables in the presence of noisyobservations. We present a new approximate algorithm for graphs withcategorical variables that achieves low Hamming error in the presence of noisyvertex and edge observations. Our main result shows a logarithmic dependency ofthe Hamming error to the number of categories of the random variables. Ourapproach draws connections to correlation clustering with a fixed number ofclusters. Our results generalize the works of Globerson et al. (2015) andFoster et al. (2018), who study the hardness of structured prediction underbinary labels, to the case of categorical labels."
"630","arXiv:1907.00038","https://arxiv.org/abs/1907.00038","The Practical Challenges of Active Learning: Lessons Learned from Live  Experimentation","Jean-François Kagy, Tolga Kayadelen, Ji Ma, Afshin Rostamizadeh, Jana Strnadova","We tested in a live setting the use of active learning for selecting textsentences for human annotations used in training a Thai segmentation machinelearning model. In our study, two concurrent annotated samples wereconstructed, one through random sampling of sentences from a text corpus, andthe other through model-based scoring and ranking of sentences from the samecorpus. In the course of the experiment, we observed the effect of significantchanges to the learning environment which are likely to occur in real-worldlearning tasks. We describe how our active learning strategy interacted withthese events and discuss other practical challenges encountered in using activelearning in the live setting."
"631","arXiv:1907.00140","https://arxiv.org/abs/1907.00140","Planting Trees for scalable and efficient Canonical Hub Labeling","Kartik Lakhotia, Qing Dong, Rajgopal Kannan, Viktor Prasanna","Point-to-Point Shortest Distance (PPSD) query is a crucial primitive in graphdatabase applications. Hub labeling algorithms compute a labeling that convertsa PPSD query into a list intersection problem (over a pre-computed indexing)enabling swift query response. However, constructing hub labeling iscomputationally challenging. Even state-of-the-art parallel algorithms based onPruned Landmark Labeling (PLL) [3], are plagued by large label size, violationof given network hierarchy, poor scalability and inability to process largegraphs.In this paper, we develop novel parallel shared-memory and distributed-memoryalgorithms for constructing the Canonical Hub Labeling (CHL) that is minimal insize for a given network hierarchy. To the best of our knowledge, none of theexisting parallel algorithms guarantee canonical labeling. Our keycontribution, the PLaNT algorithm, scales well beyond the limits of currentpractice by completely avoiding inter-node communication. PLaNT also enablesthe design of a collaborative label partitioning scheme across multiple nodesfor completely in-memory processing of massive graphs whose labels cannot fiton a single machine.Compared to the sequential PLL, we empirically demonstrate upto 47.4x speedupon a 72 thread shared-memory platform. On a 64-node cluster, PLaNT achieves anaverage 42x speedup over single node execution. Finally, we show how ourapproach demonstrates superior scalability - we can process 14x larger graphs(in terms of label size) and construct hub labeling orders of magnitude fastercompared to state-of-the-art distributed paraPLL algorithm."
"632","arXiv:1907.00139","https://arxiv.org/abs/1907.00139","Fast Convolutive Nonnegative Matrix Factorization Through Coordinate and  Block Coordinate Updates","Anthony Degleris, Ben Antin, Surya Ganguli, Alex H Williams","Identifying recurring patterns in high-dimensional time series data is animportant problem in many scientific domains. A popular model to achieve thisis convolutive nonnegative matrix factorization (CNMF), which extends classicnonnegative matrix factorization (NMF) to extract short-lived temporal motifsfrom a long time series. Prior work has typically fit this model bymultiplicative parameter updates---an approach widely considered to besuboptimal for NMF, especially in large-scale data applications. Here, wedescribe how to extend two popular and computationally scalable NMFalgorithms---Hierarchical Alternating Least Squares (HALS) and AlternatiningNonnegative Least Squares (ANLS)---for the CNMF model. Both methods demonstrateperformance advantages over multiplicative updates on large-scale synthetic andreal world data."
"633","arXiv:1907.00138","https://arxiv.org/abs/1907.00138","Approximate matrix completion based on cavity method","Chihiro Noguchi, Yoshiyuki Kabashima","In order to solve large matrix completion problems with practicalcomputational cost, an approximate approach based on matrix factorization hasbeen widely used. Alternating least squares (ALS) and stochastic gradientdescent (SGD) are two major algorithms to this end. In this study, we propose anew algorithm, namely cavity-based matrix factorization (CBMF) and approximatecavity-based matrix factorization (ACBMF), which are developed based on thecavity method from statistical mechanics. ALS yields solutions with lessiterations when compared to those of SGD. This is because its update rules aredescribed in a closed form although it entails higher computational cost. CBMFcan also write its update rules in a closed form, and its computational cost islower than that of ALS. ACBMF is proposed to compensate a disadvantage of CBMFin terms of relatively high memory cost. We experimentally illustrate that theproposed methods outperform the two existing algorithms in terms of convergencespeed per iteration, and it can work under the condition where observed entriesare relatively fewer. Additionally, in contrast to SGD, (A)CBMF does notrequire scheduling of the learning rate."
"634","arXiv:1907.00135","https://arxiv.org/abs/1907.00135","RFBNet: Deep Multimodal Networks with Residual Fusion Blocks for RGB-D  Semantic Segmentation","Liuyuan Deng, Ming Yang, Tianyi Li, Yuesheng He, Chunxiang Wang","Signals from RGB and depth data carry complementary information about thescene. Conventional RGB-D semantic segmentation methods adopt two-stream fusionstructure which uses two modality-specific encoders to extract features fromthe RGB and depth data. There is currently no explicit mechanism to model theinterdependencies between the encoders. This letter proposes a novel bottom-upinteractive fusion structure which introduces an interaction stream to bridgethe modality-specific encoders. The interaction stream progressively aggregatesmodality-specific features from the encoders and computes complementaryfeatures for the encoders. To instantiate this structure, the letter proposes aresidual fusion block (RFB) to formulate the interdependences of the encoders.The RFB consists of two residual units and one fusion unit with gate mechanism.It learns complementary features for the modality-specific encoders andextracts modality-specific features as well as cross-modal features. Based onthe RFB, the letter presents the deep multimodal networks for RGB-D semanticsegmentation called RFBNet. The experiments conducted on two datasetsdemonstrate the effectiveness of modeling the interdependencies and that theRFBNet outperforms state-of-the-art methods."
"635","arXiv:1907.00124","https://arxiv.org/abs/1907.00124","Helion: Enabling a Natural Perspective of Home Automation","Sunil Manandhar, Kevin Moran, Kaushal Kafle, Ruhao Tang, Denys Poshyvanyk, Adwait Nadkarni","Security researchers have recently discovered significant security and safetyissues related to home automation and developed approaches to address them.Such approaches often face design and evaluation challenges which arise fromtheir restricted perspective of home automation that is bounded by the IoT appsthey analyze. The challenges of past work can be overcome by relying on adeeper understanding of realistic home automation usage. More specifically, theavailability of natural home automation scenarios, i.e., sequences of homeautomation events that may realistically occur in an end-user's home, couldhelp security researchers design better security/safety systems. This paperpresents Helion, a framework for building a natural perspective of homeautomation. Helion identifies the regularities in user-driven home automation,i.e., from user-driven routines that are increasingly being created by usersthrough intuitive platform UIs. Our intuition for designing Helion is thatsmart home event sequences created by users exhibit an inherent set of semanticpatterns, or naturalness that can be modeled and used to generate valid anduseful scenarios. To evaluate our approach, we first empirically demonstratethat this naturalness hypothesis holds, with a corpus of 30,518 home automationevents, constructed from 273 routines collected from 40 users. We thendemonstrate that the scenarios generated by Helion are reasonable and validfrom an end-user perspective, through an evaluation with 16 externalevaluators. We further show the usefulness of Helion's scenarios by generating17 home security/safety policies with significantly less effort than existingapproaches. We conclude by discussing key takeaways and future researchchallenges enabled by Helion's natural perspective of home automation."
"636","arXiv:1907.00123","https://arxiv.org/abs/1907.00123","Deep Reinforcement Learning for 5G Networks: Joint Beamforming, Power  Control, and Interference Coordination","Faris B. Mismar, Brian L. Evans, Ahmed Alkhateeb","The fifth generation of wireless communications (5G) promises massiveincreases in traffic volume and data rates, as well as improved reliability invoice calls. Jointly optimizing beamforming, power control, and interferencecoordination in a 5G wireless network to enhance the communication performanceto end users poses a significant challenge. In this paper, we formulate thejoint design of beamforming, power control, and interference coordination tomaximize the signal to interference plus noise ratio (SINR) and solve thenon-convex problem using deep reinforcement learning. By using the greedynature of deep Q-learning to estimate future benefits of actions, we propose analgorithm for voice bearers in sub-6 GHz bands and data bearers in millimeterwave (mmWave) frequency bands. The algorithm exploits reported SINR fromconnected users, the transmit powers of the base stations, and the coordinatesof the connected users to improve the performance measured by coverage andsumrate capacity. The proposed algorithm does not require the channel stateinformation and removes the need for channel estimation. Simulation resultsshow that our algorithm outperforms the link adaptation industry standards forsub-6 GHz voice bearers and approaches the optimal limits for mmWave databearers for small antenna sizes in realistic cellular environments."
"637","arXiv:1907.00119","https://arxiv.org/abs/1907.00119","One Size Does Not Fit All: Modeling Users' Personal Curiosity in  Recommender Systems","Fakhri Abbas, Xi Niu","Today's recommender systems are criticized for recommending items that aretoo obvious to arouse users' interest. That's why the recommender systemsresearch community has advocated some ""beyond accuracy"" evaluation metrics suchas novelty, diversity, coverage, and serendipity with the hope of promotinginformation discovery and sustain users' interest over a long period of time.While bringing in new perspectives, most of these evaluation metrics have notconsidered individual users' difference: an open-minded user may favor highlynovel or diversified recommendations whereas a conservative user's appetite fornovelty or diversity may not be that large. In this paper, we developed a modelto approximate an individual's curiosity distribution over different levels ofstimuli guided by the well-known Wundt curve in Psychology. We measured anitem's surprise level to assess the stimulation level and whether it is in therange of the user's appetite for stimulus. We then proposed a recommendationsystem framework that considers both user preference and appetite for stimuluswhere the curiosity is maximally aroused. Our framework differs from a typicalrecommender system in that it leverages human's curiosity to promote intrinsicinterest with the system. A series of evaluation experiments have beenconducted to show that our framework is able to rank higher the items with notonly high ratings but also high response likelihood. The recommendation listgenerated by our algorithm has higher potential of inspiring user curiositycompared to traditional approaches. The personalization factor for assessingthe stimulus (surprise) strength further helps the recommender achieve smaller(better) inter-user similarity."
"638","arXiv:1907.00117","https://arxiv.org/abs/1907.00117","Min-Max Correlation Clustering via MultiCut","Saba Ahmadi, Sainyam Galhotra, Samir Khuller, Barna Saha, Roy Schwartz","Correlation clustering is a fundamental combinatorial optimization problemarising in many contexts and applications that has been the subject of dozensof papers in the literature. In this problem we are given a general weightedgraph where each edge is labeled positive or negative. The goal is to obtain apartitioning (clustering) of the vertices that minimizes disagreements - weightof negative edges trapped inside a cluster plus positive edges betweendifferent clusters. Most of the papers on this topic mainly focus on minimizingtotal disagreement, a global objective for this problem. In this paper, westudy a cluster-wise objective function that asks to minimize the maximumnumber of disagreements of each cluster, which we call min-max correlationclustering. The min-max objective is a natural objective that respects thequality of every cluster. In this paper, we provide the first nontrivialapproximation algorithm for this problem achieving an $\mathcal{O}(\sqrt{\logn\cdot\max\{\log(|E^-|),\log(k)\}})$ approximation for general weighted graphs,where $|E^-|$ denotes the number of negative edges and $k$ is the number ofclusters in the optimum solution. To do so, we also obtain a correspondingresult for multicut where we wish to find a multicut solution while trying tominimize the total weight of cut edges on every component. The results are thenfurther improved to obtain (i) $\mathcal{O}(r^2)$-approximation for min-maxcorrelation clustering and min-max multicut for graphs that exclude $K_{r,r}$minors (ii) a 14-approximation for the min-max correlation clustering oncomplete graphs."
"639","arXiv:1907.00112","https://arxiv.org/abs/1907.00112","Leveraging Acoustic Cues and Paralinguistic Embeddings to Detect  Expression from Voice","Vikramjit Mitra, Sue Booker, Erik Marchi, David Scott Farrar, Ute Dorothea Peitz, Bridget Cheng, Ermine Teves, Anuj Mehta, Devang Naik","Millions of people reach out to digital assistants such as Siri every day,asking for information, making phone calls, seeking assistance, and much more.The expectation is that such assistants should understand the intent of theusers query. Detecting the intent of a query from a short, isolated utteranceis a difficult task. Intent cannot always be obtained from speech-recognizedtranscriptions. A transcription driven approach can interpret what has beensaid but fails to acknowledge how it has been said, and as a consequence, mayignore the expression present in the voice. Our work investigates whether asystem can reliably detect vocal expression in queries using acoustic andparalinguistic embedding. Results show that the proposed method offers arelative equal error rate (EER) decrease of 60% compared to a bag-of-word basedsystem, corroborating that expression is significantly represented by vocalattributes, rather than being purely lexical. Addition of emotion embeddinghelped to reduce the EER by 30% relative to the acoustic embedding,demonstrating the relevance of emotion in expressive voice."
"640","arXiv:1907.00109","https://arxiv.org/abs/1907.00109","SetGANs: Enforcing Distributional Accuracy in Generative Adversarial  Networks","Alessandro Ferrero, Shireen Elhabian, Ross Whitaker","This paper addresses the ability of generative adversarial networks (GANs) tomodel complex distributions of data in high-dimensional spaces. Our propositionis that the more effective the adversary is in discriminating the output of thegenerator, the more effective the generator will be at modeling (or generating)the distribution represented by the training data. The most extreme failure ofGANs in this context is mode collapse, and there are several proposed methodsto address that problem. However, mode collapse is merely a symptom of a moregeneral problem of GANs, where the generator fools the adversary while failingto faithfully model the distribution of the training data. Here, we address thechallenge of constructing and evaluating GANs that more effectively representthe input distribution. We introduce an adversarial architecture that processessets of generated and real samples, and discriminates between the origins ofthese sets (i.e., training versus generated data) in a flexible, permutationinvariant manner. We present quantitative and qualitative results thatdemonstrate the effectiveness of this approach relative to state-of-the-artmethods for avoiding mode collapse."
"641","arXiv:1907.00107","https://arxiv.org/abs/1907.00107","Adaptive Sequential Experiments with Unknown Information Flows","Yonatan Gur, Ahmadreza Momeni","Systems that make sequential decisions in the presence of partial feedback onactions often need to strike a balance between maximizing immediate payoffsbased on available information, and acquiring new information that may beessential for maximizing future payoffs. This trade-off is captured by themulti-armed bandit (MAB) framework that has been studied and applied fordesigning sequential experiments when at each time epoch a single observationis collected on the action that was selected at that epoch. However, in manypractical settings additional information may become available between decisionepochs. We introduce a generalized MAB formulation in which auxiliaryinformation on each arm may appear arbitrarily over time. By obtaining matchinglower and upper bounds, we characterize the minimax complexity of this familyof MAB problems as a function of the information arrival process, and study howsalient characteristics of this process impact policy design and achievableperformance. We establish the robustness of a Thompson sampling policy in thepresence of additional information, but observe that other policies that are ofpractical importance do not exhibit such robustness. We therefore introduce abroad adaptive exploration approach for designing policies that, without anyprior knowledge on the information arrival process, attain the best performance(in terms of regret rate) that is achievable when the information arrivalprocess is a priori known. Our approach is based on adjusting MAB policiesdesigned to perform well in the absence of auxiliary information by usingdynamically customized virtual time indexes to endogenously control theexploration rate of the policy. We demonstrate our approach throughappropriately adjusting known MAB policies and establishing improvedperformance bounds for these policies in the presence of auxiliary information."
"642","arXiv:1907.00106","https://arxiv.org/abs/1907.00106","Smart Charging Benefits in Autonomous Mobility on Demand Systems","Berkay Turan, Nathaniel Tucker, Mahnoosh Alizadeh","In this paper, we study the potential benefits from smart charging for afleet of electric vehicles (EVs) providing autonomous mobility-on-demand (AMoD)services. We first consider a profit-maximizing platform operator who makesdecisions for routing, charging, rebalancing, and pricing for rides based on anetwork flow model. Clearly, each of these decisions directly influence thefleet's smart charging potential; however, it is not possible to directlycharacterize the effects of various system parameters on smart charging under aclassical network flow model. As such, we propose a modeling variation thatallows us to decouple the charging and routing problems faced by the operator.This variation allows us to provide closed-form mathematical expressionsrelating the charging costs to the maximum battery capacity of the vehicles aswell as the fleet operational costs. We show that investing in larger batterycapacities and operating more vehicles for rebalancing reduces the chargingcosts, while increasing the fleet operational costs. Hence, we study thetrade-off the operator faces, analyze the minimum cost fleet charging strategy,and provide numerical results illustrating the smart charging benefits to theoperator."
"643","arXiv:1907.00025","https://arxiv.org/abs/1907.00025","Angular separability of data clusters or network communities in  geometrical space and its relevance to hyperbolic embedding","Alessandro Muscoloni, Carlo Vittorio Cannistraci","Analysis of 'big data' characterized by high-dimensionality such as wordvectors and complex networks requires often their representation in ageometrical space by embedding. Recent developments in machine learning andnetwork geometry have pointed out the hyperbolic space as a useful frameworkfor the representation of this data derived by real complex physical systems.In the hyperbolic space, the radial coordinate of the nodes characterizes theirhierarchy, whereas the angular distance between them represents theirsimilarity. Several studies have highlighted the relationship between theangular coordinates of the nodes embedded in the hyperbolic space and thecommunity metadata available. However, such analyses have been often limited toa visual or qualitative assessment. Here, we introduce the angular separationindex (ASI), to quantitatively evaluate the separation of node networkcommunities or data clusters over the angular coordinates of a geometricalspace. ASI is particularly useful in the hyperbolic space - where it isextensively tested along this study - but can be used in general for anyassessment of angular separation regardless of the adopted geometry. ASI isproposed together with an exact test statistic based on a uniformly random nullmodel to assess the statistical significance of the separation. We show thatASI allows to discover two significant phenomena in network geometry. The firstis that the increase of temperature in 2D hyperbolic network generative models,not only reduces the network clustering but also induces a 'dimensionalityjump' of the network to dimensions higher than two. The second is that ASI canbe successfully applied to detect the intrinsic dimensionality of networkstructures that grow in a hidden geometrical space."
"644","arXiv:1907.00028","https://arxiv.org/abs/1907.00028","Classification of glomerular hypercellularity using convolutional  features and support vector machine","Paulo Chagas, Luiz Souza, Ikaro Araújo, Nayze Aldeman, Angelo Duarte, Michele Angelo, Washington LC dos-Santos, Luciano Oliveira","Glomeruli are histological structures of the kidney cortex formed byinterwoven blood capillaries, and are responsible for blood filtration.Glomerular lesions impair kidney filtration capability, leading to protein lossand metabolic waste retention. An example of lesion is the glomerularhypercellularity, which is characterized by an increase in the number of cellnuclei in different areas of the glomeruli. Glomerular hypercellularity is afrequent lesion present in different kidney diseases. Automatic detection ofglomerular hypercellularity would accelerate the screening of scannedhistological slides for the lesion, enhancing clinical diagnosis. Having thisin mind, we propose a new approach for classification of hypercellularity inhuman kidney images. Our proposed method introduces a novel architecture of aconvolutional neural network (CNN) along with a support vector machine,achieving near perfect average results with the FIOCRUZ data set in a binaryclassification (lesion or normal). Our deep-based classifier outperformed thestate-of-the-art results on the same data set. Additionally, classification ofhypercellularity sub-lesions was also performed, considering mesangial,endocapilar and both lesions; in this multi-classification task, our proposedmethod just failed in 4\% of the cases. To the best of our knowledge, this isthe first study on deep learning over a data set of glomerular hypercellularityimages of human kidney."
"645","arXiv:1907.00031","https://arxiv.org/abs/1907.00031","The Thermodynamic Variational Objective","Vaden Masrani, Tuan Anh Le, Frank Wood","We introduce the thermodynamic variational objective (TVO) for learning inboth continuous and discrete deep generative models. The TVO arises from a keyconnection between variational inference and thermodynamic integration thatresults in a tighter lower bound to the log marginal likelihood than thestandard variational evidence lower bound (ELBO), while remaining as broadlyapplicable. We provide a computationally efficient gradient estimator for theTVO that applies to continuous, discrete, and non-reparameterizabledistributions and show that the objective functions used in variationalinference, variational autoencoders, wake sleep, and inference compilation areall special cases of the TVO. We evaluate the TVO for learning of discrete andcontinuous variational auto encoders, and find it achieves state of the art forlearning in discrete variable models, and outperform VAEs on continuousvariable models without using the reparameterization trick."
"646","arXiv:1907.00039","https://arxiv.org/abs/1907.00039","The Branching-Course MPC Algorithm for Maritime Collision Avoidance","Bjørn-Olav H. Eriksen, Morten Breivik, Erik F. Wilthil, Andreas L. Flåten, Edmund F. Brekke","This article presents a new algorithm for short-term maritime collisionavoidance (COLAV) named the branching-course MPC (BC-MPC) algorithm. Thealgorithm is designed to be robust with respect to noise on obstacle estimates,which is a significant source of disturbance when using exteroceptive sensorssuch as e.g. radars for obstacle detection and tracking. Exteroceptive sensorsdo not require vessel-to-vessel communication, which enables COLAV towardvessels not equipped with e.g. automatic identification system (AIS)transponders, in addition to increasing the robustness with respect to faultyinformation which may be provided by other vessels. The BC-MPC algorithm iscompliant with rules 8 and 17 of the International Regulations for PreventingCollisions at Sea (COLREGs), and favors maneuvers following rules 13-15. Thisresults in a COLREGs-aware algorithm which can ignore rules 13-15 whennecessary. The algorithm is experimentally validated in several full-scaleexperiments in the Trondheimsfjord in 2017 using a radar-based system forobstacle detection and tracking. The COLAV experiments show good performance incompliance with the desired algorithm behavior."
"647","arXiv:1907.00042","https://arxiv.org/abs/1907.00042","Rhythm Dungeon: A Blockchain-based Music Roguelike Game","Tengfei Wang, Shuyi Zhang, Xiao Wu, Wei Cai","Rhythm Dungeon is a rhythm game which leverages the blockchain as a sharedopen database. During the gaming session, the player explores a roguelikedungeon by inputting specific sequences in time to music rhythm. By integratingsmart contract to the game program, the enemies through the venture aregenerated from other games which share the identical blockchain. On the otherhand, the player may upload their characters at the end of their journey, sothat their own character may appear in other games and make an influence.Rhythm Dungeon is designed and implemented to show the potential ofdecentralized gaming experience, which utilizes the blockchain to provideasynchronous interactions among massive players."
"648","arXiv:1907.00048","https://arxiv.org/abs/1907.00048","Bridging the Architecture Gap: Abstracting Performance-Relevant  Properties of Modern Server Processors","Johannes Hofmann, Christie L. Alappat, Georg Hager, Dietmar Fey, Gerhard Wellein","We describe a universal modeling approach for predicting single- andmulticore runtime of steady-state loops on server processors. To this end westrictly differentiate between application and machine models: An applicationmodel comprises the loop code, problem sizes, and other runtime parameters,while a machine model is an abstraction of all performance-relevant propertiesof a CPU. We introduce a generic method for determining machine models andpresent results for relevant server-processor architectures by Intel, AMD, IBM,and Marvell/Cavium. Considering this wide range of architectures, the set offeatures required for adequate performance modeling is surprisingly small. Tovalidate our approach, we compare performance predictions to empirical data foran OpenMP-parallel preconditioned CG algorithm, which includes compute- andmemory-bound kernels. Both single- and multicore analysis shows that the modelexhibits average and maximum relative errors of 5% and 10%. Deviations from themodel and insights gained are discussed in detail."
"649","arXiv:1907.00050","https://arxiv.org/abs/1907.00050","State-of-the-Art on Query & Transaction Processing Acceleration","Bernd Amann, Youry Khmelevsky, Gaetan Hains","The vast amount of processing power and memory bandwidth provided by modernGraphics Processing Units (GPUs) make them a platform for data-intensiveapplications. The database community identified GPUs as effective co-processorsfor data processing. In the past years, there were many approaches to make useof GPUs at different levels of a database system. In this Internal TechnicalReport, based on the [1] and some other research papers, we identify possibleresearch areas at LIP6 for GPU-accelerated database management systems. Wedescribe some key properties, typical challenges of GPU-aware databasearchitectures, and identify major open challenges."
"650","arXiv:1907.00053","https://arxiv.org/abs/1907.00053","Composable Rate-Independent Computation in Continuous Chemical Reaction  Networks","Cameron Chalk, Niels Kornerup, Wyatt Reeves, David Soloveichik","Biological regulatory networks depend upon chemical interactions to processinformation. Engineering such molecular computing systems is a major challengefor synthetic biology and related fields. The chemical reaction network (CRN)model idealizes chemical interactions, allowing rigorous reasoning aboutcomputational power of chemical kinetics. Here we focus on function computationwith CRNs, where we think of the initial concentrations of some species as theinput and the equilibrium concentration of another species as the output.Specifically, we are concerned with CRNs that are rate-independent (thecomputation must be correct independent of the reaction rate law) andcomposable ($f \circ g$) can be computed by concatenating the CRNs computing$f$ and $g$). Rate independence and composability are important engineeringdesiderata, permitting implementations that violate mass-action kinetics, oreven ""well-mixedness"", and allowing the systematic construction of complexcomputation via modular design. We show that to construct composablerate-independent CRNs, it is necessary and sufficient to ensure that the outputspecies of a module is not areactant in any reaction within the module. We thenexactly characterize the functions computable by such CRNs assuperadditive,positive-continuous, and piecewise rational linear. Thuscomposability severely limits rate-independent computation unless moresophisticated input/output encodings are used."
"651","arXiv:1907.00056","https://arxiv.org/abs/1907.00056","Extending de Bruijn sequences to larger alphabets","Verónica Becher, Lucas Cortés","A circular de Bruijn sequence of order $n$ in an alphabet of $k$ symbols is asequence in which each sequence of length $n$ occurs exactly once. In this workwe show that for each circular de Bruijn sequence $v$ of order $n$ in analphabet of $k$ symbols there is another circular de Bruijn sequence $w$ alsoof order $n$ in an alphabet with one more symbol, that is an alphabet of $k +1$ symbols, such that $v$ is a subsequence of $w$ and in between any twosuccessive occurrences of the new symbol in $w$ there are at most $n + 2k-2$consecutive symbols of $v$. We give an algorithm that receives as input such asequence $v$ and outputs a sequence $w$. We also give a much faster algorithmthat receives as input such a sequence $v$ and outputs a sequence $w$, but thenew symbol may not be evenly spread out."
"652","arXiv:1907.00074","https://arxiv.org/abs/1907.00074","Forensic Analysis of Third Party Location Applications in Android and  iOS","Jason Bays, Umit Karabiyik","Location sharing applications are becoming increasingly common. Theseapplications allow users to share their own locations and view contacts'current locations on a map. Location applications are commonly used by friendsand family members to view Global Positioning System (GPS) location of anindividual, but valuable forensic evidence may exist in this data when storedlocally on smartphones. This paper aims to discover forensic artifacts from twopopular third-party location sharing applications on iOS and Android devices.Industry standard mobile forensic suites are utilized to discover if anylocally stored data could be used to assist investigations reliant on knowingthe past location of a suspect. Security issues raised regarding the artifactsfound during our analysis is also discussed."
"653","arXiv:1907.00058","https://arxiv.org/abs/1907.00058","Explainable Shape Analysis through Deep Hierarchical Generative Models:  Application to Cardiac Remodeling","Carlo Biffi, Juan J. Cerrolaza, Giacomo Tarroni, Wenjia Bai, Ozan Oktay, Loic Le Folgoc, Konstantinos Kamnitsas, Antonio de Marvao, Georgia Doumou, Jinming Duan, Sanjay K. Prasad, Stuart A. Cook, Declan P. O'Regan, Daniel Rueckert","Quantification of anatomical shape changes still relies on scalar globalindexes which are largely insensitive to regional or asymmetric modifications.Accurate assessment of pathology-driven anatomical remodeling is a crucial stepfor the diagnosis and treatment of heart conditions. Deep learning approacheshave recently achieved wide success in the analysis of medical images, but theylack interpretability in the feature extraction and decision processes. In thiswork, we propose a new interpretable deep learning model for shape analysis. Inparticular, we exploit deep generative networks to model a population ofanatomical segmentations through a hierarchy of conditional latent variables.At the highest level of this hierarchy, a two-dimensional latent space issimultaneously optimised to discriminate distinct clinical conditions, enablingthe direct visualisation of the classification space. Moreover, the anatomicalvariability encoded by this discriminative latent space can be visualised inthe segmentation space thanks to the generative properties of the model, makingthe classification task transparent. This approach yielded high accuracy in thecategorisation of healthy and remodelled hearts when tested on unseensegmentations from our own multi-centre dataset as well as in an externalvalidation set. More importantly, it enabled the visualisation inthree-dimensions of the most discriminative anatomical features between the twoconditions. The proposed approach scales effectively to large populations,facilitating high-throughput analysis of normal anatomy and pathology inlarge-scale studies of volumetric imaging."
"654","arXiv:1907.00061","https://arxiv.org/abs/1907.00061","Complexity of acyclic colorings of graphs and digraphs with degree and  girth constraints","Tom\' as Feder, Pavol Hell, Carlos Subi","We consider acyclic r-colorings in graphs and digraphs: they color thevertices in r colors, each of which induces an acyclic graph or digraph. (Thisincludes the dichromatic number of a digraph, and the arboricity of a graph.)For any girth and sufficiently high degree, we prove the NP-completeness ofacyclic r-colorings; our method also implies the known analogue for classicalcolorings. The proofs use high girth graphs with high arboricity anddichromatic numbers. High girth graphs and digraphs with high chromatic anddichromatic numbers have been well studied; we re-derive the results from ageneral result about relational systems, which also implies the similar factabout high girth and high arboricity used in the proofs. These facts concerngraphs and digraphs of high girth and low degree; we contrast them byconsidering acyclic colorings of tournaments (which have low girth and highdegree). We prove that even though acyclic two-colorability of tournaments isknown to be NP-complete, random acyclically r-colorable tournaments allowrecovering an acyclic r-coloring in deterministic linear time, with highprobablity."
"655","arXiv:1907.00062","https://arxiv.org/abs/1907.00062","DIEL: Transparent Scaling for Interactive Visualization","Yifan Wu, Remco Chang, Eugene Wu, Joseph M. Hellerstein","We live in an era of big data and rich data visualization. As data setsincrease in size, browser-based interactive visualizations eventually hitlimits in storage and processing capacity. In order to provide interactivityover large datasets, visualization applications typically need to beextensively rewritten to make use of powerful back-end services. It would befar preferable if front-end developers could write visualizations once in anatural way, and have a framework take responsibility for transparently scalingup the visualization to use back-end services as needed. Achieving this goalrequires rethinking how communication and state are managed by the framework:the mapping of interaction logic to server APIs or database queries, handlingof results arriving asynchronously over the network, as well as basiccross-layer performance optimizations like caching.In this paper, we present DIEL, a framework that achieves this cross-layerautoscaling transparently under a simple, declarative interface. DIEL treats UIevents as a stream of data that is captured in an event history for reuse.Developers declare what the state of the interface should be after the arrivalof events. DIEL compiles these declarative specifications into relationalqueries over both event history and the data to be visualized. In doing so,DIEL makes it easier to develop visualizations that are robust against changesto the size and location of data. To evaluate the DIEL framework, we developeda prototype implementation and confirmed that DIEL supports a range ofvisualization and interaction designs. Visualizations written using DIEL cantransparently and seamlessly scale to use back-end services with littleintervention from the developer."
"656","arXiv:1907.00068","https://arxiv.org/abs/1907.00068","On Reducing Negative Jacobian Determinant of the Deformation Predicted  by Deep Registration Networks","Dongyang Kuang","Image registration is a fundamental step in medical image analysis. Ideally,the transformation that registers one image to another should be adiffeomorphism that is both invertible and smooth. Traditional methods likegeodesic shooting approach the problem via differential geometry, withtheoretical guarantees that the resulting transformation will be smooth andinvertible. Most previous research using unsupervised deep neural networks forregistration have used a local smoothness constraint (typically, a spatialvariation loss) to address the smoothness issue. These networks usually producenon-invertible transformations with ``folding'' in multiple voxel locations,indicated by a negative determinant of the Jacobian matrix of thetransformation. While using a loss function that specifically penalizes thefolding is a straightforward solution, this usually requires carefully tuningthe regularization strength, especially when there are also other losses. Inthis paper we address this problem from a different angle, by investigatingpossible training mechanisms that will help the network avoid negativeJacobians and produce smoother deformations. We contribute two independentideas in this direction. Both ideas greatly reduce the number of foldinglocations in the predicted deformation, without making changes to thehyperparameters or the architecture used in the existing baseline registrationnetwork."
"657","arXiv:1907.00069","https://arxiv.org/abs/1907.00069","A 1d convolutional network for leaf and time series classification","Dongyang Kuang","In this paper, a 1d convolutional neural network is designed forclassification tasks of leaves with centroid contour distance curve (CCDC) asthe single feature. With this classifier, simple feature as CCDC shows morediscriminating power than people thought previously. The same architecture canalso be applied for classifying 1 dimensional time series with little changes.Experiments on some benchmark datasets shows this architecture can provideclassification accuracies that are higher than some existing methods. Code forthe paper is available at https://github.com/dykuang/Leaf Project."
"658","arXiv:1907.00072","https://arxiv.org/abs/1907.00072","Polynomial Preconditioned GMRES to Reduce Communication in Parallel  Computing","Jennifer A. Loe, Heidi K. Thornquist, Erik G. Boman","Polynomial preconditioning with the GMRES minimal residual polynomial has thepotential to greatly reduce orthogonalization costs, making it useful forcommunication reduction. We implement polynomial preconditioning in the Belospackage from Trilinos and show how it can be effective in both serial andparallel implementations. We further show it is a communication-avoidingtechnique and is a viable option to CA-GMRES for large-scale parallelcomputing."
"659","arXiv:1907.00075","https://arxiv.org/abs/1907.00075","Programming with Timespans in Interactive Visualizations","Yifan Wu, Remco Chang, Eugene Wu, Joe Hellerstein","Modern interactive visualizations are akin to distributed systems, where userinteractions, background data processing, remote requests, and streaming dataread and modify the interface at the same time. This concurrency is crucial toprovide an interactive user experience---forbidding it can crippleresponsiveness. However, it is notoriously challenging to program distributedsystems, and concurrency can easily lead to ambiguous or confusing interfacebehaviors. In this paper, we present DIEL, a declarative programming model tohelp developers reason about and reconcile concurrency-related issues. UsingDIEL, developers no longer need to procedurally describe how the interfaceshould update based on different input events, but rather declaratively specifywhat the state of the interface should be as queries over event history. Weshow that resolving conflicts from concurrent processes in real-worldinteractive visualizations can be done in a few lines of DIEL code."
"660","arXiv:1907.00082","https://arxiv.org/abs/1907.00082","Millemeter-Wave Fixed Wireless Access Using IEEE 802.11ay","Cheng Chen, Oren Kedem, Claudio R. C. M. da Silva, Carlos Cordeiro","IEEE 802.11ay defines new PHY and MAC specifications that enable 100 Gbpscommunications in the 60 GHz millimeter-wave (mmWave) band. Among the varioususe cases supported by IEEE 802.11ay, fixed wireless access, a cost-efficienthigh-performance alternative and/or complement to conventional fixed access,differentiates itself due to its unique requirements and characteristics. Inthis article, our goal is to identify and describe key elements incorporatedinto IEEE 802.11ay, including scheduling, beamforming, and link maintenance,that efficiently support fixed wireless access. IEEE 802.11ay is thus a viableand strong candidate to form the basis of future generations ofstandards-compliant (i.e., non-proprietary) mmWave fixed wireless accessnetworks."
"661","arXiv:1907.00083","https://arxiv.org/abs/1907.00083","Extracting Novel Facts from Tables for Knowledge Graph Completion  (Extended version)","Benno Kruit, Peter Boncz, Jacopo Urbani","We propose a new end-to-end method for extending a Knowledge Graph (KG) fromtables. Existing techniques tend to interpret tables by focusing on informationthat is already in the KG, and therefore tend to extract many redundant facts.Our method aims to find more novel facts. We introduce a new technique fortable interpretation based on a scalable graphical model using entitysimilarities. Our method further disambiguates cell values using KG embeddingsas additional ranking method. Other distinctive features are the lack ofassumptions about the underlying KG and the enabling of a fine-grained tuningof the precision/recall trade-off of extracted facts. Our experiments show thatour approach has a higher recall during the interpretation process than thestate-of-the-art, and is more resistant against the bias observed in extractingmostly redundant facts since it produces more novel extractions."
"662","arXiv:1907.00084","https://arxiv.org/abs/1907.00084","Constraint-preserving hybrid finite element methods for Maxwell's  equations","Yakov Berchenko-Kogan, Ari Stern","Maxwell's equations describe the evolution of electromagnetic fields,together with constraints on the divergence of the magnetic and electric fluxdensities. These constraints correspond to fundamental physical laws: thenonexistence of magnetic monopoles and the conservation of charge,respectively. However, one or both of these constraints may be violated whenone applies a finite element method to discretize in space. This is awell-known and longstanding problem in computational electromagnetics.We use domain decomposition to construct a family of primal hybrid finiteelement methods for Maxwell's equations, where the Lagrange multipliers areshown to correspond to a numerical trace of the magnetic field and a numericalflux of the electric flux density. Expressing the charge-conservationconstraint in terms of this numerical flux, we show that both constraints arestrongly preserved. As a special case, these methods include a hybridizedversion of N\'ed\'elec's method, implying that it preserves the constraintsmore strongly than previously recognized. These constraint-preservingproperties are illustrated using numerical experiments in both the time domainand frequency domain. Additionally, we observe a superconvergence phenomenon,where hybrid post-processing yields an improved estimate of the magnetic field."
"663","arXiv:1907.00087","https://arxiv.org/abs/1907.00087","DRAT-based Bit-Vector Proofs in CVC4","Alex Ozdemir, Aina Niemetz, Mathias Preiner, Yoni Zohar, Clark Barrett","Many state-of-the-art Satisfiability Modulo Theories (SMT) solvers for thetheory of fixed-size bit-vectors employ an approach called bit-blasting, wherea given formula is translated into a Boolean satisfiability (SAT) problem anddelegated to a SAT solver. Consequently, producing bit-vector proofs in an SMTsolver requires incorporating SAT proofs into its proof infrastructure. In thispaper, we describe three approaches for integrating DRAT proofs generated by anoff-the-shelf SAT solver into the proof infrastructure of the SMT solver CVC4and explore their strengths and weaknesses. We implemented all three approachesusing cryptominisat as the SAT back-end for its bit-blasting engine andevaluated performance in terms of proof-production and proof-checking."
"664","arXiv:1907.00089","https://arxiv.org/abs/1907.00089","Learning to Identify Patients at Risk of Uncontrolled Hypertension Using  Electronic Health Records Data","Ramin Mohammadi, Sarthak Jain, Stephen Agboola, Ramya Palacholla, Sagar Kamarthi, Byron C. Wallace","Hypertension is a major risk factor for stroke, cardiovascular disease, andend-stage renal disease, and its prevalence is expected to rise dramatically.Effective hypertension management is thus critical. A particular priority isdecreasing the incidence of uncontrolled hypertension. Early identification ofpatients at risk for uncontrolled hypertension would allow targeted use ofpersonalized, proactive treatments. We develop machine learning models(logistic regression and recurrent neural networks) to stratify patients withrespect to the risk of exhibiting uncontrolled hypertension within the comingthree-month period. We trained and tested models using EHR data from 14,407 and3,009 patients, respectively. The best model achieved an AUROC of 0.719,outperforming the simple, competitive baseline of relying prediction based onthe last BP measure alone (0.634). Perhaps surprisingly, recurrent neuralnetworks did not outperform a simple logistic regression for this task,suggesting that linear models should be included as strong baselines forpredictive tasks using EHR"
"665","arXiv:1907.00091","https://arxiv.org/abs/1907.00091","Quadrature by Two Expansions: Evaluating Laplace Layer Potentials using  Complex Polynomial and Plane Wave Expansions","Lingyun Ding, Jingfang Huang, Jeremy L. Marzuola","The recently developed quadrature by expansion (QBX) technique accuratelyevaluates the layer potentials with singular, weakly or nearly singular, oreven hyper singular kernels in the integral equation reformulations of partialdifferential equations. The idea is to form a local complex polynomial orpartial wave expansion centered at a point away from the boundary to avoid thesingularity in the integrand, and then extrapolate the expansion at points nearor even exactly on the boundary. In this paper, in addition to the localcomplex Taylor polynomial expansion, we derive new representations of theLaplace layer potentials using both the local complex polynomial and plane waveexpansions. Unlike in the QBX, the local complex polynomial expansion in thenew quadrature by two expansions (QB2X) method only collects the far-fieldcontributions and its number of expansion terms can be analyzed using toolsfrom the classical fast multipole method. The plane wave type expansion in theQB2X method better captures the layer potential features near the boundary. Itis derived by applying the Fourier extension technique to the density andboundary geometry functions and then analytically utilizing the Residue Theoremfor complex contour integrals. The internal connections of the layer potentialwith its density function and curvature on the boundary are explicitly revealedin the plane wave expansion and its error is bounded by the Fourier extensionerrors. We present preliminary numerical results to demonstrate the accuracy ofthe QB2X representations and to validate our analysis."
"666","arXiv:1907.00096","https://arxiv.org/abs/1907.00096","Solving Polynomial Systems with phcpy","Jasmine Otto, Angus Forbes, Jan Verschelde","The solutions of a system of polynomials in several variables are oftenneeded, e.g.: in the design of mechanical systems, and in phase-space analysesof nonlinear biological dynamics. Reliable, accurate, and comprehensivenumerical solutions are available through PHCpack, a FOSS package for solvingpolynomial systems with homotopy continuation. This paper explores newdevelopments in phcpy, a scripting interface for PHCpack, over the past fiveyears. For instance, phcpy is now available online through a JupyterHub serverfeaturing Python2, Python3, and SageMath kernels. As small systems are solvedin real-time by phcpy, they are suitable for interactive exploration throughthe notebook interface. Meanwhile, phcpy supports GPU parallelization,improving the speed and quality of solutions to much larger polynomial systems.From various model design and analysis problems in STEM, certain classes ofpolynomial system frequently arise, to which phcpy is well-suited."
"667","arXiv:1907.00097","https://arxiv.org/abs/1907.00097","Parallel Performance of Molecular Dynamics Trajectory Analysis","Mahzad Khoshlessan, Ioannis Paraskevakos, Geoffrey C. Fox, Shantenu Jha, Oliver Beckstein","The performance of biomolecular molecular dynamics (MD) simulations hassteadily increased on modern high performance computing (HPC) resources butacceleration of the analysis of the output trajectories has lagged behind sothat analyzing simulations is increasingly becoming a bottleneck. To close thisgap, we studied the performance of parallel trajectory analysis with MPI andthe Python MDAnalysis library on three different XSEDE supercomputers wheretrajectories were read from a Lustre parallel file system. We found that strongscaling performance was impeded by stragglers, MPI processes that were slowerthan the typical process and that therefore dominated the overall run time.Stragglers were less prevalent for compute-bound workloads, thus pointing tofile reading as a crucial bottleneck for scaling. However, a more complicatedpicture emerged in which both the computation and the ingestion of dataexhibited close to ideal strong scaling behavior whereas stragglers wereprimarily caused by either large MPI communication costs or long times to openthe single shared trajectory file. We improved overall strong scalingperformance by two different approaches to file access, namely subfiling(splitting the trajectory into as many trajectory segments as number ofprocesses) and MPI-IO with Parallel HDF5 trajectory files. Applying thesestrategies, we obtained near ideal strong scaling on up to 384 cores (16nodes). We summarize our lessons-learned in guidelines and strategies on how totake advantage of the available HPC resources to gain good scalability andpotentially reduce trajectory analysis times by two orders of magnitudecompared to the prevalent serial approach."
"668","arXiv:1907.00098","https://arxiv.org/abs/1907.00098","Robustness Guarantees for Deep Neural Networks on Videos","Min Wu, Marta Kwiatkowska","The widespread adoption of deep learning models places demands on theirrobustness. In this paper, we consider the robustness of deep neural networkson videos, which comprise both the spatial features of individual framesextracted by a convolutional neural network and the temporal dynamics betweenadjacent frames captured by a recurrent neural network. To measure robustness,we study the maximum safe radius problem, which computes the minimum distancefrom the optical flow set obtained from a given input to that of an adversarialexample in the norm ball. We demonstrate that, under the assumption ofLipschitz continuity, the problem can be approximated using finite optimisationvia discretising the optical flow space, and the approximation has provableguarantees. We then show that the finite optimisation problem can be solved byutilising a two-player turn-based game in a cooperative setting, where thefirst player selects the optical flows and the second player determines thedimensions to be manipulated in the chosen flow. We employ an anytime approachto solve the game, in the sense of approximating the value of the game bymonotonically improving its upper and lower bounds. We exploit a gradient-basedsearch algorithm to compute the upper bounds, and the admissible A* algorithmto update the lower bounds. Finally, we evaluate our framework on the UCF101video dataset."
"669","arXiv:1907.00102","https://arxiv.org/abs/1907.00102","The Complexity of Tiling Problems","François Schwarzentruber","In this document, we collected the most important complexity results oftilings. We also propose a definition of a so-called deterministic set of tiletypes, in order to capture deterministic classes without the notion of games.We also pinpoint tiling problems complete for respectively LOGSPACE andNLOGSPACE."
"670","arXiv:1907.00103","https://arxiv.org/abs/1907.00103","Learning Effective Loss Functions Efficiently","Matthew Streeter","We consider the problem of learning a loss function which, when minimizedover a training dataset, yields a model that approximately minimizes avalidation error metric. Though learning an optimal loss function is NP-hard,we present an anytime algorithm that is asymptotically optimal in the worstcase, and is provably efficient in an idealized ""easy"" case. Experimentally, weshow that this algorithm can be used to tune loss function hyperparametersorders of magnitude faster than state-of-the-art alternatives. We also showthat our algorithm can be used to learn novel and effective loss functionson-the-fly during training."
